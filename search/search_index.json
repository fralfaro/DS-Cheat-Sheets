{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Cheat Sheets for Data Science Learning","text":"<p>This repository is a comprehensive resource for Data Science Cheat Sheets,  specifically designed for Python and R. </p> <p>These Cheat Sheets offer a multidimensional approach to learning, available in three distinct formats:</p> PDF Streamlit Google Colab"},{"location":"#sections","title":"Sections","text":""},{"location":"#python","title":"\ud83d\udcd7 Python","text":"<p>Python</p><p> Python, an easily readable high-level programming language, was created by Guido van Rossum in 1991. </p> <p>Numpy</p><p> NumPy is Python's essential library for scientific computing, offering high-performance multidimensional arrays. </p> <p>Pandas</p><p> Pandas, built on NumPy, offers user-friendly data structures and analysis tools for Python. </p> <p>Matplotlib</p><p> Matplotlib is a Python library for creating high-quality 2D plots in various formats and interactive platforms. </p> <p>Scikit-Learn</p><p> Scikit-learn is an open-source Python library that offers a unified interface for machine learning algorithms. </p> <p>Polars</p><p> Polars is an efficient DataFrame library for working with structured data (written in Rust). </p>"},{"location":"#r","title":"\ud83d\udcd8 R","text":"<p>Dplyr</p><p> dplyr is a data manipulation tool that offers a consistent set of actions for solving common data manipulation tasks. </p> <p>Ggplot2</p><p> ggplot2 is a system for declaratively creating graphics, based on The Grammar of Graphics. </p> <p>Forcats</p><p> forcats package is to provide a suite of tools that solve common problems with factors (in R). </p> <p>\ud83d\udd11 Note: The PDF cheat sheets in this repository are created by various contributors and have inspired the content presented here.</p>"},{"location":"#references","title":"\ud83d\udcd6 References","text":"<ul> <li>Data Science Cheat Sheets - DataCamp</li> <li>Cheatsheets and Handouts - Matplotlib</li> <li>Streamlit Cheat Sheet - Daniel Lewis</li> <li>Polars cheat sheet - Franz Diebold</li> <li>Posit Cheatsheets - Posit</li> </ul>"},{"location":"__init__/","title":"init","text":""},{"location":"examples/dplyr/app/","title":"App","text":"In\u00a0[\u00a0]: Copied! <pre>import streamlit as st\nfrom pathlib import Path\nimport base64\nimport requests\n</pre> import streamlit as st from pathlib import Path import base64 import requests In\u00a0[\u00a0]: Copied! <pre># Initial page config\nst.set_page_config(\n    page_title='Dplyr Cheat Sheet',\n    layout=\"wide\",\n    initial_sidebar_state=\"expanded\",\n)\n</pre> # Initial page config st.set_page_config(     page_title='Dplyr Cheat Sheet',     layout=\"wide\",     initial_sidebar_state=\"expanded\", ) In\u00a0[\u00a0]: Copied! <pre>def main():\n    \"\"\"\n    Main function to set up the Streamlit app layout.\n    \"\"\"\n    cs_sidebar()\n    cs_body()\n    return None\n</pre> def main():     \"\"\"     Main function to set up the Streamlit app layout.     \"\"\"     cs_sidebar()     cs_body()     return None In\u00a0[\u00a0]: Copied! <pre># Define img_to_bytes() function\ndef img_to_bytes(img_url):\n    response = requests.get(img_url)\n    img_bytes = response.content\n    encoded = base64.b64encode(img_bytes).decode()\n    return encoded\n</pre> # Define img_to_bytes() function def img_to_bytes(img_url):     response = requests.get(img_url)     img_bytes = response.content     encoded = base64.b64encode(img_bytes).decode()     return encoded In\u00a0[\u00a0]: Copied! <pre># Define the cs_sidebar() function\ndef cs_sidebar():\n    \"\"\"\n    Populate the sidebar with various content sections related to dplyr.\n    \"\"\"\n    st.sidebar.markdown(\n        '''[&lt;img src='data:image/png;base64,{}' class='img-fluid' width=95 &gt;](https://streamlit.io/)'''.format(\n            img_to_bytes(\"https://rstudio.github.io/cheatsheets/html/images/logo-dplyr.png\")), unsafe_allow_html=True)\n\n    st.sidebar.header('Dplyr Cheat Sheet')\n    st.sidebar.markdown('''\n&lt;small&gt;[dplyr](https://dplyr.tidyverse.org/) functions work with pipes and expect **tidy data**. In tidy data:\n\n*   Each **variable** is in its own **column**\n*   Each **observation**, or **case**, is in its own **row**\n*   **pipes** `x |&gt; f(y)` becomes `f(x,y)`&lt;/small&gt;\n    ''', unsafe_allow_html=True)\n\n    # dplyr installation and import\n    st.sidebar.markdown('__Install and import dplyr__')\n    st.sidebar.code('''$ install.packages('dplyr')''')\n    st.sidebar.code('''\n# Import dplyr \n&gt;&gt;&gt; library(dplyr)\n''')\n\n\n    return None\n</pre> # Define the cs_sidebar() function def cs_sidebar():     \"\"\"     Populate the sidebar with various content sections related to dplyr.     \"\"\"     st.sidebar.markdown(         '''[](https://streamlit.io/)'''.format(             img_to_bytes(\"https://rstudio.github.io/cheatsheets/html/images/logo-dplyr.png\")), unsafe_allow_html=True)      st.sidebar.header('Dplyr Cheat Sheet')     st.sidebar.markdown(''' [dplyr](https://dplyr.tidyverse.org/) functions work with pipes and expect **tidy data**. In tidy data:  *   Each **variable** is in its own **column** *   Each **observation**, or **case**, is in its own **row** *   **pipes** `x |&gt; f(y)` becomes `f(x,y)`     ''', unsafe_allow_html=True)      # dplyr installation and import     st.sidebar.markdown('__Install and import dplyr__')     st.sidebar.code('''$ install.packages('dplyr')''')     st.sidebar.code(''' # Import dplyr  &gt;&gt;&gt; library(dplyr) ''')       return None In\u00a0[\u00a0]: Copied! <pre># Define the cs_body() function\ndef cs_body():\n    \"\"\"\n    Create content sections for the main body of the Streamlit cheat sheet with dplyr examples.\n    \"\"\"\n    col1, col2, col3 = st.columns(3)  # Create columns for layout\n\n    #######################################\n    # COLUMN 1\n    #######################################\n\n    # Summarize Cases\n    col1.subheader('Summarize Cases')\n    col1.code('''\n    # Compute table of summaries.\n    mtcars |&gt; summarize(avg = mean(mpg))\n        ''')\n\n    col1.code('''\n    # Count number of rows in each group.\n    mtcars |&gt; count(cyl)\n        ''')\n\n    # Group Cases\n    col1.subheader('Group Cases')\n    col1.code('''\n    # created a \u201cgrouped\u201d copy of a table grouped by columns in `...`\n    mtcars |&gt;\n          group_by(cyl) |&gt;\n          summarize(avg = mean(mpg))\n        ''')\n    col1.code('''\n    # to group data into individual rows\n    starwars |&gt;\n          rowwise() |&gt;\n          mutate(film_count = length(films))\n        ''')\n    col1.code('''\n    # Returns ungrouped copy of table.\n    ungroup(x, ...)\n        ''')\n\n\n    # Extract Cases\n    col1.subheader('Extract Cases')\n    col1.code('''\n     # Extract rows that meet logical criteria.\n     mtcars |&gt; filter(mpg &gt; 20)\n         ''')\n    col1.code('''\n     # Remove rows with duplicate values.\n     mtcars |&gt; distinct(gear)\n         ''')\n    col1.code('''\n     # Select rows by position.\n      mtcars |&gt; slice(10:15)\n         ''')\n    col1.code('''\n     # Randomly select rows.\n      mtcars |&gt; slice_sample(n = 5, replace = TRUE)\n         ''')\n    col1.code('''\n     # Select rows with the lowest and highest values.\n      mtcars |&gt; slice_min(mpg, prop = 0.25)\n         ''')\n    col1.code('''\n     # Select the first or last rows.\n      mtcars |&gt; slice_head(n = 5)\n         ''')\n    col1.subheader('''Logical and boolean operations to use with `filter()`''')\n    col1.markdown('''\n        *   `==`\n    *   `&lt;`\n    *   `&lt;=`\n    *   `is.na()`\n    *   `%in%`\n    *   `|`\n    *   `xor()`\n    *   `!=`\n    *   `&gt;`\n    *   `&gt;=`\n    *   `!is.na()`\n    *   `!`\n    *   `&amp;`\n    *   See `?base::Logic` and `?Comparison` for help.\n            ''')\n\n    # Arrange Cases\n    col1.subheader('Arrange Cases')\n    col1.code('''\n     # Order rows by values of a column or columns (low to high)\n     mtcars |&gt; arrange(mpg)\n     mtcars |&gt; arrange(desc(mpg))\n         ''')\n\n    # Add Cases\n    col1.subheader('Add Cases')\n    col1.code('''\n     # Add one or more rows to a table.\n     cars |&gt; add_row(speed = 1, dist = 1)\n         ''')\n\n\n    #######################################\n    # COLUMN 2\n    #######################################\n\n    # Extract Variables\n    col1.subheader('Extract Variables')\n    col1.code('''\n    # Extract column values as a vector, by name or index.\n    mtcars |&gt; pull(wt)\n        ''')\n    col1.code('''\n    # Extract columns as a table.\n    mtcars |&gt; select(mpg, wt)\n        ''')\n    col1.code('''\n    # Move columns to new position.\n    mtcars |&gt; relocate(mpg, cyl, after = last_col())\n        ''')\n\n    # Logical\n    col2.subheader('''More about: `select()` and `across()`''')\n    col2.code('''\n            mtcars |&gt; select(mpg:cyl)\n                ''')\n    col2.markdown('''\n    *   `contains(match)`\n    *   `num_range(prefix, range)`\n    *   `:`, e.g., `mpg:cyl`\n    *   `ends_with(match)`\n    *   `all_of(x)` or `any_of(x, ..., vars)`\n    *   `!`, e.g., `!gear`\n    *   `starts_with(match)`\n    *   `matches(match)`\n    *   `everything()`\n                ''')\n\n    # Manipulate Multiple Variables at Once\n    col2.subheader('Manipulate Multiple Variables at Once')\n    col2.code('''\n        df &lt;- tibble(x_1 = c(1, 2), x_2 = c(3, 4), y = c(4, 5))\n            ''')\n    col2.code('''\n        # summarize or mutate multiple columns in the same way.\n        df |&gt; summarize(across(everything(), mean))\n            ''')\n    col2.code('''\n        # Compute across columns in row-wise data.\n        df |&gt; \n          rowwise() |&gt;\n          mutate(x_total = sum(c_across(1:2)))\n            ''')\n\n    # Make New Variables\n    col2.subheader('Make New Variables')\n    col2.code('''\n        # Compute new column(s). Also add_column().\n        mtcars |&gt; mutate(gpm = 1 / mpg)\n        mtcars |&gt; mutate(mtcars, gpm = 1 / mpg, .keep = \"none\")\n            ''')\n    col2.code('''\n        # Rename columns. Use rename_with() to rename with a function.\n        mtcars |&gt; rename(miles_per_gallon = mpg)\n            ''')\n\n\n\n    # Logical\n    col2.subheader('''Vectorized Functions''')\n    col2.markdown('''\n    ### To Use with `mutate()`[](#to-use-with-mutate)\n\n    `mutate()` applies vectorized functions to columns to create new columns. Vectorized functions take vectors as input and return vectors of the same length as output.\n\n    ### Offset[](#offset)\n\n    *   `dplyr::lag()`: offset elements by 1\n    *   `dplyr::lead()`: offset elements by -1\n\n    ### Cumulative Aggregate[](#cumulative-aggregate)\n\n    *   `dplyr::cumall()`: cumulative `all()`\n    *   `dply::cumany()`: cumulative `any()`\n    *   `cummax()`: cumulative `max()`\n    *   `dplyr::cummean()`: cumulative `mean()`\n    *   `cummin()`: cumulative `min()`\n    *   `cumprod()`: cumulative `prod()`\n    *   `cumsum()`: cumulative `sum()`\n\n    ### Ranking[](#ranking)\n\n    *   `dplyr::cume_dist()`: proportion of all values &lt;=\n    *   `dplyr::dense_rank()`: rank with ties = min, no gaps\n    *   `dplyr::min_rank()`: rank with ties = min\n    *   `dplyr::ntile()`: bins into n bins\n    *   `dplyr::percent_rank()`: `min_rank()` scaled to \\[0,1\\]\n    *   `dplyr::row_number()`: rank with ties = \u201cfirst\u201d\n\n    ### Math[](#math)\n\n    *   `+`, `-`, `/`, `^`, `%/%`, `%%`: arithmetic ops\n    *   `log()`, `log2()`, `log10()`: logs\n    *   `&lt;`, `&lt;=`, `&gt;`, `&gt;=`, `!=`, `==`: logical comparisons\n    *   `dplyr::between()`: x &gt;= left &amp; x &lt;= right\n    *   `dplyr::near()`: safe `==` for floating point numbers\n\n    ### Miscellaneous[](#miscellaneous)\n\n    *   `dplyr::case_when()`: multi-case `if_else()`\n\n            starwars |&gt;\n              mutate(type = case_when(\n                height &gt; 200 | mass &gt; 200 ~ \"large\",\n                species == \"Droid\" ~ \"robot\",\n                TRUE ~ \"other\"\n              ))\n\n    *   `dplyr::coalesce()`: first non-NA values by element across a set of vectors\n\n    *   `dplyr::if_else()`: element-wise if() + else()\n\n    *   `dplyr::na_if()`: replace specific values with NA\n\n    *   `pmax()`: element-wise max()\n\n    *   `pmin()`: element-wise min()\n                    ''')\n\n\n\n\n    #######################################\n    # COLUMN 3\n    #######################################\n\n    # Row Names\n    col3.subheader('Row Names')\n    col3.code('''\n        # Move row names into col.\n        a &lt;- rownames_to_column(mtcars, var = \"C\")\n            ''')\n    col3.code('''\n        # Move col into row names.\n        column_to_rownames(a, var = \"C\")\n            ''')\n\n    # Summary Functions\n    col3.subheader('''Summary Functions''')\n    col3.markdown('''\n    ### To Use with `summarize()`[](#to-use-with-summarize)\n\n    `summarize()` applies summary functions to columns to create a new table. Summary functions take vectors as input and return single values as output.\n\n    ### Count[](#count)\n\n    *   `dplyr::n()`: number of values/rows\n    *   `dplyr::n_distinct()`: # of uniques\n    *   `sum(!is.na())`: # of non-NAs\n\n    ### Position[](#position)\n\n    *   `mean()`: mean, also `mean(!is.na())`\n    *   `median()`: median\n\n    ### Logical[](#logical)\n\n    *   `mean()`: proportion of TRUEs\n    *   `sum()`: # of TRUEs\n\n    ### Order[](#order)\n\n    *   `dplyr::first()`: first value\n    *   `dplyr::last()`: last value\n    *   `dplyr::nth()`: value in the nth location of vector\n\n    ### Rank[](#rank)\n\n    *   `quantile()`: nth quantile\n    *   `min()`: minimum value\n    *   `max()`: maximum value\n\n    ### Spread[](#spread)\n\n    *   `IQR()`: Inter-Quartile Range\n    *   `mad()`: median absolute deviation\n    *   `sd()`: standard deviation\n    *   `var()`: variance\n                ''')\n\n    # Relational Data\n    col3.subheader('''Relational Data''')\n    col3.markdown('''\n        Use a **\u201cMutating Join\u201d** to join one table to columns from another, matching values with the rows that the correspond to.\n\n    *   `left_join(x, y, by = NULL, copy = FALSE, suffix = c(\".x\", \".y\"), ..., keep = FALSE, na_matches = \"na\")`: Join matching values from `y` to `x`.\n    *   `right_join(x, y, by = NULL, copy = FALSE, suffix = c(\".x\", \".y\"), ..., keep = FALSE, na_matches = \"na\")`: Join matching values from `x` to `y`.\n    *   `inner_join(x, y, by = NULL, copy = FALSE, suffix = c(\".x\", \".y\"), ..., keep = FALSE, na_matches = \"na\")`: Join data. retain only rows with matches.\n    *   `full_join(x, y, by = NULL, copy = FALSE, suffix = c(\".x\", \".y\"), ..., keep = FALSE, na_matches = \"na\")`: Join data. Retain all values, all rows.\n\n    Use a **\u201cFiltering Join\u201d** to filter one table against the rows of another.\n\n    *   `semi_join(x, y, by = NULL, copy = FALSE, ..., na_matches = \"na\")`: Return rows of `x` that have a match in `y`. Use to see what will be included in a join.\n    *   `anti_join(x, y, by = NULL, copy = FALSE, ..., na_matches = \"na\")`: Return rows of `x` that do not have a match in `y`. Use to see what will not be included in a join.\n\n    Use a **\u201cNest Join\u201d** to inner join one table to another into a nested data frame.\n\n    *   `nest_join(x, y, by = NULL, copy = FALSE, keep = FALSE, name = NULL, ...)`: Join data, nesting matches from `y` in a single new data frame column.\n\n                    ''')\n\n    # Column Matching for Joins\n    col3.subheader('Column Matching for Joins')\n    col3.code('''\n        # Use by = join_by(col1, col2, \u2026) to specify one or more common columns to match on.\n        left_join(x, y, by = join_by(A))\n        left_join(x, y, by = join_by(A, B))\n            ''')\n    col3.code('''\n        # Use a logical statement, by = join_by(col1 == col2), to match on columns that have different names in each table.\n        left_join(x, y, by = join_by(C == D))\n            ''')\n    col3.code('''\n        # Use suffix to specify the suffix to give to unmatched columns that have the same name in both tables.\n        left_join(x, y, by = join_by(C == D), suffix = c(\"1\", \"2\"))\n            ''')\n\n\n\n\n\n   # Set Operations\n    col3.subheader('''Set Operations''')\n    col3.markdown('''\n*   `intersect(x, y, ...)`: Rows that appear in both `x` and `y`.\n*   `setdiff(x, y, ...)`: Rows that appear in `x` but not `y`.\n*   `union(x, y, ...)`: Rows that appear in x or y, duplicates removed. `union_all()` retains duplicates.\n*   Use `setequal()` to test whether two data sets contain the exact same rows (in any order).\n            ''')\n</pre> # Define the cs_body() function def cs_body():     \"\"\"     Create content sections for the main body of the Streamlit cheat sheet with dplyr examples.     \"\"\"     col1, col2, col3 = st.columns(3)  # Create columns for layout      #######################################     # COLUMN 1     #######################################      # Summarize Cases     col1.subheader('Summarize Cases')     col1.code('''     # Compute table of summaries.     mtcars |&gt; summarize(avg = mean(mpg))         ''')      col1.code('''     # Count number of rows in each group.     mtcars |&gt; count(cyl)         ''')      # Group Cases     col1.subheader('Group Cases')     col1.code('''     # created a \u201cgrouped\u201d copy of a table grouped by columns in `...`     mtcars |&gt;           group_by(cyl) |&gt;           summarize(avg = mean(mpg))         ''')     col1.code('''     # to group data into individual rows     starwars |&gt;           rowwise() |&gt;           mutate(film_count = length(films))         ''')     col1.code('''     # Returns ungrouped copy of table.     ungroup(x, ...)         ''')       # Extract Cases     col1.subheader('Extract Cases')     col1.code('''      # Extract rows that meet logical criteria.      mtcars |&gt; filter(mpg &gt; 20)          ''')     col1.code('''      # Remove rows with duplicate values.      mtcars |&gt; distinct(gear)          ''')     col1.code('''      # Select rows by position.       mtcars |&gt; slice(10:15)          ''')     col1.code('''      # Randomly select rows.       mtcars |&gt; slice_sample(n = 5, replace = TRUE)          ''')     col1.code('''      # Select rows with the lowest and highest values.       mtcars |&gt; slice_min(mpg, prop = 0.25)          ''')     col1.code('''      # Select the first or last rows.       mtcars |&gt; slice_head(n = 5)          ''')     col1.subheader('''Logical and boolean operations to use with `filter()`''')     col1.markdown('''         *   `==`     *   `&lt;`     *   `&lt;=`     *   `is.na()`     *   `%in%`     *   `|`     *   `xor()`     *   `!=`     *   `&gt;`     *   `&gt;=`     *   `!is.na()`     *   `!`     *   `&amp;`     *   See `?base::Logic` and `?Comparison` for help.             ''')      # Arrange Cases     col1.subheader('Arrange Cases')     col1.code('''      # Order rows by values of a column or columns (low to high)      mtcars |&gt; arrange(mpg)      mtcars |&gt; arrange(desc(mpg))          ''')      # Add Cases     col1.subheader('Add Cases')     col1.code('''      # Add one or more rows to a table.      cars |&gt; add_row(speed = 1, dist = 1)          ''')       #######################################     # COLUMN 2     #######################################      # Extract Variables     col1.subheader('Extract Variables')     col1.code('''     # Extract column values as a vector, by name or index.     mtcars |&gt; pull(wt)         ''')     col1.code('''     # Extract columns as a table.     mtcars |&gt; select(mpg, wt)         ''')     col1.code('''     # Move columns to new position.     mtcars |&gt; relocate(mpg, cyl, after = last_col())         ''')      # Logical     col2.subheader('''More about: `select()` and `across()`''')     col2.code('''             mtcars |&gt; select(mpg:cyl)                 ''')     col2.markdown('''     *   `contains(match)`     *   `num_range(prefix, range)`     *   `:`, e.g., `mpg:cyl`     *   `ends_with(match)`     *   `all_of(x)` or `any_of(x, ..., vars)`     *   `!`, e.g., `!gear`     *   `starts_with(match)`     *   `matches(match)`     *   `everything()`                 ''')      # Manipulate Multiple Variables at Once     col2.subheader('Manipulate Multiple Variables at Once')     col2.code('''         df &lt;- tibble(x_1 = c(1, 2), x_2 = c(3, 4), y = c(4, 5))             ''')     col2.code('''         # summarize or mutate multiple columns in the same way.         df |&gt; summarize(across(everything(), mean))             ''')     col2.code('''         # Compute across columns in row-wise data.         df |&gt;            rowwise() |&gt;           mutate(x_total = sum(c_across(1:2)))             ''')      # Make New Variables     col2.subheader('Make New Variables')     col2.code('''         # Compute new column(s). Also add_column().         mtcars |&gt; mutate(gpm = 1 / mpg)         mtcars |&gt; mutate(mtcars, gpm = 1 / mpg, .keep = \"none\")             ''')     col2.code('''         # Rename columns. Use rename_with() to rename with a function.         mtcars |&gt; rename(miles_per_gallon = mpg)             ''')        # Logical     col2.subheader('''Vectorized Functions''')     col2.markdown('''     ### To Use with `mutate()`[](#to-use-with-mutate)      `mutate()` applies vectorized functions to columns to create new columns. Vectorized functions take vectors as input and return vectors of the same length as output.      ### Offset[](#offset)      *   `dplyr::lag()`: offset elements by 1     *   `dplyr::lead()`: offset elements by -1      ### Cumulative Aggregate[](#cumulative-aggregate)      *   `dplyr::cumall()`: cumulative `all()`     *   `dply::cumany()`: cumulative `any()`     *   `cummax()`: cumulative `max()`     *   `dplyr::cummean()`: cumulative `mean()`     *   `cummin()`: cumulative `min()`     *   `cumprod()`: cumulative `prod()`     *   `cumsum()`: cumulative `sum()`      ### Ranking[](#ranking)      *   `dplyr::cume_dist()`: proportion of all values &lt;=     *   `dplyr::dense_rank()`: rank with ties = min, no gaps     *   `dplyr::min_rank()`: rank with ties = min     *   `dplyr::ntile()`: bins into n bins     *   `dplyr::percent_rank()`: `min_rank()` scaled to \\[0,1\\]     *   `dplyr::row_number()`: rank with ties = \u201cfirst\u201d      ### Math[](#math)      *   `+`, `-`, `/`, `^`, `%/%`, `%%`: arithmetic ops     *   `log()`, `log2()`, `log10()`: logs     *   `&lt;`, `&lt;=`, `&gt;`, `&gt;=`, `!=`, `==`: logical comparisons     *   `dplyr::between()`: x &gt;= left &amp; x &lt;= right     *   `dplyr::near()`: safe `==` for floating point numbers      ### Miscellaneous[](#miscellaneous)      *   `dplyr::case_when()`: multi-case `if_else()`              starwars |&gt;               mutate(type = case_when(                 height &gt; 200 | mass &gt; 200 ~ \"large\",                 species == \"Droid\" ~ \"robot\",                 TRUE ~ \"other\"               ))      *   `dplyr::coalesce()`: first non-NA values by element across a set of vectors      *   `dplyr::if_else()`: element-wise if() + else()      *   `dplyr::na_if()`: replace specific values with NA      *   `pmax()`: element-wise max()      *   `pmin()`: element-wise min()                     ''')         #######################################     # COLUMN 3     #######################################      # Row Names     col3.subheader('Row Names')     col3.code('''         # Move row names into col.         a &lt;- rownames_to_column(mtcars, var = \"C\")             ''')     col3.code('''         # Move col into row names.         column_to_rownames(a, var = \"C\")             ''')      # Summary Functions     col3.subheader('''Summary Functions''')     col3.markdown('''     ### To Use with `summarize()`[](#to-use-with-summarize)      `summarize()` applies summary functions to columns to create a new table. Summary functions take vectors as input and return single values as output.      ### Count[](#count)      *   `dplyr::n()`: number of values/rows     *   `dplyr::n_distinct()`: # of uniques     *   `sum(!is.na())`: # of non-NAs      ### Position[](#position)      *   `mean()`: mean, also `mean(!is.na())`     *   `median()`: median      ### Logical[](#logical)      *   `mean()`: proportion of TRUEs     *   `sum()`: # of TRUEs      ### Order[](#order)      *   `dplyr::first()`: first value     *   `dplyr::last()`: last value     *   `dplyr::nth()`: value in the nth location of vector      ### Rank[](#rank)      *   `quantile()`: nth quantile     *   `min()`: minimum value     *   `max()`: maximum value      ### Spread[](#spread)      *   `IQR()`: Inter-Quartile Range     *   `mad()`: median absolute deviation     *   `sd()`: standard deviation     *   `var()`: variance                 ''')      # Relational Data     col3.subheader('''Relational Data''')     col3.markdown('''         Use a **\u201cMutating Join\u201d** to join one table to columns from another, matching values with the rows that the correspond to.      *   `left_join(x, y, by = NULL, copy = FALSE, suffix = c(\".x\", \".y\"), ..., keep = FALSE, na_matches = \"na\")`: Join matching values from `y` to `x`.     *   `right_join(x, y, by = NULL, copy = FALSE, suffix = c(\".x\", \".y\"), ..., keep = FALSE, na_matches = \"na\")`: Join matching values from `x` to `y`.     *   `inner_join(x, y, by = NULL, copy = FALSE, suffix = c(\".x\", \".y\"), ..., keep = FALSE, na_matches = \"na\")`: Join data. retain only rows with matches.     *   `full_join(x, y, by = NULL, copy = FALSE, suffix = c(\".x\", \".y\"), ..., keep = FALSE, na_matches = \"na\")`: Join data. Retain all values, all rows.      Use a **\u201cFiltering Join\u201d** to filter one table against the rows of another.      *   `semi_join(x, y, by = NULL, copy = FALSE, ..., na_matches = \"na\")`: Return rows of `x` that have a match in `y`. Use to see what will be included in a join.     *   `anti_join(x, y, by = NULL, copy = FALSE, ..., na_matches = \"na\")`: Return rows of `x` that do not have a match in `y`. Use to see what will not be included in a join.      Use a **\u201cNest Join\u201d** to inner join one table to another into a nested data frame.      *   `nest_join(x, y, by = NULL, copy = FALSE, keep = FALSE, name = NULL, ...)`: Join data, nesting matches from `y` in a single new data frame column.                      ''')      # Column Matching for Joins     col3.subheader('Column Matching for Joins')     col3.code('''         # Use by = join_by(col1, col2, \u2026) to specify one or more common columns to match on.         left_join(x, y, by = join_by(A))         left_join(x, y, by = join_by(A, B))             ''')     col3.code('''         # Use a logical statement, by = join_by(col1 == col2), to match on columns that have different names in each table.         left_join(x, y, by = join_by(C == D))             ''')     col3.code('''         # Use suffix to specify the suffix to give to unmatched columns that have the same name in both tables.         left_join(x, y, by = join_by(C == D), suffix = c(\"1\", \"2\"))             ''')         # Set Operations     col3.subheader('''Set Operations''')     col3.markdown(''' *   `intersect(x, y, ...)`: Rows that appear in both `x` and `y`. *   `setdiff(x, y, ...)`: Rows that appear in `x` but not `y`. *   `union(x, y, ...)`: Rows that appear in x or y, duplicates removed. `union_all()` retains duplicates. *   Use `setequal()` to test whether two data sets contain the exact same rows (in any order).             ''') In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre># Run the main function if the script is executed directly\nif __name__ == '__main__':\n    main()\n</pre> # Run the main function if the script is executed directly if __name__ == '__main__':     main()"},{"location":"examples/dplyr/dplyr/","title":"Dplyr","text":"In\u00a0[\u00a0]: Copied! <pre>library(dplyr)\n</pre> library(dplyr) In\u00a0[\u00a0]: Copied! <pre>mtcars |&gt; summarize(avg = mean(mpg))\n</pre> mtcars |&gt; summarize(avg = mean(mpg))   <ul> <li><code>count(.data, ..., wt = NULL, sort = FLASE, name = NULL)</code>: Count number of rows in each group defined by the variables in <code>...</code>. Also <code>tally()</code>, <code>add_count()</code>, and <code>add_tally()</code>.</li> </ul> In\u00a0[\u00a0]: Copied! <pre>mtcars |&gt; count(cyl)\n</pre> mtcars |&gt; count(cyl)   <p>mtcars |&gt; group_by(cyl) |&gt; summarize(avg = mean(mpg))</p> <ul> <li>Use <code>rowwise(.data, ...)</code> to group data into individual rows. dplyr functions will compute results for each row. Also apply functions to list-columns. See tidyr cheatsheet for list-column workflow.</li> </ul> <p>starwars |&gt; rowwise() |&gt; mutate(film_count = length(films))</p> <ul> <li><code>ungroup(x, ...)</code>: Returns ungrouped copy of table.</li> </ul> In\u00a0[\u00a0]: Copied! <pre>mtcars |&gt; filter(mpg &gt; 20)\n</pre> mtcars |&gt; filter(mpg &gt; 20) <ul> <li><code>distinct(.data, ..., .keep_all = FALSE)</code>: Remove rows with duplicate values.</li> </ul> In\u00a0[\u00a0]: Copied! <pre>mtcars |&gt; distinct(gear)\n</pre> mtcars |&gt; distinct(gear) <ul> <li><code>slice(.data, ...,, .preserve = FALSE)</code>: Select rows by position.</li> </ul> In\u00a0[\u00a0]: Copied! <pre>mtcars |&gt; slice(10:15)\n</pre> mtcars |&gt; slice(10:15) <ul> <li><code>slice_sample(.data, ..., n, prop, weight_by = NULL, replace = FALSE)</code>: Randomly select rows. Use <code>n</code> to select a number of rows and <code>prop</code> to select a fraction of rows.</li> </ul> In\u00a0[\u00a0]: Copied! <pre>mtcars |&gt; slice_sample(n = 5, replace = TRUE)\n</pre> mtcars |&gt; slice_sample(n = 5, replace = TRUE) <ul> <li><code>slice_min(.data, order_by, ..., n, prop, with_ties = TRUE)</code> and <code>slice_max()</code>: Select rows with the lowest and highest values.</li> </ul> In\u00a0[\u00a0]: Copied! <pre>mtcars |&gt; slice_min(mpg, prop = 0.25)\n</pre> mtcars |&gt; slice_min(mpg, prop = 0.25) <ul> <li><code>slice_head(.data, ..., n, prop)</code> and <code>slice_tail()</code>: Select the first or last rows.</li> </ul> In\u00a0[\u00a0]: Copied! <pre>mtcars |&gt; slice_head(n = 5)\n</pre> mtcars |&gt; slice_head(n = 5)     In\u00a0[\u00a0]: Copied! <pre>mtcars |&gt; arrange(mpg)\nmtcars |&gt; arrange(desc(mpg))\n</pre> mtcars |&gt; arrange(mpg) mtcars |&gt; arrange(desc(mpg)) In\u00a0[\u00a0]: Copied! <pre>cars |&gt; add_row(speed = 1, dist = 1)\n</pre> cars |&gt; add_row(speed = 1, dist = 1) In\u00a0[\u00a0]: Copied! <pre>mtcars |&gt; pull(wt)\n</pre> mtcars |&gt; pull(wt) <ul> <li><code>select(.data, ...)</code>: Extract columns as a table.</li> </ul> In\u00a0[\u00a0]: Copied! <pre>mtcars |&gt; select(mpg, wt)\n</pre> mtcars |&gt; select(mpg, wt) <ul> <li><code>relocate(.data, ..., .before = NULL, .after = NULL)</code>: Move columns to new position.</li> </ul> In\u00a0[\u00a0]: Copied! <pre>mtcars |&gt; relocate(mpg, cyl, after = last_col())\n</pre> mtcars |&gt; relocate(mpg, cyl, after = last_col()) In\u00a0[\u00a0]: Copied! <pre>mtcars |&gt; select(mpg:cyl)\n</pre> mtcars |&gt; select(mpg:cyl) <ul> <li><code>contains(match)</code></li> <li><code>num_range(prefix, range)</code></li> <li><code>:</code>, e.g., <code>mpg:cyl</code></li> <li><code>ends_with(match)</code></li> <li><code>all_of(x)</code> or <code>any_of(x, ..., vars)</code></li> <li><code>!</code>, e.g., <code>!gear</code></li> <li><code>starts_with(match)</code></li> <li><code>matches(match)</code></li> <li><code>everything()</code></li> </ul> In\u00a0[\u00a0]: Copied! <pre>df &lt;- tibble(x_1 = c(1, 2), x_2 = c(3, 4), y = c(4, 5))\n</pre> df &lt;- tibble(x_1 = c(1, 2), x_2 = c(3, 4), y = c(4, 5)) <ul> <li><code>across(.cols, .fun, ..., .name = NULL)</code>: summarize or mutate multiple columns in the same way.</li> </ul> In\u00a0[\u00a0]: Copied! <pre>df |&gt; summarize(across(everything(), mean))\n</pre> df |&gt; summarize(across(everything(), mean)) <ul> <li><code>c_across(.cols)</code>: Compute across columns in row-wise data.</li> </ul> In\u00a0[\u00a0]: Copied! <pre>df |&gt; \n    rowwise() |&gt;\n    mutate(x_total = sum(c_across(1:2)))\n</pre> df |&gt;      rowwise() |&gt;     mutate(x_total = sum(c_across(1:2))) In\u00a0[\u00a0]: Copied! <pre>mtcars |&gt; mutate(gpm = 1 / mpg)\nmtcars |&gt; mutate(mtcars, gpm = 1 / mpg, .keep = \"none\")\n</pre> mtcars |&gt; mutate(gpm = 1 / mpg) mtcars |&gt; mutate(mtcars, gpm = 1 / mpg, .keep = \"none\") <ul> <li><code>rename(.data, ...)</code>: Rename columns. Use <code>rename_with()</code> to rename with a function.</li> </ul> In\u00a0[\u00a0]: Copied! <pre>mtcars |&gt; rename(miles_per_gallon = mpg)\n</pre> mtcars |&gt; rename(miles_per_gallon = mpg) In\u00a0[\u00a0]: Copied! <pre>a &lt;- rownames_to_column(mtcars, var = \"C\")\n</pre> a &lt;- rownames_to_column(mtcars, var = \"C\") <ul> <li><code>tibble::columns_to_rownames()</code>: Move col into row names.</li> </ul> In\u00a0[\u00a0]: Copied! <pre>column_to_rownames(a, var = \"C\")\n</pre> column_to_rownames(a, var = \"C\") <ul> <li>Also <code>tibble::has_rownames()</code> and <code>tibble::remove_rownames()</code>.</li> </ul> In\u00a0[\u00a0]: Copied! <pre>x &lt;- tribble(\n   ~A,  ~B, ~C,\n  \"a\", \"t\",  1,\n  \"b\", \"u\",  2,\n  \"c\", \"v\",  3\n)\n    \ny &lt;- tribble(\n   ~A,  ~B, ~D,\n  \"a\", \"t\",  3,\n  \"b\", \"u\",  2,\n  \"d\", \"w\",  1\n)\n</pre> x &lt;- tribble(    ~A,  ~B, ~C,   \"a\", \"t\",  1,   \"b\", \"u\",  2,   \"c\", \"v\",  3 )      y &lt;- tribble(    ~A,  ~B, ~D,   \"a\", \"t\",  3,   \"b\", \"u\",  2,   \"d\", \"w\",  1 ) In\u00a0[\u00a0]: Copied! <pre>left_join(x, y, by = join_by(A))\nleft_join(x, y, by = join_by(A, B))\n</pre> left_join(x, y, by = join_by(A)) left_join(x, y, by = join_by(A, B)) <ul> <li>Use a logical statement, <code>by = join_by(col1 == col2)</code>, to match on columns that have different names in each table.</li> </ul> In\u00a0[\u00a0]: Copied! <pre>left_join(x, y, by = join_by(C == D))\n</pre> left_join(x, y, by = join_by(C == D)) <ul> <li>Use <code>suffix</code> to specify the suffix to give to unmatched columns that have the same name in both tables.</li> </ul> In\u00a0[\u00a0]: Copied! <pre>left_join(x, y, by = join_by(C == D), suffix = c(\"1\", \"2\"))\n</pre> left_join(x, y, by = join_by(C == D), suffix = c(\"1\", \"2\"))"},{"location":"examples/dplyr/dplyr/#dplyr","title":"Dplyr\u00b6","text":"<p>dplyr functions work with pipes and expect tidy data. In tidy data:</p> <ul> <li>Each variable is in its own column</li> <li>Each observation, or case, is in its own row</li> <li>pipes <code>x |&gt; f(y)</code> becomes <code>f(x,y)</code></li> </ul>"},{"location":"examples/dplyr/dplyr/#summarize-cases","title":"Summarize Cases\u00b6","text":"<p>Apply summary functions to columns to create a new table of summary statistics. Summary functions take vectors as input and return one value back (see Summary Functions).</p> <ul> <li><code>summarize(.data, ...)</code>: Compute table of summaries.</li> </ul>"},{"location":"examples/dplyr/dplyr/#group-cases","title":"Group Cases\u00b6","text":"<ul> <li>Use <code>group_by(.data, ..., .add = FALSE, .drop = TRUE)</code> to created a \u201cgrouped\u201d copy of a table grouped by columns in <code>...</code>. dplyr functions will manipulate each \u201cgroup\u201d separately and combine the results.</li> </ul>"},{"location":"examples/dplyr/dplyr/#manipulate-cases","title":"Manipulate Cases\u00b6","text":""},{"location":"examples/dplyr/dplyr/#extract-cases","title":"Extract Cases\u00b6","text":"<p>Row functions return a subset of rows as a new table.</p> <ul> <li><code>filter(.data, ..., .preserve = FALSE)</code>: Extract rows that meet logical criteria.</li> </ul>"},{"location":"examples/dplyr/dplyr/#logical-and-boolean-operations-to-use-with-filter","title":"Logical and boolean operations to use with <code>filter()</code>\u00b6","text":"<ul> <li><code>==</code></li> <li><code>&lt;</code></li> <li><code>&lt;=</code></li> <li><code>is.na()</code></li> <li><code>%in%</code></li> <li><code>|</code></li> <li><code>xor()</code></li> <li><code>!=</code></li> <li><code>&gt;</code></li> <li><code>&gt;=</code></li> <li><code>!is.na()</code></li> <li><code>!</code></li> <li><code>&amp;</code></li> <li>See <code>?base::Logic</code> and <code>?Comparison</code> for help.</li> </ul>"},{"location":"examples/dplyr/dplyr/#arrange-cases","title":"Arrange cases\u00b6","text":"<ul> <li><code>arrange(.data, ..., .by_group = FALSE)</code>: Order rows by values of a column or columns (low to high), use with <code>desc()</code> to order from high to low.</li> </ul>"},{"location":"examples/dplyr/dplyr/#add-cases","title":"Add Cases\u00b6","text":"<ul> <li><code>add_row(.data, ..., .before = NULL, .after = NULL)</code>: Add one or more rows to a table.</li> </ul>"},{"location":"examples/dplyr/dplyr/#manipulate-variables","title":"Manipulate Variables\u00b6","text":""},{"location":"examples/dplyr/dplyr/#extract-variables","title":"Extract Variables\u00b6","text":"<p>Column functions return a set of columns as a new vector or table.</p> <ul> <li><code>pull(.data, var = -1, name = NULL, ...)</code>: Extract column values as a vector, by name or index.</li> </ul>"},{"location":"examples/dplyr/dplyr/#use-these-helpers-with-select-and-across","title":"Use these helpers with <code>select()</code> and <code>across()</code>\u00b6","text":""},{"location":"examples/dplyr/dplyr/#manipulate-multiple-variables-at-once","title":"Manipulate Multiple Variables at Once\u00b6","text":""},{"location":"examples/dplyr/dplyr/#make-new-variables","title":"Make New Variables\u00b6","text":"<p>Apply vectorized functions to columns. Vectorized functions take vectors as input and return vectors of the same length as output (see Vectorized Functions).</p> <ul> <li><code>mutate(.data, ..., .keep = \"all\", .before = NULL, .after = NULL)</code>: Compute new column(s). Also <code>add_column()</code>.</li> </ul>"},{"location":"examples/dplyr/dplyr/#vectorized-functions","title":"Vectorized Functions\u00b6","text":""},{"location":"examples/dplyr/dplyr/#to-use-with-mutate","title":"To Use with <code>mutate()</code>\u00b6","text":"<p><code>mutate()</code> applies vectorized functions to columns to create new columns. Vectorized functions take vectors as input and return vectors of the same length as output.</p>"},{"location":"examples/dplyr/dplyr/#offset","title":"Offset\u00b6","text":"<ul> <li><code>dplyr::lag()</code>: offset elements by 1</li> <li><code>dplyr::lead()</code>: offset elements by -1</li> </ul>"},{"location":"examples/dplyr/dplyr/#cumulative-aggregate","title":"Cumulative Aggregate\u00b6","text":"<ul> <li><code>dplyr::cumall()</code>: cumulative <code>all()</code></li> <li><code>dply::cumany()</code>: cumulative <code>any()</code></li> <li><code>cummax()</code>: cumulative <code>max()</code></li> <li><code>dplyr::cummean()</code>: cumulative <code>mean()</code></li> <li><code>cummin()</code>: cumulative <code>min()</code></li> <li><code>cumprod()</code>: cumulative <code>prod()</code></li> <li><code>cumsum()</code>: cumulative <code>sum()</code></li> </ul>"},{"location":"examples/dplyr/dplyr/#ranking","title":"Ranking\u00b6","text":"<ul> <li><code>dplyr::cume_dist()</code>: proportion of all values &lt;=</li> <li><code>dplyr::dense_rank()</code>: rank with ties = min, no gaps</li> <li><code>dplyr::min_rank()</code>: rank with ties = min</li> <li><code>dplyr::ntile()</code>: bins into n bins</li> <li><code>dplyr::percent_rank()</code>: <code>min_rank()</code> scaled to [0,1]</li> <li><code>dplyr::row_number()</code>: rank with ties = \u201cfirst\u201d</li> </ul>"},{"location":"examples/dplyr/dplyr/#math","title":"Math\u00b6","text":"<ul> <li><code>+</code>, <code>-</code>, <code>/</code>, <code>^</code>, <code>%/%</code>, <code>%%</code>: arithmetic ops</li> <li><code>log()</code>, <code>log2()</code>, <code>log10()</code>: logs</li> <li><code>&lt;</code>, <code>&lt;=</code>, <code>&gt;</code>, <code>&gt;=</code>, <code>!=</code>, <code>==</code>: logical comparisons</li> <li><code>dplyr::between()</code>: x &gt;= left &amp; x &lt;= right</li> <li><code>dplyr::near()</code>: safe <code>==</code> for floating point numbers</li> </ul>"},{"location":"examples/dplyr/dplyr/#miscellaneous","title":"Miscellaneous\u00b6","text":"<ul> <li><p><code>dplyr::case_when()</code>: multi-case <code>if_else()</code></p> <pre><code>starwars |&gt;\n  mutate(type = case_when(\n    height &gt; 200 | mass &gt; 200 ~ \"large\",\n    species == \"Droid\" ~ \"robot\",\n    TRUE ~ \"other\"\n  ))</code></pre> </li> <li><p><code>dplyr::coalesce()</code>: first non-NA values by element across a set of vectors</p> </li> <li><p><code>dplyr::if_else()</code>: element-wise if() + else()</p> </li> <li><p><code>dplyr::na_if()</code>: replace specific values with NA</p> </li> <li><p><code>pmax()</code>: element-wise max()</p> </li> <li><p><code>pmin()</code>: element-wise min()</p> </li> </ul>"},{"location":"examples/dplyr/dplyr/#summary-functions","title":"Summary Functions\u00b6","text":""},{"location":"examples/dplyr/dplyr/#to-use-with-summarize","title":"To Use with <code>summarize()</code>\u00b6","text":"<p><code>summarize()</code> applies summary functions to columns to create a new table. Summary functions take vectors as input and return single values as output.</p>"},{"location":"examples/dplyr/dplyr/#count","title":"Count\u00b6","text":"<ul> <li><code>dplyr::n()</code>: number of values/rows</li> <li><code>dplyr::n_distinct()</code>: # of uniques</li> <li><code>sum(!is.na())</code>: # of non-NAs</li> </ul>"},{"location":"examples/dplyr/dplyr/#position","title":"Position\u00b6","text":"<ul> <li><code>mean()</code>: mean, also <code>mean(!is.na())</code></li> <li><code>median()</code>: median</li> </ul>"},{"location":"examples/dplyr/dplyr/#logical","title":"Logical\u00b6","text":"<ul> <li><code>mean()</code>: proportion of TRUEs</li> <li><code>sum()</code>: # of TRUEs</li> </ul>"},{"location":"examples/dplyr/dplyr/#order","title":"Order\u00b6","text":"<ul> <li><code>dplyr::first()</code>: first value</li> <li><code>dplyr::last()</code>: last value</li> <li><code>dplyr::nth()</code>: value in the nth location of vector</li> </ul>"},{"location":"examples/dplyr/dplyr/#rank","title":"Rank\u00b6","text":"<ul> <li><code>quantile()</code>: nth quantile</li> <li><code>min()</code>: minimum value</li> <li><code>max()</code>: maximum value</li> </ul>"},{"location":"examples/dplyr/dplyr/#spread","title":"Spread\u00b6","text":"<ul> <li><code>IQR()</code>: Inter-Quartile Range</li> <li><code>mad()</code>: median absolute deviation</li> <li><code>sd()</code>: standard deviation</li> <li><code>var()</code>: variance</li> </ul>"},{"location":"examples/dplyr/dplyr/#row-names","title":"Row Names\u00b6","text":"<p>Tidy data does not use rownames, which store a variable outside of the columns. To work with the rownames, first move them into a column.</p> <ul> <li><code>tibble::rownames_to_column()</code>: Move row names into col.</li> </ul>"},{"location":"examples/dplyr/dplyr/#combine-tables","title":"Combine Tables\u00b6","text":""},{"location":"examples/dplyr/dplyr/#combine-variables","title":"Combine Variables\u00b6","text":"<ul> <li><code>bind_cols(..., .name_repair)</code>: Returns tables placed side by side as a single table. Column lengths must be equal. Columns will NOT be matched by id (to do that look at Relational Data below), so be sure to check that both tables are ordered the way you want before binding.</li> </ul>"},{"location":"examples/dplyr/dplyr/#combine-cases","title":"Combine Cases\u00b6","text":"<ul> <li><code>bind_rows(..., .id = NULL)</code>: Returns tables one on top of the other as a single table. Set <code>.id</code> to a column name to add a column of the original table names.</li> </ul>"},{"location":"examples/dplyr/dplyr/#relational-data","title":"Relational Data\u00b6","text":"<p>Use a \u201cMutating Join\u201d to join one table to columns from another, matching values with the rows that the correspond to. Each join retains a different combination of values from the tables.</p> <ul> <li><code>left_join(x, y, by = NULL, copy = FALSE, suffix = c(\".x\", \".y\"), ..., keep = FALSE, na_matches = \"na\")</code>: Join matching values from <code>y</code> to <code>x</code>.</li> <li><code>right_join(x, y, by = NULL, copy = FALSE, suffix = c(\".x\", \".y\"), ..., keep = FALSE, na_matches = \"na\")</code>: Join matching values from <code>x</code> to <code>y</code>.</li> <li><code>inner_join(x, y, by = NULL, copy = FALSE, suffix = c(\".x\", \".y\"), ..., keep = FALSE, na_matches = \"na\")</code>: Join data. retain only rows with matches.</li> <li><code>full_join(x, y, by = NULL, copy = FALSE, suffix = c(\".x\", \".y\"), ..., keep = FALSE, na_matches = \"na\")</code>: Join data. Retain all values, all rows.</li> </ul> <p>Use a \u201cFiltering Join\u201d to filter one table against the rows of another.</p> <ul> <li><code>semi_join(x, y, by = NULL, copy = FALSE, ..., na_matches = \"na\")</code>: Return rows of <code>x</code> that have a match in <code>y</code>. Use to see what will be included in a join.</li> <li><code>anti_join(x, y, by = NULL, copy = FALSE, ..., na_matches = \"na\")</code>: Return rows of <code>x</code> that do not have a match in <code>y</code>. Use to see what will not be included in a join.</li> </ul> <p>Use a \u201cNest Join\u201d to inner join one table to another into a nested data frame.</p> <ul> <li><code>nest_join(x, y, by = NULL, copy = FALSE, keep = FALSE, name = NULL, ...)</code>: Join data, nesting matches from <code>y</code> in a single new data frame column.</li> </ul>"},{"location":"examples/dplyr/dplyr/#column-matching-for-joins","title":"Column Matching for Joins\u00b6","text":"<ul> <li>Use <code>by = join_by(col1, col2, \u2026)</code> to specify one or more common columns to match on.</li> </ul>"},{"location":"examples/dplyr/dplyr/#set-operations","title":"Set Operations\u00b6","text":"<ul> <li><code>intersect(x, y, ...)</code>: Rows that appear in both <code>x</code> and <code>y</code>.</li> <li><code>setdiff(x, y, ...)</code>: Rows that appear in <code>x</code> but not <code>y</code>.</li> <li><code>union(x, y, ...)</code>: Rows that appear in x or y, duplicates removed. <code>union_all()</code> retains duplicates.</li> <li>Use <code>setequal()</code> to test whether two data sets contain the exact same rows (in any order).</li> </ul>"},{"location":"examples/forcats/app/","title":"App","text":"In\u00a0[\u00a0]: Copied! <pre>import streamlit as st\nfrom pathlib import Path\nimport base64\nimport requests\n</pre> import streamlit as st from pathlib import Path import base64 import requests In\u00a0[\u00a0]: Copied! <pre># Initial page config\nst.set_page_config(\n    page_title='Forcats Cheat Sheet',\n    layout=\"wide\",\n    initial_sidebar_state=\"expanded\",\n)\n</pre> # Initial page config st.set_page_config(     page_title='Forcats Cheat Sheet',     layout=\"wide\",     initial_sidebar_state=\"expanded\", ) In\u00a0[\u00a0]: Copied! <pre>def main():\n    \"\"\"\n    Main function to set up the Streamlit app layout.\n    \"\"\"\n    cs_sidebar()\n    cs_body()\n    return None\n</pre> def main():     \"\"\"     Main function to set up the Streamlit app layout.     \"\"\"     cs_sidebar()     cs_body()     return None In\u00a0[\u00a0]: Copied! <pre># Define img_to_bytes() function\ndef img_to_bytes(img_url):\n    response = requests.get(img_url)\n    img_bytes = response.content\n    encoded = base64.b64encode(img_bytes).decode()\n    return encoded\n</pre> # Define img_to_bytes() function def img_to_bytes(img_url):     response = requests.get(img_url)     img_bytes = response.content     encoded = base64.b64encode(img_bytes).decode()     return encoded In\u00a0[\u00a0]: Copied! <pre># Define the cs_sidebar() function\ndef cs_sidebar():\n    \"\"\"\n    Populate the sidebar with various content sections related to forcats.\n    \"\"\"\n    st.sidebar.markdown(\n        '''[&lt;img src='data:image/png;base64,{}' class='img-fluid' width=95 &gt;](https://streamlit.io/)'''.format(\n            img_to_bytes(\"https://rstudio.github.io/cheatsheets/html/images/logo-forcats.png\")), unsafe_allow_html=True)\n\n    st.sidebar.header('Forcats Cheat Sheet')\n    st.sidebar.markdown('''\n&lt;small&gt;The [forcats](https://forcats.tidyverse.org/) package provides tools for working with factors, which are R\u2019s data structure for categorical data.\n&lt;/small&gt;\n    ''', unsafe_allow_html=True)\n\n    # forcats installation and import\n    st.sidebar.markdown('__Install and import forcats__')\n    st.sidebar.code('''$ install.packages('forcats')''')\n    st.sidebar.code('''\n# Import forcats \n&gt;&gt;&gt; library(forcats)\n''')\n\n\n    return None\n</pre> # Define the cs_sidebar() function def cs_sidebar():     \"\"\"     Populate the sidebar with various content sections related to forcats.     \"\"\"     st.sidebar.markdown(         '''[](https://streamlit.io/)'''.format(             img_to_bytes(\"https://rstudio.github.io/cheatsheets/html/images/logo-forcats.png\")), unsafe_allow_html=True)      st.sidebar.header('Forcats Cheat Sheet')     st.sidebar.markdown(''' The [forcats](https://forcats.tidyverse.org/) package provides tools for working with factors, which are R\u2019s data structure for categorical data.      ''', unsafe_allow_html=True)      # forcats installation and import     st.sidebar.markdown('__Install and import forcats__')     st.sidebar.code('''$ install.packages('forcats')''')     st.sidebar.code(''' # Import forcats  &gt;&gt;&gt; library(forcats) ''')       return None In\u00a0[\u00a0]: Copied! <pre># Define the cs_body() function\ndef cs_body():\n    \"\"\"\n    Create content sections for the main body of the Streamlit cheat sheet with forcats examples.\n    \"\"\"\n    col1, col2, col3 = st.columns(3)  # Create columns for layout\n\n    #######################################\n    # COLUMN 1\n    #######################################\n\n    # Factors\n    col1.subheader('Factors')\n    col1.markdown('''\n    R represents categorical data with factors. A **factor** is an integer vector with a **levels** attribute that stores a set of mappings between integers and categorical values. When you view a factor, R displays not the integers but the levels associated with them.\n    \n    For example, R will display `c(\"a\", \"c\", \"b\", \"a\")` with levels `c(\"a\", \"b\", \"c\")` but will store `c(1, 3, 2, 1)` where 1 = a, 2 = b, and 3 = c.\n        ''')\n    col1.code('''\n        # R will display:\n        [1] a c b a\n        Levels: a b c\n        ''')\n    col1.code('''\n        # R will store:\n        [1] 1 3 2 1\n        attr(,\"levels\")\n        [1] \"a\" \"b\" \"c\"\n        ''')\n\n\n    col1.subheader('''Create a factor with `factor()`''')\n    col1.code('''\n    # Convert a vector to a factor. Also as_factor().\n    f &lt;- factor(c(\"a\", \"c\", \"b\", \"a\"), levels = c(\"a\", \"b\", \"c\"))\n    ''')\n    col1.code('''\n    # Return/set the levels of a factor.\n    levels(f)\n    levels(f) &lt;- c(\"x\", \"y\", \"z\")\n    ''')\n\n    # Inspect Factors\n    col1.subheader('''Inspect Factors''')\n    col1.code('''\n    # Count the number of values with each level.\n    fct_match(f, \"a\")\n    ''')\n    col1.code('''\n    # Check for lvls in f.\n    fct_count(f)\n    ''')\n    col1.code('''\n    # Return the unique values, removing duplicates.\n    fct_unique(f)\n    ''')\n\n\n    #######################################\n    # COLUMN 2\n    #######################################\n\n    # Combine Factors\n    col2.subheader('''Combine Factors''')\n    col2.code('''\n            # Combine factors with different levels. Also fct_cross().\n            f1 &lt;- factor(c(\"a\", \"c\"))\n            f2 &lt;- factor(c(\"b\", \"a\"))\n            fct_c(f1, f2)\n                ''')\n    col2.code('''\n            # Standardize levels across a list of factors.\n            fct_unify(list(f2, f1))\n                ''')\n\n    # Change the order of levels\n    col2.subheader('''Change the order of levels''')\n    col2.code('''\n            # Manually reorder factor levels.\n            fct_relevel(f, c(\"b\", \"c\", \"a\"))\n                ''')\n    col2.code('''\n            # Reorder levels by the frequency in which they appear in the data (highest frequency first).\n            f3 &lt;- factor(c(\"c\", \"c\", \"a\"))\n            fct_infreq(f3)\n                ''')\n    col2.code('''\n            #  Reverse level order.\n            f4 &lt;- factor(c(\"a\",\"b\",\"c\"))\n            fct_rev(f4)\n                ''')\n    col2.code('''\n            # Shift levels to left or right, wrapping around end.\n            fct_shift(f4)\n                ''')\n    col2.code('''\n            # Randomly permute order of factor levels.\n            fct_shuffle(f4)\n                ''')\n    col2.code('''\n            # Reorder levels by their relationship with another variable.\n            boxplot(PlantGrowth, weight ~ fct_reorder(group, weight))\n                ''')\n    col2.code('''\n            # Reorder levels by their final values when plotted with two other variables.\n            ggplot(\n                diamonds,aes(carat, price, \n                color = fct_reorder2(color, carat, price))\n                ) + geom_smooth()\n                ''')\n\n    #######################################\n    # COLUMN 3\n    #######################################\n\n    # Change the value of levels\n    col3.subheader('Change the value of levels')\n    col3.code('''\n        # Manually change levels.\n        fct_recode(f, v = \"a\", x = \"b\", z = \"c\")\n        fct_relabel(f, ~ paste0(\"x\", .x))\n            ''')\n    col3.code('''\n        # Anonymize levels with random integers.\n        fct_anon(f)\n            ''')\n    col3.code('''\n        # Collapse levels into manually defined groups.\n        fct_collapse(f, x = c(\"a\", \"b\"))\n            ''')\n    col3.code('''\n        #  Lumps together factors that appear fewer than min times.\n        fct_lump_min(f, min = 2)\n            ''')\n    col3.code('''\n        # Replace levels with \u201cother.\u201d\n        fct_other(f, keep = c(\"a\", \"b\"))\n            ''')\n\n    # Add or drop levels\n    col3.subheader('''Add or drop levels''')\n    col3.code('''\n        # Drop unused levels.\n        f5 &lt;- factor(c(\"a\",\"b\"),c(\"a\",\"b\",\"x\"))\n        f6 &lt;- fct_drop(f5)\n            ''')\n    col3.code('''\n        # Add levels to a factor.\n        fct_expand(f6, \"x\")\n            ''')\n    col3.code('''\n        # Assigns a level to NAs to ensure they appear in plots, etc.\n        f &lt;- factor(c(\"a\", \"b\", NA))\n        fct_na_value_to_level(\n            f, \n            level = \"(Missing)\"\n        )\n            ''')\n</pre> # Define the cs_body() function def cs_body():     \"\"\"     Create content sections for the main body of the Streamlit cheat sheet with forcats examples.     \"\"\"     col1, col2, col3 = st.columns(3)  # Create columns for layout      #######################################     # COLUMN 1     #######################################      # Factors     col1.subheader('Factors')     col1.markdown('''     R represents categorical data with factors. A **factor** is an integer vector with a **levels** attribute that stores a set of mappings between integers and categorical values. When you view a factor, R displays not the integers but the levels associated with them.          For example, R will display `c(\"a\", \"c\", \"b\", \"a\")` with levels `c(\"a\", \"b\", \"c\")` but will store `c(1, 3, 2, 1)` where 1 = a, 2 = b, and 3 = c.         ''')     col1.code('''         # R will display:         [1] a c b a         Levels: a b c         ''')     col1.code('''         # R will store:         [1] 1 3 2 1         attr(,\"levels\")         [1] \"a\" \"b\" \"c\"         ''')       col1.subheader('''Create a factor with `factor()`''')     col1.code('''     # Convert a vector to a factor. Also as_factor().     f &lt;- factor(c(\"a\", \"c\", \"b\", \"a\"), levels = c(\"a\", \"b\", \"c\"))     ''')     col1.code('''     # Return/set the levels of a factor.     levels(f)     levels(f) &lt;- c(\"x\", \"y\", \"z\")     ''')      # Inspect Factors     col1.subheader('''Inspect Factors''')     col1.code('''     # Count the number of values with each level.     fct_match(f, \"a\")     ''')     col1.code('''     # Check for lvls in f.     fct_count(f)     ''')     col1.code('''     # Return the unique values, removing duplicates.     fct_unique(f)     ''')       #######################################     # COLUMN 2     #######################################      # Combine Factors     col2.subheader('''Combine Factors''')     col2.code('''             # Combine factors with different levels. Also fct_cross().             f1 &lt;- factor(c(\"a\", \"c\"))             f2 &lt;- factor(c(\"b\", \"a\"))             fct_c(f1, f2)                 ''')     col2.code('''             # Standardize levels across a list of factors.             fct_unify(list(f2, f1))                 ''')      # Change the order of levels     col2.subheader('''Change the order of levels''')     col2.code('''             # Manually reorder factor levels.             fct_relevel(f, c(\"b\", \"c\", \"a\"))                 ''')     col2.code('''             # Reorder levels by the frequency in which they appear in the data (highest frequency first).             f3 &lt;- factor(c(\"c\", \"c\", \"a\"))             fct_infreq(f3)                 ''')     col2.code('''             #  Reverse level order.             f4 &lt;- factor(c(\"a\",\"b\",\"c\"))             fct_rev(f4)                 ''')     col2.code('''             # Shift levels to left or right, wrapping around end.             fct_shift(f4)                 ''')     col2.code('''             # Randomly permute order of factor levels.             fct_shuffle(f4)                 ''')     col2.code('''             # Reorder levels by their relationship with another variable.             boxplot(PlantGrowth, weight ~ fct_reorder(group, weight))                 ''')     col2.code('''             # Reorder levels by their final values when plotted with two other variables.             ggplot(                 diamonds,aes(carat, price,                  color = fct_reorder2(color, carat, price))                 ) + geom_smooth()                 ''')      #######################################     # COLUMN 3     #######################################      # Change the value of levels     col3.subheader('Change the value of levels')     col3.code('''         # Manually change levels.         fct_recode(f, v = \"a\", x = \"b\", z = \"c\")         fct_relabel(f, ~ paste0(\"x\", .x))             ''')     col3.code('''         # Anonymize levels with random integers.         fct_anon(f)             ''')     col3.code('''         # Collapse levels into manually defined groups.         fct_collapse(f, x = c(\"a\", \"b\"))             ''')     col3.code('''         #  Lumps together factors that appear fewer than min times.         fct_lump_min(f, min = 2)             ''')     col3.code('''         # Replace levels with \u201cother.\u201d         fct_other(f, keep = c(\"a\", \"b\"))             ''')      # Add or drop levels     col3.subheader('''Add or drop levels''')     col3.code('''         # Drop unused levels.         f5 &lt;- factor(c(\"a\",\"b\"),c(\"a\",\"b\",\"x\"))         f6 &lt;- fct_drop(f5)             ''')     col3.code('''         # Add levels to a factor.         fct_expand(f6, \"x\")             ''')     col3.code('''         # Assigns a level to NAs to ensure they appear in plots, etc.         f &lt;- factor(c(\"a\", \"b\", NA))         fct_na_value_to_level(             f,              level = \"(Missing)\"         )             ''') In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre># Run the main function if the script is executed directly\nif __name__ == '__main__':\n    main()\n</pre> # Run the main function if the script is executed directly if __name__ == '__main__':     main()"},{"location":"examples/forcats/forcats/","title":"Forcats","text":"In\u00a0[\u00a0]: Copied! <pre>library(forcats)\n</pre> library(forcats) In\u00a0[\u00a0]: Copied! <pre>f &lt;- factor(c(\"a\", \"c\", \"b\", \"a\"), levels = c(\"a\", \"b\", \"c\"))\n</pre> f &lt;- factor(c(\"a\", \"c\", \"b\", \"a\"), levels = c(\"a\", \"b\", \"c\")) <p>Return its levels with <code>levels()</code>:</p> <ul> <li><code>levels(x)</code>: Return/set the levels of a factor.</li> </ul> In\u00a0[\u00a0]: Copied! <pre>levels(f)\nlevels(f) &lt;- c(\"x\", \"y\", \"z\")\n</pre> levels(f) levels(f) &lt;- c(\"x\", \"y\", \"z\") <p>Use <code>unclass()</code> to see its structure.</p> In\u00a0[\u00a0]: Copied! <pre>fct_count(f)\n</pre> fct_count(f) <ul> <li><code>fct_match(f, lvls)</code>: Check for <code>lvls</code> in <code>f</code>.</li> </ul> In\u00a0[\u00a0]: Copied! <pre>fct_match(f, \"a\")\n</pre> fct_match(f, \"a\") <ul> <li><code>fct_unique(f)</code>: Return the unique values, removing duplicates.</li> </ul> In\u00a0[\u00a0]: Copied! <pre>fct_unique(f)\n</pre> fct_unique(f)  In\u00a0[\u00a0]: Copied! <pre>f1 &lt;- factor(c(\"a\", \"c\"))\nf2 &lt;- factor(c(\"b\", \"a\"))\nfct_c(f1, f2)\n</pre> f1 &lt;- factor(c(\"a\", \"c\")) f2 &lt;- factor(c(\"b\", \"a\")) fct_c(f1, f2) <ul> <li><code>fct_unify(fs, levels = lvls_union(fs))</code>: Standardize levels across a list of factors.</li> </ul> In\u00a0[\u00a0]: Copied! <pre>fct_unify(list(f2, f1))\n</pre> fct_unify(list(f2, f1)) In\u00a0[\u00a0]: Copied! <pre>fct_relevel(f, c(\"b\", \"c\", \"a\"))\n</pre> fct_relevel(f, c(\"b\", \"c\", \"a\")) <ul> <li><code>fct_infreq(f, ordered = NA)</code>: Reorder levels by the frequency in which they appear in the data (highest frequency first). Also <code>fct_inseq()</code>.</li> </ul> In\u00a0[\u00a0]: Copied! <pre>f3 &lt;- factor(c(\"c\", \"c\", \"a\"))\nfct_infreq(f3)\n</pre> f3 &lt;- factor(c(\"c\", \"c\", \"a\")) fct_infreq(f3) <ul> <li><code>fct_inorder(f, ordered = NA)</code>: Reorder levels by order in which they appear in the data.</li> </ul> In\u00a0[\u00a0]: Copied! <pre>fct_inorder(f2)\n</pre> fct_inorder(f2) <ul> <li><code>fct_rev(f)</code>: Reverse level order.</li> </ul> In\u00a0[\u00a0]: Copied! <pre>f4 &lt;- factor(c(\"a\",\"b\",\"c\"))\nfct_rev(f4)\n</pre> f4 &lt;- factor(c(\"a\",\"b\",\"c\")) fct_rev(f4) <ul> <li><code>fct_shift(f)</code>: Shift levels to left or right, wrapping around end.</li> </ul> In\u00a0[\u00a0]: Copied! <pre>fct_shift(f4)\n</pre> fct_shift(f4) <ul> <li><code>fct_shuffle(f, n = 1L)</code>: Randomly permute order of factor levels.</li> </ul> In\u00a0[\u00a0]: Copied! <pre>fct_shuffle(f4)\n</pre> fct_shuffle(f4)     <ul> <li><code>fct_reorder(.f, .x, .fun = median, ..., .desc = FALSE)</code>: Reorder levels by their relationship with another variable.</li> </ul> In\u00a0[\u00a0]: Copied! <pre>boxplot(PlantGrowth, weight ~ fct_reorder(group, weight))\n</pre> boxplot(PlantGrowth, weight ~ fct_reorder(group, weight)) <ul> <li><code>fct_reorder2(.f, .x, .y, .fun = last2, ..., .desc = TRUE)</code>: Reorder levels by their final values when plotted with two other variables.</li> </ul> In\u00a0[\u00a0]: Copied! <pre>ggplot(\n  diamonds,\n  aes(carat, price, color = fct_reorder2(color, carat, price))\n  ) + \n  geom_smooth()\n</pre> ggplot(   diamonds,   aes(carat, price, color = fct_reorder2(color, carat, price))   ) +    geom_smooth() In\u00a0[\u00a0]: Copied! <pre>fct_recode(f, v = \"a\", x = \"b\", z = \"c\")\nfct_relabel(f, ~ paste0(\"x\", .x))\n</pre> fct_recode(f, v = \"a\", x = \"b\", z = \"c\") fct_relabel(f, ~ paste0(\"x\", .x)) <ul> <li><code>fct_anon(f, prefix = \"\")</code>: Anonymize levels with random integers.</li> </ul> In\u00a0[\u00a0]: Copied! <pre>fct_anon(f)\n</pre> fct_anon(f) <ul> <li><code>fct_collapse(.f, \u2026, other_level = NULL)</code>: Collapse levels into manually defined groups.</li> </ul> In\u00a0[\u00a0]: Copied! <pre>fct_collapse(f, x = c(\"a\", \"b\"))\n</pre> fct_collapse(f, x = c(\"a\", \"b\")) <ul> <li><code>fct_lump_min(f, min, w = NULL, other_level = \"Other\")</code>: Lumps together factors that appear fewer than <code>min</code> times. Also <code>fct_lump_n()</code>, <code>fct_lump_prop()</code>, and <code>fct_lump_lowfreq()</code>.</li> </ul> In\u00a0[\u00a0]: Copied! <pre>fct_lump_min(f, min = 2)\n</pre> fct_lump_min(f, min = 2)     <ul> <li><code>fct_other(f, keep, drop, other_level = \"Other\")</code>: Replace levels with \u201cother.\u201d</li> </ul> In\u00a0[\u00a0]: Copied! <pre>fct_other(f, keep = c(\"a\", \"b\"))\n</pre> fct_other(f, keep = c(\"a\", \"b\"))     In\u00a0[\u00a0]: Copied! <pre>f5 &lt;- factor(c(\"a\",\"b\"),c(\"a\",\"b\",\"x\"))\nf6 &lt;- fct_drop(f5)\n</pre> f5 &lt;- factor(c(\"a\",\"b\"),c(\"a\",\"b\",\"x\")) f6 &lt;- fct_drop(f5) <ul> <li><code>fct_expand(f, ...)</code>: Add levels to a factor.</li> </ul> In\u00a0[\u00a0]: Copied! <pre>fct_expand(f6, \"x\")\n</pre> fct_expand(f6, \"x\") <ul> <li><code>fct_na_value_to_level(f, level = \"(Missing)\")</code>: Assigns a level to NAs to ensure they appear in plots, etc.</li> </ul> In\u00a0[\u00a0]: Copied! <pre>f &lt;- factor(c(\"a\", \"b\", NA))\nfct_na_value_to_level(f, level = \"(Missing)\")\n</pre> f &lt;- factor(c(\"a\", \"b\", NA)) fct_na_value_to_level(f, level = \"(Missing)\")"},{"location":"examples/forcats/forcats/#forcats","title":"Forcats\u00b6","text":"<p>The forcats package provides tools for working with factors, which are R\u2019s data structure for categorical data.</p>"},{"location":"examples/forcats/forcats/#factors","title":"Factors\u00b6","text":"<p>R represents categorical data with factors. A factor is an integer vector with a levels attribute that stores a set of mappings between integers and categorical values. When you view a factor, R displays not the integers but the levels associated with them.</p> <p>For example, R will display <code>c(\"a\", \"c\", \"b\", \"a\")</code> with levels <code>c(\"a\", \"b\", \"c\")</code> but will store <code>c(1, 3, 2, 1)</code> where 1 = a, 2 = b, and 3 = c.</p> <p>R will display:</p> <pre>[1] a c b a\nLevels: a b c\n</pre> <p>R will store:</p> <pre>[1] 1 3 2 1\nattr(,\"levels\")\n[1] \"a\" \"b\" \"c\"\n</pre> <p>Create a factor with <code>factor()</code>:</p> <ul> <li><code>factor(x = character(), levels, labels = levels, exclude = NA, ordered = is.ordered(x), nmax = NA)</code>: Convert a vector to a factor. Also <code>as_factor()</code>.</li> </ul>"},{"location":"examples/forcats/forcats/#inspect-factors","title":"Inspect Factors\u00b6","text":"<ul> <li><code>fct_count(f, sort = FALSE, prop = FALSE)</code>: Count the number of values with each level.</li> </ul>"},{"location":"examples/forcats/forcats/#combine-factors","title":"Combine Factors\u00b6","text":"<ul> <li><code>fct_c(...)</code>: Combine factors with different levels. Also <code>fct_cross()</code>.</li> </ul>"},{"location":"examples/forcats/forcats/#change-the-order-of-levels","title":"Change the order of levels\u00b6","text":"<ul> <li><code>fct_relevel(.f, ..., after = 0L)</code>: Manually reorder factor levels.</li> </ul>"},{"location":"examples/forcats/forcats/#change-the-value-of-levels","title":"Change the value of levels\u00b6","text":"<ul> <li><code>fct_recode(.f, ...)</code>: Manually change levels. Also <code>fct_relabel()</code> which obeys <code>purrr::map</code> syntax to apply a function or expression to each level.</li> </ul>"},{"location":"examples/forcats/forcats/#add-or-drop-levels","title":"Add or drop levels\u00b6","text":"<ul> <li><code>fct_drop(f, only)</code>: Drop unused levels.</li> </ul>"},{"location":"examples/ggplot2/app/","title":"App","text":"In\u00a0[\u00a0]: Copied! <pre>import streamlit as st\nfrom pathlib import Path\nimport base64\nimport requests\n</pre> import streamlit as st from pathlib import Path import base64 import requests In\u00a0[\u00a0]: Copied! <pre># Initial page config\nst.set_page_config(\n    page_title='Ggplot2 Cheat Sheet',\n    layout=\"wide\",\n    initial_sidebar_state=\"expanded\",\n)\n</pre> # Initial page config st.set_page_config(     page_title='Ggplot2 Cheat Sheet',     layout=\"wide\",     initial_sidebar_state=\"expanded\", ) In\u00a0[\u00a0]: Copied! <pre>def main():\n    \"\"\"\n    Main function to set up the Streamlit app layout.\n    \"\"\"\n    cs_sidebar()\n    cs_body()\n    return None\n</pre> def main():     \"\"\"     Main function to set up the Streamlit app layout.     \"\"\"     cs_sidebar()     cs_body()     return None In\u00a0[\u00a0]: Copied! <pre># Define img_to_bytes() function\ndef img_to_bytes(img_url):\n    response = requests.get(img_url)\n    img_bytes = response.content\n    encoded = base64.b64encode(img_bytes).decode()\n    return encoded\n</pre> # Define img_to_bytes() function def img_to_bytes(img_url):     response = requests.get(img_url)     img_bytes = response.content     encoded = base64.b64encode(img_bytes).decode()     return encoded In\u00a0[\u00a0]: Copied! <pre># Define the cs_sidebar() function\ndef cs_sidebar():\n    \"\"\"\n    Populate the sidebar with various content sections related to ggplot2.\n    \"\"\"\n    st.sidebar.markdown(\n        '''[&lt;img src='data:image/png;base64,{}' class='img-fluid' width=95 &gt;](https://streamlit.io/)'''.format(\n            img_to_bytes(\"https://rstudio.github.io/cheatsheets/html/images/logo-ggplot2.png\")), unsafe_allow_html=True)\n\n    st.sidebar.header('Ggplot2 Cheat Sheet')\n    st.sidebar.markdown('''\n&lt;small&gt;[ggplot2](https://ggplot2.tidyverse.org/) is based on the **grammar of graphics**, the idea that you can build every graph from the same components: a **data** set, a **coordinate system**, and **geoms**\u2014visual marks that represent data points.&lt;/small&gt;\n    ''', unsafe_allow_html=True)\n\n    # ggplot2 installation and import\n    st.sidebar.markdown('__Install and import ggplot2__')\n    st.sidebar.code('''$ install.packages('ggplot2')''')\n    st.sidebar.code('''\n# Import ggplot2 \n&gt;&gt;&gt; library(ggplot2)\n''')\n\n\n\n\n    return None\n</pre> # Define the cs_sidebar() function def cs_sidebar():     \"\"\"     Populate the sidebar with various content sections related to ggplot2.     \"\"\"     st.sidebar.markdown(         '''[](https://streamlit.io/)'''.format(             img_to_bytes(\"https://rstudio.github.io/cheatsheets/html/images/logo-ggplot2.png\")), unsafe_allow_html=True)      st.sidebar.header('Ggplot2 Cheat Sheet')     st.sidebar.markdown(''' [ggplot2](https://ggplot2.tidyverse.org/) is based on the **grammar of graphics**, the idea that you can build every graph from the same components: a **data** set, a **coordinate system**, and **geoms**\u2014visual marks that represent data points.     ''', unsafe_allow_html=True)      # ggplot2 installation and import     st.sidebar.markdown('__Install and import ggplot2__')     st.sidebar.code('''$ install.packages('ggplot2')''')     st.sidebar.code(''' # Import ggplot2  &gt;&gt;&gt; library(ggplot2) ''')         return None In\u00a0[\u00a0]: Copied! <pre># Define the cs_body() function\ndef cs_body():\n    \"\"\"\n    Create content sections for the main body of the Streamlit cheat sheet with ggplot2 examples.\n    \"\"\"\n    col1, col2, col3 = st.columns(3)  # Create columns for layout\n\n    #######################################\n    # COLUMN 1\n    #######################################\n    col1.subheader('Basic')\n    col1.code('''\n        # Complete the template below to build a graph.\n        ggplot(data = &lt;Data&gt;) +\n            &lt;Geom_Function&gt;(mapping = aes(&lt;Mappings&gt;),\n            stat = &lt;Stat&gt;,\n            position = &lt;Position&gt;) +\n            &lt;Coordinate_Function&gt; +\n            &lt;Facet_Function&gt; +\n            &lt;Scale_Function&gt; +\n            &lt;Theme_Function&gt;\n        ''')\n\n    col1.markdown('''\n    *   `ggplot(data = mpg, aes(x = cty, y = hwy))`: Begins a plot that you finish by adding layers to. Add one geom function per layer.\n\n    *   `last_plot()`: Returns the last plot.\n\n    *   `ggsave(\"plot.png\", width = 5, height = 5)`: Saves last plot as 5\u2019 x 5\u2019 file named \u201cplot.png\u201d in working directory. Matches file type to file extension.\n                ''')\n\n    # Aes\n    col1.subheader('Aes')\n    col1.markdown('''\nCommon aesthetic values.\n\n*   `color` and `fill`: String (`\"red\"`, `\"#RRGGBB\"`).\n    \n*   `linetype`: Integer or string (0 = `\"blank\"`, 1 = `\"solid\"`, 2 = `\"dashed\"`, 3 = `\"dotted\"`, 4 = `\"dotdash\"`, 5 = `\"longdash\"`, 6 = `\"twodash\"`).\n    \n*   `size`: Integer (line width in mm for outlines).\n    \n*   `linewidth`: Integer (line width in mm for lines).\n    \n*   `shape`: Integer/shape name or a single character (`\"a\"`).\n        ''')\n\n    # Graphical Primitives\n    col1.subheader('Graphical Primitives')\n    col1.code('''\n    a &lt;- ggplot(economics, aes(date, unemploy))\n    b &lt;- ggplot(seals, aes(x = long, y = lat))\n    ''')\n\n\n    col1.subheader('''One Variable - Continuous''')\n    col1.code('''\n           c &lt;- ggplot(mpg, aes(hwy))\n           c2 &lt;- ggplot(mpg)\n                ''')\n\n\n    col1.subheader('''One Variable - Discrete''')\n    col1.code('''\n               d &lt;- ggplot(mpg, aes(fl))\n                    ''')\n\n\n    col1.subheader('''Two Variables - Both Continuous''')\n    col1.code('''\n               e &lt;- ggplot(mpg, aes(cty, hwy))\n                    ''')\n\n    col1.subheader('''Two Variables - One Discrete, One Continuous''')\n    col1.code('''\n               f &lt;- ggplot(mpg, aes(class, hwy))\n                    ''')\n\n\n    #######################################\n    # COLUMN 2\n    #######################################\n\n\n    # Logical\n    col2.subheader('''Two Variables - Both Discrete''')\n    col2.code('''\n               g &lt;- ggplot(diamonds, aes(cut, color))\n                    ''')\n\n    col2.subheader('''Two Variables - Continuous Bivariate Distribution''')\n    col2.code('''\n              h &lt;- ggplot(diamonds, aes(carat, price))\n                    ''')\n\n    col2.subheader('''Two Variables - Continuous Function''')\n    col2.code('''\n             i &lt;- ggplot(economics, aes(date, unemploy))\n                    ''')\n\n    col2.subheader('''Two Variables - Visualizing Error''')\n    col2.code('''\n             Two Variables - Visualizing Error\n                    ''')\n\n    col2.subheader('''Two Variables - Maps''')\n    col2.code('''\n             murder_data &lt;- data.frame(\n                    murder = USArrests$Murder, \n                    state = tolower(rownames(USArrests))\n            )\n            map &lt;- map_data(\"state\")\n            k &lt;- ggplot(murder_data, aes(fill = murder))\n                    ''')\n\n    col2.subheader('''Three Variables''')\n    col2.code('''\n             seals$z &lt;- with(seals, sqrt(delta_long^2 + delta_lat^2))\n             l &lt;- ggplot(seals, aes(long, lat))\n                    ''')\n\n    col2.subheader('''Stats''')\n    col2.markdown('''\n    An alternative way to build a layer. A stat builds new variables to plot (e.g., count, prop).\n    ''')\n    col2.code('''\n             i + stat_density_2d(aes(fill = after_stat(level)), geom = \"polygon\")\n                    ''')\n\n    col2.subheader('''Scales''')\n    col2.markdown('''\n    Scales map data values to the visual values of an aesthetic. To change a mapping, add a new scale.\n    ''')\n    col2.code('''\nn &lt;- d + geom_bar(aes(fill = fl))\n\nn + scale_fill_manual(\n  value = c(),\n  limits = c(), \n  breaks = c(),\n  name = \"fuel\", \n  labels = c(\"D\", \"E\", \"P\", \"R\")\n)\n                    ''')\n\n\n\n    #######################################\n    # COLUMN 3\n    #######################################\n\n    # Row Names\n    col3.subheader('''Color and Fill Scales (Continuous)''')\n    col3.code('''\no &lt;- c + geom_dotplot(aes(fill = ..x..))\n                    ''')\n\n    col3.subheader('''Shape and Size Scales''')\n    col3.code('''\np &lt;- e + geom_point(aes(shape = fl, size = cyl))\n                        ''')\n\n    col3.subheader('''Coordinate Systems''')\n    col3.code('''\nu &lt;- d + geom_bar()\n                        ''')\n\n    col3.subheader('''Position Adjustments''')\n    col3.markdown('''\n    Position adjustments determine how to arrange geoms that would otherwise occupy the same space.\n    ''')\n    col3.code('''\ns &lt;- ggplot(mpg, aes(fl, fill = drv))\n                        ''')\n    col3.code('''\n    s + geom_bar(position = position_dodge(width = 1))\n                            ''')\n\n    col3.subheader('''Themes''')\n\n    col3.code('''\nr + ggtitle(\"Title\") + theme(plot.title.postion = \"plot\")\n\nr + theme(panel.background = element_rect(fill = \"blue\"))\n                            ''')\n\n    col3.subheader('''Faceting''')\n    col3.markdown('''\n    Facets divide a plot into subplots based on the values of one or more discrete variables.\n    ''')\n    col3.code('''\nt &lt;- ggplot(mpg, aes(cty, hwy)) + geom_point()                        ''')\n\n    col3.subheader('''Labels and Legends''')\n    col3.markdown('''\n        Use `labs()` to label elements of your plot.\n        ''')\n    col3.code('''\n    t + labs(x = \"New x axis label\", \n        y = \"New y axis label\",\n        title =\"Add a title above the plot\",\n        subtitle = \"Add a subtitle below title\",\n        caption = \"Add a caption below plot\",\n        alt = \"Add alt text to the plot\",\n        &lt;Aes&gt; = \"New &lt;Aes&gt; legend title\")\n                         ''')\n\n    col3.subheader('''Zooming''')\n    col3.markdown('''\n*   `t + coord_cartesian(xlim = c(0, 100), ylim = c(10,20))`: Zoom without clipping (preferred).\n    \n*   `t + xlim(0, 100) + ylim(10, 20)` or `t + scale_x_continuous(limits = c(0, 100)) + scale_y_continuous(limits = c(0, 100))`: Zoom with clipping (removes unseen data points).\n    \n        ''')\n</pre> # Define the cs_body() function def cs_body():     \"\"\"     Create content sections for the main body of the Streamlit cheat sheet with ggplot2 examples.     \"\"\"     col1, col2, col3 = st.columns(3)  # Create columns for layout      #######################################     # COLUMN 1     #######################################     col1.subheader('Basic')     col1.code('''         # Complete the template below to build a graph.         ggplot(data = ) +             (mapping = aes(),             stat = ,             position = ) +              +              +              +                      ''')      col1.markdown('''     *   `ggplot(data = mpg, aes(x = cty, y = hwy))`: Begins a plot that you finish by adding layers to. Add one geom function per layer.      *   `last_plot()`: Returns the last plot.      *   `ggsave(\"plot.png\", width = 5, height = 5)`: Saves last plot as 5\u2019 x 5\u2019 file named \u201cplot.png\u201d in working directory. Matches file type to file extension.                 ''')      # Aes     col1.subheader('Aes')     col1.markdown(''' Common aesthetic values.  *   `color` and `fill`: String (`\"red\"`, `\"#RRGGBB\"`).      *   `linetype`: Integer or string (0 = `\"blank\"`, 1 = `\"solid\"`, 2 = `\"dashed\"`, 3 = `\"dotted\"`, 4 = `\"dotdash\"`, 5 = `\"longdash\"`, 6 = `\"twodash\"`).      *   `size`: Integer (line width in mm for outlines).      *   `linewidth`: Integer (line width in mm for lines).      *   `shape`: Integer/shape name or a single character (`\"a\"`).         ''')      # Graphical Primitives     col1.subheader('Graphical Primitives')     col1.code('''     a &lt;- ggplot(economics, aes(date, unemploy))     b &lt;- ggplot(seals, aes(x = long, y = lat))     ''')       col1.subheader('''One Variable - Continuous''')     col1.code('''            c &lt;- ggplot(mpg, aes(hwy))            c2 &lt;- ggplot(mpg)                 ''')       col1.subheader('''One Variable - Discrete''')     col1.code('''                d &lt;- ggplot(mpg, aes(fl))                     ''')       col1.subheader('''Two Variables - Both Continuous''')     col1.code('''                e &lt;- ggplot(mpg, aes(cty, hwy))                     ''')      col1.subheader('''Two Variables - One Discrete, One Continuous''')     col1.code('''                f &lt;- ggplot(mpg, aes(class, hwy))                     ''')       #######################################     # COLUMN 2     #######################################       # Logical     col2.subheader('''Two Variables - Both Discrete''')     col2.code('''                g &lt;- ggplot(diamonds, aes(cut, color))                     ''')      col2.subheader('''Two Variables - Continuous Bivariate Distribution''')     col2.code('''               h &lt;- ggplot(diamonds, aes(carat, price))                     ''')      col2.subheader('''Two Variables - Continuous Function''')     col2.code('''              i &lt;- ggplot(economics, aes(date, unemploy))                     ''')      col2.subheader('''Two Variables - Visualizing Error''')     col2.code('''              Two Variables - Visualizing Error                     ''')      col2.subheader('''Two Variables - Maps''')     col2.code('''              murder_data &lt;- data.frame(                     murder = USArrests$Murder,                      state = tolower(rownames(USArrests))             )             map &lt;- map_data(\"state\")             k &lt;- ggplot(murder_data, aes(fill = murder))                     ''')      col2.subheader('''Three Variables''')     col2.code('''              seals$z &lt;- with(seals, sqrt(delta_long^2 + delta_lat^2))              l &lt;- ggplot(seals, aes(long, lat))                     ''')      col2.subheader('''Stats''')     col2.markdown('''     An alternative way to build a layer. A stat builds new variables to plot (e.g., count, prop).     ''')     col2.code('''              i + stat_density_2d(aes(fill = after_stat(level)), geom = \"polygon\")                     ''')      col2.subheader('''Scales''')     col2.markdown('''     Scales map data values to the visual values of an aesthetic. To change a mapping, add a new scale.     ''')     col2.code(''' n &lt;- d + geom_bar(aes(fill = fl))  n + scale_fill_manual(   value = c(),   limits = c(),    breaks = c(),   name = \"fuel\",    labels = c(\"D\", \"E\", \"P\", \"R\") )                     ''')        #######################################     # COLUMN 3     #######################################      # Row Names     col3.subheader('''Color and Fill Scales (Continuous)''')     col3.code(''' o &lt;- c + geom_dotplot(aes(fill = ..x..))                     ''')      col3.subheader('''Shape and Size Scales''')     col3.code(''' p &lt;- e + geom_point(aes(shape = fl, size = cyl))                         ''')      col3.subheader('''Coordinate Systems''')     col3.code(''' u &lt;- d + geom_bar()                         ''')      col3.subheader('''Position Adjustments''')     col3.markdown('''     Position adjustments determine how to arrange geoms that would otherwise occupy the same space.     ''')     col3.code(''' s &lt;- ggplot(mpg, aes(fl, fill = drv))                         ''')     col3.code('''     s + geom_bar(position = position_dodge(width = 1))                             ''')      col3.subheader('''Themes''')      col3.code(''' r + ggtitle(\"Title\") + theme(plot.title.postion = \"plot\")  r + theme(panel.background = element_rect(fill = \"blue\"))                             ''')      col3.subheader('''Faceting''')     col3.markdown('''     Facets divide a plot into subplots based on the values of one or more discrete variables.     ''')     col3.code(''' t &lt;- ggplot(mpg, aes(cty, hwy)) + geom_point()                        ''')      col3.subheader('''Labels and Legends''')     col3.markdown('''         Use `labs()` to label elements of your plot.         ''')     col3.code('''     t + labs(x = \"New x axis label\",          y = \"New y axis label\",         title =\"Add a title above the plot\",         subtitle = \"Add a subtitle below title\",         caption = \"Add a caption below plot\",         alt = \"Add alt text to the plot\",          = \"New  legend title\")                          ''')      col3.subheader('''Zooming''')     col3.markdown(''' *   `t + coord_cartesian(xlim = c(0, 100), ylim = c(10,20))`: Zoom without clipping (preferred).      *   `t + xlim(0, 100) + ylim(10, 20)` or `t + scale_x_continuous(limits = c(0, 100)) + scale_y_continuous(limits = c(0, 100))`: Zoom with clipping (removes unseen data points).              ''') In\u00a0[\u00a0]: Copied! <pre># Run the main function if the script is executed directly\nif __name__ == '__main__':\n    main()\n</pre> # Run the main function if the script is executed directly if __name__ == '__main__':     main()"},{"location":"examples/ggplot2/ggplot2/","title":"Ggplot2","text":"In\u00a0[\u00a0]: Copied! <pre>library(ggplot2)\n</pre> library(ggplot2) <p>To display values, map variables in the data to visual properties of the geom (aesthetics) like size, color, and x and y locations.</p> <p>Complete the template below to build a graph.</p> <pre>ggplot(data = &lt;Data&gt;) +\n      &lt;Geom_Function&gt;(mapping = aes(&lt;Mappings&gt;),\n      stat = &lt;Stat&gt;,\n      position = &lt;Position&gt;) +\n      &lt;Coordinate_Function&gt; +\n      &lt;Facet_Function&gt; +\n      &lt;Scale_Function&gt; +\n      &lt;Theme_Function&gt;\n</pre> <p>Data, a Geom Function, and Aes Mappings are required. Stat, Position, and the Coordinate, Facet, Scale, and Theme functions are not required and will supply sensible defaults.</p> <ul> <li><p><code>ggplot(data = mpg, aes(x = cty, y = hwy))</code>: Begins a plot that you finish by adding layers to. Add one geom function per layer.</p> </li> <li><p><code>last_plot()</code>: Returns the last plot.</p> </li> <li><p><code>ggsave(\"plot.png\", width = 5, height = 5)</code>: Saves last plot as 5\u2019 x 5\u2019 file named \u201cplot.png\u201d in working directory. Matches file type to file extension.</p> </li> </ul> In\u00a0[\u00a0]: Copied! <pre>a &lt;- ggplot(economics, aes(date, unemploy))\n</pre> a &lt;- ggplot(economics, aes(date, unemploy)) In\u00a0[\u00a0]: Copied! <pre>b &lt;- ggplot(seals, aes(x = long, y = lat))\n</pre> b &lt;- ggplot(seals, aes(x = long, y = lat)) <ul> <li><p><code>a + geom_blank()</code> and <code>a + expand_limits()</code>: Ensure limits include values across all plots.</p> </li> <li><p><code>b + geom_curve(aes(yend = lat + 1, xend = long + 1), curvature = 1)</code>: Draw a curved line from <code>(x, y)</code> to <code>(xend, yend)</code>. <code>aes()</code> arguments: <code>x</code>, <code>xend</code>, <code>y</code>, <code>yend</code>, <code>alpha</code>, <code>angle</code>, <code>color</code>, <code>curvature</code>, <code>linetype</code>, <code>size</code>.</p> </li> <li><p><code>a + geom_path(lineend = \"butt\", linejoin = \"round\", linemitre = 1)</code>: Connect observations in the order they appear. <code>aes()</code> arguments: <code>x</code>, <code>y</code>, <code>alpha</code>, <code>color</code>, <code>group</code>, <code>linetype</code>, <code>size</code>.</p> </li> <li><p><code>a + geom_polygon(aes(alpha = 50))</code>: Connect points into polygons. <code>aes()</code> arguments: <code>x</code>, <code>y</code>, <code>alpha</code>, <code>color</code>, <code>fill</code>, <code>group</code>, <code>subgroup</code>, <code>linetype</code>, <code>size</code>.</p> </li> <li><p><code>b + geom_rect(aes(xmin = long, ymin = lat, xmax = long + 1, ymax = lat + 1))</code>: Draw a rectangle by connecting four corners (<code>xmin</code>, <code>xmax</code>, <code>ymin</code>, <code>ymax</code>). <code>aes()</code> arguments: <code>xmax</code>, <code>xmin</code>, <code>ymax</code>, <code>ymin</code>, <code>alpha</code>, <code>color</code>, <code>fill</code>, <code>linetype</code>, <code>size</code>.</p> </li> <li><p><code>a + geom_ribbon(aes(ymin = unemploy - 900, ymax = unemploy + 900)</code>: For each <code>x</code>, plot an interval from <code>ymin</code> to <code>ymax</code>. <code>aes()</code> arguments: <code>x</code>, <code>ymax</code>, <code>ymin</code>, <code>alpha</code>, <code>color</code>, <code>fill</code>, <code>group</code>, <code>linetype</code>, <code>size</code>.</p> </li> </ul> In\u00a0[\u00a0]: Copied! <pre>c &lt;- ggplot(mpg, aes(hwy))\nc2 &lt;- ggplot(mpg)\n</pre> c &lt;- ggplot(mpg, aes(hwy)) c2 &lt;- ggplot(mpg) <ul> <li><p><code>c + geom_area(stat = \"bin\")</code>: Draw an area plot. <code>aes()</code> arguments: <code>x</code>, <code>y</code>, <code>alpha</code>, <code>color</code>, <code>fill</code>, <code>linetype</code>, <code>linewidth</code>.</p> </li> <li><p><code>c + geom_density(kernel = \"gaussian\")</code>: Compute and draw kernel density estimates. <code>aes()</code> arguments: <code>x</code>, <code>y</code>, <code>alpha</code>, <code>color</code>, <code>fill</code>, <code>group</code>, <code>linetype</code>, <code>linewidth</code>, <code>weight</code>.</p> </li> <li><p><code>c + geom_dotplot()</code>: Draw a dot plot. <code>aes()</code> arguments: <code>x</code>, <code>y</code>, <code>alpha</code>, <code>color</code>, <code>fill</code>.</p> </li> <li><p><code>c + geom_freqpoly()</code>: Draw a frequency polygon. <code>aes()</code> arguments: <code>x</code>, <code>y</code>, <code>alpha</code>, <code>color</code>, <code>group</code>, <code>linetype</code>, <code>linewidth</code>.</p> </li> <li><p><code>c + geom_histogram(binwidth = 5)</code>: Draw a histogram. <code>aes()</code> arguments: <code>x</code>, <code>y</code>, <code>alpha</code>, <code>color</code>, <code>fill</code>, <code>linetype</code>, <code>linewidth</code>, <code>weight</code>.</p> </li> <li><p><code>c2 + geom_qq(aes(sample = hwy))</code>: Draw a quantile-quantile plot. <code>aes()</code> arguments: <code>x</code>, <code>y</code>, <code>alpha</code>, <code>color</code>, <code>fill</code>, <code>linetype</code>, <code>size</code>, <code>weight</code>.</p> </li> </ul> In\u00a0[\u00a0]: Copied! <pre>d &lt;- ggplot(mpg, aes(fl))\n</pre> d &lt;- ggplot(mpg, aes(fl)) <ul> <li><code>d + geom_bar()</code>: Draw a bar chart. <code>aes()</code> arguments: <code>x</code>, <code>alpha</code>, <code>color</code>, <code>fill</code>, <code>linetype</code>, <code>linewidth</code>, <code>weight</code>.</li> </ul> In\u00a0[\u00a0]: Copied! <pre>e &lt;- ggplot(mpg, aes(cty, hwy))\n</pre> e &lt;- ggplot(mpg, aes(cty, hwy)) <ul> <li><p><code>e + geom_label(aes(label = cty), nudge_x = 1, nudge_y = 1)</code>: Add text with a rectangle background. <code>aes()</code> arguments: - <code>x</code>, <code>y</code>, <code>label</code>, <code>alpha</code>, <code>angle</code>, <code>color</code>, <code>family</code>, <code>fontface</code>, <code>hjust</code>, <code>lineheight</code>, <code>size</code>, <code>vjust</code>.</p> </li> <li><p><code>e + geom_point()</code>: Draw a scatter plot. <code>aes()</code> arguments: <code>x</code>, <code>y</code>, <code>alpha</code>, <code>color</code>, <code>fill</code>, <code>shape</code>, <code>size</code>, <code>stroke</code>.</p> </li> <li><p><code>e + geom_quantile()</code>: Fit and draw quantile regression for the plot data. <code>aes()</code> arguments: <code>x</code>, <code>y</code>, <code>alpha</code>, <code>color</code>, <code>group</code>, <code>linetype</code>, <code>linewidth</code>, <code>weight</code>.</p> </li> <li><p><code>e + geom_rug(sides = \"bl\")</code>: Draw a rug plot. <code>aes()</code> arguments: <code>x</code>, <code>y</code>, <code>alpha</code>, <code>color</code>, <code>linetype</code>, <code>linewidth</code>.</p> </li> <li><p><code>e + geom_smooth(method = lm)</code>: Plot smoothed conditional means. <code>aes()</code> arguments: <code>x</code>, <code>y</code>, <code>alpha</code>, <code>color</code>, <code>fill</code>, <code>group</code>, <code>linetype</code>, <code>linewidth</code>, <code>weight</code>.</p> </li> <li><p><code>e + geom_text(aes(label = cty), nudge_x = 1, nudge_y = 1)</code>: Add text to a plot. <code>aes()</code> arguments: <code>x</code>, <code>y</code>, <code>label</code>, <code>alpha</code>, <code>angle</code>, <code>color</code>, <code>family</code>, <code>fontface</code>, <code>hjust</code>, <code>lineheight</code>, <code>size</code>, <code>vjust</code>.</p> </li> </ul> In\u00a0[\u00a0]: Copied! <pre>f &lt;- ggplot(mpg, aes(class, hwy))\n</pre> f &lt;- ggplot(mpg, aes(class, hwy)) <ul> <li><p><code>f + geom_col()</code>: Draw a bar plot. <code>aes()</code> arguments: <code>x</code>, <code>y</code>, <code>alpha</code>, <code>color</code>, <code>fill</code>, <code>group</code>, <code>linetype</code>, <code>linewidth</code>.</p> </li> <li><p><code>f + geom_boxplot()</code>: Draw a box plot. <code>aes()</code> arguments: <code>x</code>, <code>y</code>, <code>lower</code>, <code>middle</code>, <code>upper</code>, <code>ymax</code>, <code>ymin</code>, <code>alpha</code>, <code>color</code>, <code>fill</code>, <code>group</code>, <code>linetype</code>, <code>shape</code>, <code>linewidth</code>, <code>weight</code>.</p> </li> <li><p><code>f + geom_dotplot(binaxis =\"y\", stackdir = \"center\")</code>: Draw a dot plot. <code>aes()</code> arguments: <code>x</code>, <code>y</code>, <code>alpha</code>, <code>color</code>, <code>fill</code>, <code>group</code>.</p> </li> <li><p><code>f + geom_violin(scale = \"area\")</code>: Draw a violin plot. <code>aes()</code> arguments: <code>x</code>, <code>y</code>, <code>alpha</code>, <code>color</code>, <code>fill</code>, <code>group</code>, <code>linetype</code>, <code>linewidth</code>, <code>weight</code>.</p> </li> </ul> In\u00a0[\u00a0]: Copied! <pre>g &lt;- ggplot(diamonds, aes(cut, color))\n</pre> g &lt;- ggplot(diamonds, aes(cut, color)) <ul> <li><p><code>g + geom_count()</code>: Plot a count of points in an area to address over plotting. <code>aes()</code> arguments: <code>x</code>, <code>y</code>, <code>alpha</code>, <code>color</code>, <code>fill</code>, <code>shape</code>, <code>size</code>, <code>stroke</code>.</p> </li> <li><p><code>e + geom_jitter(height = 2, width = 2)</code>: Jitter points in a plot. <code>aes()</code> arguments: <code>x</code>, <code>y</code>, <code>alpha</code>, <code>color</code>, <code>fill</code>, <code>shape</code>, <code>size</code>.</p> </li> </ul> In\u00a0[\u00a0]: Copied! <pre>h &lt;- ggplot(diamonds, aes(carat, price))\n</pre> h &lt;- ggplot(diamonds, aes(carat, price)) <ul> <li><p><code>h + geom_bin2d(binwidth = c(0.25, 500))</code>: Draw a heatmap of 2D rectangular bin counts. <code>aes()</code> arguments: <code>x</code>, <code>y</code>, <code>alpha</code>, <code>color</code>, <code>fill</code>, <code>linetype</code>, <code>size</code>, <code>weight</code>.</p> </li> <li><p><code>h + geom_density_2d()</code>: Plot contours from 2D kernel density estimation. <code>aes()</code> arguments: <code>x</code>, <code>y</code>, <code>alpha</code>, <code>color</code>, <code>group</code>, <code>linetype</code>, <code>linewidth</code>.</p> </li> <li><p><code>h + geom_hex()</code>: Draw a heatmap of 2D hexagonal bin counts. <code>aes()</code> arguments: <code>x</code>, <code>y</code>, <code>alpha</code>, <code>color</code>, <code>fill</code>, <code>linewidth</code>.</p> </li> </ul> In\u00a0[\u00a0]: Copied! <pre>i &lt;- ggplot(economics, aes(date, unemploy))\n</pre> i &lt;- ggplot(economics, aes(date, unemploy)) <ul> <li><p><code>i + geom_area()</code>: Draw an area plot. <code>aes()</code> arguments: <code>x</code>, <code>y</code>, <code>alpha</code>, <code>color</code>, <code>fill</code>, <code>linetype</code>, <code>linewidth</code>.</p> </li> <li><p><code>i + geom_line()</code>: Connect data points, ordered by the x axis variable. <code>aes()</code> arguments: <code>x</code>, <code>y</code>, <code>alpha</code>, <code>color</code>, <code>group</code>, <code>linetype</code>, <code>linewidth</code>.</p> </li> <li><p><code>i + geom_step(direction = \"hv\"</code>: Draw a stairstep plot. <code>aes()</code> arguments: <code>x</code>, <code>y</code>, <code>alpha</code>, <code>color</code>, <code>group</code>, <code>linetype</code>, <code>linewidth</code>.</p> </li> </ul> In\u00a0[\u00a0]: Copied! <pre>df &lt;- data.frame(grp = c(\"A\", \"B\"), fit = 4:5, se = 1:2)\nj &lt;- ggplot(df, aes(grp, fit, ymin = fit - se, ymax = fit + se))\n</pre> df &lt;- data.frame(grp = c(\"A\", \"B\"), fit = 4:5, se = 1:2) j &lt;- ggplot(df, aes(grp, fit, ymin = fit - se, ymax = fit + se)) <ul> <li><p><code>j + geom_crossbar(fatten = 2)</code>: Draw a crossbar. <code>aes()</code> arguments: <code>x</code>, <code>y</code>, <code>ymax</code>, <code>ymin</code>, <code>alpha</code>, <code>color</code>, <code>fill</code>, <code>group</code>, <code>linetype</code>, <code>linewidth</code>.</p> </li> <li><p><code>j + geom_errorbar()</code>: Draw an errorbar. Also <code>geom_errorbarh()</code>. <code>aes()</code> arguments: <code>x</code>, <code>ymax</code>, <code>ymin</code>, <code>alpha</code>, <code>color</code>, <code>group</code>, <code>linetype</code>, <code>linewidth</code>, <code>width</code>.</p> </li> <li><p><code>j + geom_linerange()</code>: Draw a line range. <code>aes()</code> arguments: <code>x</code>, <code>ymin</code>, <code>ymax</code>, <code>alpha</code>, <code>color</code>, <code>group</code>, <code>linetype</code>, <code>linewidth</code>.</p> </li> <li><p><code>j + geom_pointrange()</code>: Draw a point range. <code>aes()</code> arguments: <code>x</code>, <code>y</code>, <code>ymin</code>, <code>ymax</code>, <code>alpha</code>, <code>color</code>, <code>fill</code>, <code>group</code>, <code>linetype</code>, <code>shape</code>, <code>linewidth</code>.</p> </li> </ul> In\u00a0[\u00a0]: Copied! <pre>murder_data &lt;- data.frame(\n  murder = USArrests$Murder, \n  state = tolower(rownames(USArrests))\n)\nmap &lt;- map_data(\"state\")\nk &lt;- ggplot(murder_data, aes(fill = murder))\n</pre> murder_data &lt;- data.frame(   murder = USArrests$Murder,    state = tolower(rownames(USArrests)) ) map &lt;- map_data(\"state\") k &lt;- ggplot(murder_data, aes(fill = murder)) <ul> <li><code>k + geom_map(aes(map_id = state), map = map) + expand_limits(x = map$long, y = map$lat)</code>: Draw polygons as a map. <code>aes()</code> arguments: <code>map_id</code>, <code>alpha</code>, <code>color</code>, <code>fill</code>, <code>linetype</code>, <code>linewidth</code>.</li> </ul> In\u00a0[\u00a0]: Copied! <pre>seals$z &lt;- with(seals, sqrt(delta_long^2 + delta_lat^2))\nl &lt;- ggplot(seals, aes(long, lat))\n</pre> seals$z &lt;- with(seals, sqrt(delta_long^2 + delta_lat^2)) l &lt;- ggplot(seals, aes(long, lat)) <ul> <li><p><code>l + geom_contour(aes(z = z))</code>: Draw 2D contour plot. <code>aes()</code> arguments: <code>x</code>, <code>y</code>, <code>z</code>, <code>alpha</code>, <code>color</code>, <code>group</code>, <code>linetype</code>, <code>linewidth</code>, <code>weight</code>.</p> </li> <li><p><code>l + geom_contour_filled(aes(fill = z))</code>: Draw 2D contour plot with the space between lines filled. <code>aes()</code> arguments: <code>x</code>, <code>y</code>, <code>alpha</code>, <code>color</code>, <code>fill</code>, <code>group</code>, <code>linetype</code>, <code>linewidth</code>, <code>subgroup</code>.</p> </li> <li><p><code>l + geom_raster(aes(fill = z), hjust = 0.5, vjust = 0.5, interpolate = FALSE)</code>: Draw a raster plot. <code>aes()</code> arguments: <code>x</code>, <code>y</code>, <code>alpha</code>, <code>fill</code>.</p> </li> <li><p><code>l + geom_tile(aes(fill = z))</code>: Draw a tile plot. <code>aes()</code> arguments: <code>x</code>, <code>y</code>, <code>alpha</code>, <code>color</code>, <code>fill</code>, <code>linetype</code>, <code>linewidth</code>, <code>width</code>.</p> </li> </ul> In\u00a0[\u00a0]: Copied! <pre>i + stat_density_2d(aes(fill = after_stat(level)), geom = \"polygon\")\n</pre> i + stat_density_2d(aes(fill = after_stat(level)), geom = \"polygon\") <p>In this example, <code>\"polygon\"</code> is the geom to use, <code>stat_density_2d()</code> is the stat function, <code>aes()</code> contains the geom mappings, and <code>level</code> is the variable created by stat.</p> <ul> <li><p><code>c + stat_bin(binwidth = 1, boundary = 10)</code>: <code>x</code>, <code>y</code> | <code>count</code>, <code>ncount</code>, <code>density</code>, <code>ndensity</code></p> </li> <li><p><code>c + stat_count(width = 1)</code>: <code>x</code>, <code>y</code> | <code>count</code>, <code>density</code></p> </li> <li><p><code>c + stat_density(adjust = 1, kernel = \"gaussian\")</code>: <code>x</code>, <code>y</code> | <code>count</code>, <code>density</code>, <code>scaled</code></p> </li> <li><p><code>e + stat_bin_2d(bins = 30, drop = T)</code>: <code>x</code>, <code>y</code>, <code>fill</code> | <code>count</code>, <code>density</code></p> </li> <li><p><code>e + stat_bin_hex(bins =30)</code>: <code>x</code>, <code>y</code>, <code>fill</code> | <code>count</code>, <code>density</code></p> </li> <li><p><code>e + stat_density_2d(contour = TRUE, n = 100)</code>: <code>x</code>, <code>y</code>, <code>color</code>, <code>linewidth</code> | <code>level</code></p> </li> <li><p><code>e + stat_ellipse(level = 0.95, segments = 51, type = \"t\")</code></p> </li> <li><p><code>l + stat_contour(aes(z = z))</code>: <code>x</code>, <code>y</code>, <code>z</code>, <code>order</code> | <code>level</code></p> </li> <li><p><code>l + stat_summary_hex(aes(z = z), bins = 30, fun = max)</code>: <code>x</code>, <code>y</code>, <code>z</code>, <code>fill</code> | <code>value</code></p> </li> <li><p><code>l + stat_summary_2d(aes(z = z), bins = 30, fun = mean)</code>: <code>x</code>, <code>y</code>, <code>z</code>, <code>fill</code> | <code>value</code></p> </li> <li><p><code>f + stat_boxplot(coef = 1.5)</code>: <code>x</code>, <code>y</code> | <code>lower</code>, <code>middle</code>, <code>upper</code>, <code>width</code>, <code>ymin</code>, <code>ymax</code></p> </li> <li><p><code>f + stat_ydensity(kernel = \"gaussian\", scale = \"area\")</code>: <code>x</code>, <code>y</code> | <code>density</code>, <code>scaled</code>, <code>count</code>, <code>n</code>, <code>violinwidth</code>, <code>width</code></p> </li> <li><p><code>e + stat_ecdf(n = 40)</code>: <code>x</code>, <code>y</code> | <code>x</code>, <code>y</code></p> </li> <li><p><code>e + stat_quantile(quantiles = c(0.1, 0.9), formula = y ~ log(x), method = \"rq\")</code>: <code>x</code>, <code>y</code> | <code>quantile</code></p> </li> <li><p><code>e + stat_smooth(method = \"lm\", formula = y ~ x, se = T, level = 0.95)</code>: <code>x</code>, <code>y</code> | <code>se</code>, <code>x</code>, <code>y</code>, <code>ymin</code>, <code>ymax</code></p> </li> <li><p><code>ggplot() + xlim(-5, 5) + stat_function(fun = dnorm, n = 20, geom = \"point\")</code>: <code>x</code> | <code>x</code>, <code>y</code></p> </li> <li><p><code>ggplot() + stat_qq(aes(sample = 1:100))</code>: <code>x</code>, <code>y</code>, <code>sample</code> | <code>sample</code>, <code>theoretical</code></p> </li> <li><p><code>e + stat_sum()</code>: <code>x</code>, <code>y</code>, <code>size</code> | <code>n</code>, <code>prop</code></p> </li> <li><p><code>e + stat_summary(fun.data = \"mean_cl_boot\")</code></p> </li> <li><p><code>h + stat_summary_bin(fun = \"mean\", geom = \"bar\")</code></p> </li> <li><p><code>e + stat_identity()</code></p> </li> <li><p><code>e + stat_unique()</code></p> </li> </ul> In\u00a0[\u00a0]: Copied! <pre>n &lt;- d + geom_bar(aes(fill = fl))\n    \nn + scale_fill_manual(\n  value = c(),\n  limits = c(), \n  breaks = c(),\n  name = \"fuel\", \n  labels = c(\"D\", \"E\", \"P\", \"R\")\n)\n</pre> n &lt;- d + geom_bar(aes(fill = fl))      n + scale_fill_manual(   value = c(),   limits = c(),    breaks = c(),   name = \"fuel\",    labels = c(\"D\", \"E\", \"P\", \"R\") ) <p>In this example, <code>scale_</code> specifies a scale function, <code>fill</code> is the aesthetic to adjust, and <code>manual</code> is the prepackaged scale to use.</p> <p><code>values</code> contains scale-specific arguments, <code>limits</code> specifies the range of values to include in mappings, <code>breaks</code> specifies the breaks to use in legend/axis, and <code>name</code> and <code>labels</code> specify the title and labels to use in the legend/axis.</p> In\u00a0[\u00a0]: Copied! <pre>o &lt;- c + geom_dotplot(aes(fill = ..x..))\n</pre> o &lt;- c + geom_dotplot(aes(fill = ..x..)) <ul> <li><p><code>o + scale_fill_distiller(palette = \"Blues\")</code>: Interpolate a palette into a continuous scale.</p> </li> <li><p><code>o + scale_fill_gradient(low = \"red\", high = \"yellow\")</code>: Create a two color gradient.</p> </li> <li><p><code>o + scale_fill_gradient2(low = \"red\", high = \"blue\", mid = \"white\", midpoint = 25)</code>: Create a diverging color gradient.</p> </li> <li><p><code>o + scale_fill_gradientn(colors = topo.colors(6))</code>: Create a n-color gradient. Also <code>rainbow()</code>, <code>heat.colors()</code>, <code>terrain.colors()</code>, <code>cm.colors()</code>, <code>RColorBrewer::brewer.pal()</code>.</p> </li> </ul> In\u00a0[\u00a0]: Copied! <pre>p &lt;- e + geom_point(aes(shape = fl, size = cyl))\n</pre> p &lt;- e + geom_point(aes(shape = fl, size = cyl)) <ul> <li><p><code>p + scale_shape() + scale_size()</code>: Map discrete values to shape and size aesthetics.</p> </li> <li><p><code>p + scale_shape_manual(values = c(3:7))</code>: Map discrete values to specified shape values.</p> </li> <li><p><code>p + scale_radius(range = c(1,6))</code>: Map values to a shape\u2019s radius.</p> </li> <li><p><code>p + scale_size_area(max_size = 6)</code>: Like <code>scale_size()</code> but maps zero values to zero size.</p> </li> </ul> <p>Shapes used here are the same as the ones listed in the Aes section.</p> In\u00a0[\u00a0]: Copied! <pre>u &lt;- d + geom_bar()\n</pre> u &lt;- d + geom_bar() <ul> <li><p><code>u + coord_cartesian(xlim = c(0, 5))</code>: <code>xlim</code>, <code>ylim</code>. The default Cartesian coordinate system.</p> </li> <li><p><code>u + coord_fixed(ratio = 1/2)</code>: <code>ratio</code>, <code>xlim</code>, <code>ylim</code>. Cartesian coordinates with fixed aspect ration between x and y units.</p> </li> <li><p><code>ggplot(mpg, aes(y = fl)) + geom_bar()</code>: Flip Cartesian coordinates by switching x and y aesthetic mappings.</p> </li> <li><p><code>u + coord_polar(theta = \"x\", direction = 1)</code>: <code>theta</code>, <code>start</code>, <code>direction</code>. Polar coordinates.</p> </li> <li><p><code>u + coord_trans(y = \"sqrt\")</code>: <code>x</code>, <code>y</code>, <code>xlim</code>, <code>ylim</code>. Transformed Cartesian coordinates. Set <code>xtrans</code> and <code>ytrans</code> to the name of a window function.</p> </li> <li><p><code>\u03c0 + coord_quickmap(); \u03c0 + coord_map(projection = \"ortho\", orientation = c(41, -74, 0))</code>: <code>projection</code>, <code>xlim</code>, <code>ylim</code>. Map projections from the mapproj packages (<code>mercator</code> (default), <code>azequalarea</code>, <code>lagrange</code>, etc.).</p> </li> </ul> In\u00a0[\u00a0]: Copied! <pre>s &lt;- ggplot(mpg, aes(fl, fill = drv))\n</pre> s &lt;- ggplot(mpg, aes(fl, fill = drv)) <ul> <li><p><code>s + geom_bar(position = \"dodge\")</code>: Arrange elements side by side.</p> </li> <li><p><code>s + geom_bar(position = \"fill\")</code>: Stack elements on top of one another, normalize height.</p> </li> <li><p><code>e + geom_point(position = \"jitter\")</code>: Add random noise to X and Y position of each element to avoid over plotting.</p> </li> <li><p><code>e + geom_label(position = \"nudge\")</code>: Nudge labels away from points.</p> </li> <li><p><code>s + geom_bar(position = \"stack\")</code>: Stack elements on top of one another.</p> </li> </ul> <p>Each position adjustment can be recast as a function with manual <code>width</code> and <code>height</code> arguments:</p> In\u00a0[\u00a0]: Copied! <pre>s + geom_bar(position = position_dodge(width = 1))\n</pre> s + geom_bar(position = position_dodge(width = 1)) In\u00a0[\u00a0]: Copied! <pre>r + ggtitle(\"Title\") + theme(plot.title.postion = \"plot\")\n</pre> r + ggtitle(\"Title\") + theme(plot.title.postion = \"plot\") In\u00a0[\u00a0]: Copied! <pre>r + theme(panel.background = element_rect(fill = \"blue\"))\n</pre> r + theme(panel.background = element_rect(fill = \"blue\")) In\u00a0[\u00a0]: Copied! <pre>t &lt;- ggplot(mpg, aes(cty, hwy)) + geom_point()\n</pre> t &lt;- ggplot(mpg, aes(cty, hwy)) + geom_point() <ul> <li><p><code>t + facet_grid(. ~ fl)</code>: Facet into a column based on fl.</p> </li> <li><p><code>t + facet_grid(year ~ .)</code>: Facet into rows based on year.</p> </li> <li><p><code>t + facet_grid(year ~ fl)</code>: Facet into both rows and columns.</p> </li> <li><p><code>t + facet_wrap(~ fl)</code>: Wrap facets into a rectangular layout.</p> </li> <li><p><code>t + facet_grid(drv ~ fl, scales = \"free\")</code>: Set scales to let axis limits vary across facets. Also <code>\"free_x\"</code> for x axis limits adjust to individual facets and <code>\"free_y\"</code> for y axis limits adjust to individual facets.</p> </li> </ul> <p>Set labeller to adjust facet label:</p> <ul> <li><p><code>t + facet_grid(. ~ fl, labeller = label_both)</code>: Labels each facet as \u201cfl: c\u201d, \u201cfl: d\u201d, etc.</p> </li> <li><p><code>t + facet_grid(fl ~ ., labeller = label_bquote(alpha ^ .(fl)))</code>: Labels each facet as \u201c\ud835\udefcc\u201d, \u201c\ud835\udefcd\u201d, etc.</p> </li> </ul> <pre>t + labs(x = \"New x axis label\", \n  y = \"New y axis label\",\n  title =\"Add a title above the plot\",\n  subtitle = \"Add a subtitle below title\",\n  caption = \"Add a caption below plot\",\n  alt = \"Add alt text to the plot\",\n  &lt;Aes&gt; = \"New &lt;Aes&gt; legend title\")\n</pre> <ul> <li><p><code>t + annotate(geom = \"text\", x = 8, y = 9, label = \"A\")</code>: Places a geom with manually selected aesthetics.</p> </li> <li><p><code>p + guides(x = guide_axis(n.dodge = 2))</code>: Avoid crowded or overlapping labels with <code>guide_axis(n.dodge or angle)</code>.</p> </li> <li><p><code>n + guides(fill = \"none\")</code>: Set legend type for each aesthetic: <code>colorbar</code>, <code>legend</code>, or <code>none</code> (no legend).</p> </li> <li><p><code>n + theme(legend.position = \"bottom\")</code>: Place legend at \u201cbottom\u201d, \u201ctop\u201d, \u201cleft\u201d, or \u201cright\u201d.</p> </li> <li><p><code>n + scale_fill_discrete(name = \"Title\", labels = c(\"A\", \"B\", \"C\", \"D\", \"E\"))</code>: Set legend title and labels with a scale function.</p> </li> </ul>"},{"location":"examples/ggplot2/ggplot2/#ggplot2","title":"Ggplot2\u00b6","text":""},{"location":"examples/ggplot2/ggplot2/#basics","title":"Basics\u00b6","text":"<p>ggplot2 is based on the grammar of graphics, the idea that you can build every graph from the same components: a data set, a coordinate system, and geoms\u2014visual marks that represent data points.</p>"},{"location":"examples/ggplot2/ggplot2/#aes","title":"Aes\u00b6","text":"<p>Common aesthetic values.</p> <ul> <li><p><code>color</code> and <code>fill</code>: String (<code>\"red\"</code>, <code>\"#RRGGBB\"</code>).</p> </li> <li><p><code>linetype</code>: Integer or string (0 = <code>\"blank\"</code>, 1 = <code>\"solid\"</code>, 2 = <code>\"dashed\"</code>, 3 = <code>\"dotted\"</code>, 4 = <code>\"dotdash\"</code>, 5 = <code>\"longdash\"</code>, 6 = <code>\"twodash\"</code>).</p> </li> <li><p><code>size</code>: Integer (line width in mm for outlines).</p> </li> <li><p><code>linewidth</code>: Integer (line width in mm for lines).</p> </li> <li><p><code>shape</code>: Integer/shape name or a single character (<code>\"a\"</code>).</p> <ul> <li><code>shape</code> integer/name pairs: 0 = <code>\"square open\"</code>, 1 = <code>\"circle open\"</code>, 2 = <code>\"triangle open\"</code>, 3 = <code>\"plus\"</code>, 4 = <code>\"cross\"</code>, 5 = <code>\"diamond open\"</code>, 6 = <code>\"triangle down open\"</code>, 7 = <code>\"square cross\"</code>, 8 = <code>\"asterisk\"</code>, 9 = <code>\"diamond plus\"</code>, 10 = <code>\"circle plus\"</code>, 11 = <code>\"star\"</code>, 12 = <code>\"square plus\"</code>, 13 = <code>\"circle cross\"</code>, 14 = <code>\"square triangle\"</code>, 15 = <code>\"square\"</code>, 16 = <code>\"circle\"</code>, 17 = <code>\"triangle\"</code>, 18 = <code>\"diamond\"</code>, 19 = <code>\"circle small\"</code>, 20 = <code>\"bullet\"</code>, 21 = <code>\"circle filled\"</code>, 22 = <code>\"square filled\"</code>, 23 = <code>\"diamond filled\"</code>, 24 = <code>\"triangle filled\"</code>, 25 = <code>\"triangle down filled\"</code></li> </ul> </li> </ul>"},{"location":"examples/ggplot2/ggplot2/#geoms","title":"Geoms\u00b6","text":"<p>Use a geom function to represent data points, use the geom\u2019s aesthetic properties to represent variables. Each function returns a layer.</p>"},{"location":"examples/ggplot2/ggplot2/#graphical-primitives","title":"Graphical Primitives\u00b6","text":""},{"location":"examples/ggplot2/ggplot2/#line-segments","title":"Line Segments\u00b6","text":"<p>Common aesthetics: <code>x</code>, <code>y</code>, <code>alpha</code>, <code>color</code>, <code>linetype</code>, <code>size</code>, <code>linewidth</code>.</p> <ul> <li><p><code>b + geom_abline(aes(intercept = 0, slope = 1))</code>: Draw a diagonal reference line with a given <code>slope</code> and <code>intercept</code>.</p> </li> <li><p><code>b + geom_hline(aes(yintercept = lat))</code>: Draw a horizontal reference line with a given <code>yintercept</code>.</p> </li> <li><p><code>b + geom_vline(aes(xintercept = long))</code>: Draw a vertical reference line with a given <code>xintercept</code>.</p> </li> <li><p><code>b + geom_segment(aes(yend = lat + 1, xend = long + 1))</code>: Draw a straight line from <code>(x, y)</code> to <code>(xend, yend)</code>.</p> </li> <li><p><code>b + geom_spoke(aes(angle = 1:1155, radius = 1))</code>: Draw line segments using polar coordinates (<code>angle</code> and <code>radius</code>).</p> </li> </ul>"},{"location":"examples/ggplot2/ggplot2/#one-variable-continuous","title":"One Variable - Continuous\u00b6","text":""},{"location":"examples/ggplot2/ggplot2/#one-variable-discrete","title":"One Variable - Discrete\u00b6","text":""},{"location":"examples/ggplot2/ggplot2/#two-variables-both-continuous","title":"Two Variables - Both Continuous\u00b6","text":""},{"location":"examples/ggplot2/ggplot2/#two-variables-one-discrete-one-continuous","title":"Two Variables - One Discrete, One Continuous\u00b6","text":""},{"location":"examples/ggplot2/ggplot2/#two-variables-both-discrete","title":"Two Variables - Both Discrete\u00b6","text":""},{"location":"examples/ggplot2/ggplot2/#two-variables-continuous-bivariate-distribution","title":"Two Variables - Continuous Bivariate Distribution\u00b6","text":""},{"location":"examples/ggplot2/ggplot2/#two-variables-continuous-function","title":"Two Variables - Continuous Function\u00b6","text":""},{"location":"examples/ggplot2/ggplot2/#two-variables-visualizing-error","title":"Two Variables - Visualizing Error\u00b6","text":""},{"location":"examples/ggplot2/ggplot2/#two-variables-maps","title":"Two Variables - Maps\u00b6","text":""},{"location":"examples/ggplot2/ggplot2/#three-variables","title":"Three Variables\u00b6","text":""},{"location":"examples/ggplot2/ggplot2/#stats","title":"Stats\u00b6","text":"<p>An alternative way to build a layer.</p> <p>A stat builds new variables to plot (e.g., count, prop).</p> <p>Visualize a stat by changing the default stat of a geom function, <code>geom_bar(stat = \"count\")</code>, or by using a stat function, <code>stat_count(geom = \"bar\")</code>, which calls a default geom to make a layer (equivalent to a geom function). Use <code>after_stat(name)</code> syntax to map the stat variable <code>name</code> to an aesthetic.</p>"},{"location":"examples/ggplot2/ggplot2/#scales","title":"Scales\u00b6","text":"<p>Override defaults with scales package.</p> <p>Scales map data values to the visual values of an aesthetic. To change a mapping, add a new scale.</p>"},{"location":"examples/ggplot2/ggplot2/#general-purpose-scales","title":"General Purpose Scales\u00b6","text":"<p>Use with most aesthetics.</p> <ul> <li><p><code>scale_*_continuous()</code>: Map continuous values to visual ones.</p> </li> <li><p><code>scale_*_discrete()</code>: Map discrete values to visual ones.</p> </li> <li><p><code>scale_*_binned()</code>: Map continuous values to discrete bins.</p> </li> <li><p><code>scale_*_identity()</code>: Use data values as visual ones.</p> </li> <li><p><code>scale_*_manual(values = c())</code>: Map discrete values to manually chosen visual ones.</p> </li> <li><p><code>scale_*_date(date_labels = \"%m/%d\", date_breaks = \"2 weeks\")</code>: Treat data values as dates.</p> </li> <li><p><code>scale_*_datetime()</code>: Treat data values as date times. Same as <code>scale_*_date()</code>. See <code>?strptime</code> for label formats.</p> </li> </ul>"},{"location":"examples/ggplot2/ggplot2/#x-y-location-scales","title":"X &amp; Y Location Scales\u00b6","text":"<p>Use with x or y aesthetics (x shown here).</p> <ul> <li><p><code>scale_x_log10()</code>: Plot <code>x</code> on log10 scale.</p> </li> <li><p><code>scale_x_reverse()</code>: Reverse the direction of the x axis.</p> </li> <li><p><code>scale_x_sqrt()</code>: Plot <code>x</code> on square root scale.</p> </li> </ul>"},{"location":"examples/ggplot2/ggplot2/#color-and-fill-scales-discrete","title":"Color and Fill Scales (Discrete)\u00b6","text":"<ul> <li><p><code>n + scale_fill_brewer(palette = \"Blues\")</code>: Use color scales from ColorBrewer. For palette choices <code>RColorBrewer::display.brewer.all()</code>.</p> </li> <li><p><code>n + scale_fill_grey(start = 0.2, end = 0.8, na.value = \"red\")</code>: Use a grey gradient color scale.</p> </li> </ul>"},{"location":"examples/ggplot2/ggplot2/#color-and-fill-scales-continuous","title":"Color and Fill Scales (Continuous)\u00b6","text":""},{"location":"examples/ggplot2/ggplot2/#shape-and-size-scales","title":"Shape and Size Scales\u00b6","text":""},{"location":"examples/ggplot2/ggplot2/#coordinate-systems","title":"Coordinate Systems\u00b6","text":""},{"location":"examples/ggplot2/ggplot2/#position-adjustments","title":"Position Adjustments\u00b6","text":"<p>Position adjustments determine how to arrange geoms that would otherwise occupy the same space.</p>"},{"location":"examples/ggplot2/ggplot2/#themes","title":"Themes\u00b6","text":"<ul> <li><p><code>u + theme_bw()</code>: White background with grid lines.</p> </li> <li><p><code>u + theme_gray()</code>: Grey background with white grid lines (default theme).</p> </li> <li><p><code>u + theme_dark()</code>: Dark grey background and grid lines for contrast.</p> </li> <li><p><code>u + theme_classic()</code>: No grid lines.</p> </li> <li><p><code>u + theme_light()</code>: Light grey axes and grid lines.</p> </li> <li><p><code>u + theme_linedraw()</code>: Uses only black lines.</p> </li> <li><p><code>u + theme_minimal()</code>: Minimal theme.</p> </li> <li><p><code>u + theme_void()</code>: Empty theme.</p> </li> <li><p><code>u + theme()</code>: Customize aspects of the theme such as axis, legend, panel, and facet properties.</p> </li> </ul>"},{"location":"examples/ggplot2/ggplot2/#faceting","title":"Faceting\u00b6","text":"<p>Facets divide a plot into subplots based on the values of one or more discrete variables.</p>"},{"location":"examples/ggplot2/ggplot2/#labels-and-legends","title":"Labels and Legends\u00b6","text":"<p>Use <code>labs()</code> to label elements of your plot.</p>"},{"location":"examples/ggplot2/ggplot2/#zooming","title":"Zooming\u00b6","text":"<ul> <li><p><code>t + coord_cartesian(xlim = c(0, 100), ylim = c(10,20))</code>: Zoom without clipping (preferred).</p> </li> <li><p><code>t + xlim(0, 100) + ylim(10, 20)</code> or <code>t + scale_x_continuous(limits = c(0, 100)) + scale_y_continuous(limits = c(0, 100))</code>: Zoom with clipping (removes unseen data points).</p> </li> </ul>"},{"location":"examples/matplotlib/app/","title":"App","text":"In\u00a0[\u00a0]: Copied! <pre>import streamlit as st\nfrom pathlib import Path\nimport base64\nimport requests\n</pre> import streamlit as st from pathlib import Path import base64 import requests In\u00a0[\u00a0]: Copied! <pre># Initial page config\nst.set_page_config(\n    page_title='Matplotlib Cheat Sheet',\n    layout=\"wide\",\n    initial_sidebar_state=\"expanded\",\n)\n</pre> # Initial page config st.set_page_config(     page_title='Matplotlib Cheat Sheet',     layout=\"wide\",     initial_sidebar_state=\"expanded\", ) In\u00a0[\u00a0]: Copied! <pre>def main():\n    \"\"\"\n    Main function to set up the Streamlit app layout.\n    \"\"\"\n    cs_sidebar()\n    cs_body()\n    return None\n</pre> def main():     \"\"\"     Main function to set up the Streamlit app layout.     \"\"\"     cs_sidebar()     cs_body()     return None In\u00a0[\u00a0]: Copied! <pre># Define img_to_bytes() function\ndef img_to_bytes(img_url):\n    response = requests.get(img_url)\n    img_bytes = response.content\n    encoded = base64.b64encode(img_bytes).decode()\n    return encoded\n</pre> # Define img_to_bytes() function def img_to_bytes(img_url):     response = requests.get(img_url)     img_bytes = response.content     encoded = base64.b64encode(img_bytes).decode()     return encoded In\u00a0[\u00a0]: Copied! <pre># Define the cs_sidebar() function\ndef cs_sidebar():\n    \"\"\"\n    Populate the sidebar with various content sections related to Matplotlib.\n    \"\"\"\n    st.sidebar.markdown(\n        '''[&lt;img src='data:image/png;base64,{}' class='img-fluid' width=150 &gt;](https://streamlit.io/)'''.format(\n            img_to_bytes(\"https://raw.githubusercontent.com/fralfaro/DS-Cheat-Sheets/main/docs/examples/matplotlib/matplotlib.png\")), unsafe_allow_html=True)\n\n    st.sidebar.header('Matplotlib Cheat Sheet')\n    st.sidebar.markdown('''\n&lt;small&gt;[Matplotlib](https://matplotlib.org/) is a Python 2D plotting library which produces publication-quality \nfigures in a variety of hardcopy formats and interactive environments across platforms.&lt;/small&gt;\n    ''', unsafe_allow_html=True)\n\n    # Matplotlib installation and import\n    st.sidebar.markdown('__Install and import Matplotlib__')\n    st.sidebar.code('$ pip install matplotlib')\n    st.sidebar.code('''\n# Import Matplotlib convention\n&gt;&gt;&gt; import matplotlib.pyplot as plt\n''')\n\n    # Anatomy of a figure\n    st.sidebar.markdown('__Anatomy of a figure__')\n    st.sidebar.markdown(\n        '''[&lt;img src='data:image/png;base64,{}' class='img-fluid' width=450 &gt;](https://streamlit.io/)'''.format(\n            img_to_bytes(\"https://raw.githubusercontent.com/fralfaro/DS-Cheat-Sheets/main/docs/examples/matplotlib/mlp_01.png\")), unsafe_allow_html=True)\n\n    st.sidebar.markdown('''\n    &lt;small&gt;In Matplotlib, a figure refers to the overall canvas or window that contains one or more individual plots or subplots. \n    Understanding the anatomy of a Matplotlib figure is crucial for creating and customizing your visualizations effectively. &lt;/small&gt;\n        ''', unsafe_allow_html=True)\n\n\n    # Example code for the workflow\n    st.sidebar.code('''\n    # Workflow\n    import matplotlib.pyplot as plt\n    \n    # Step 1: Prepare Data\n    x = [1, 2, 3, 4]  \n    y = [10, 20, 25, 30] \n\n    # Step 2: Create Plot\n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n\n    # Step 3: Plot\n    ax.plot(x, y, color='lightblue', linewidth=3)\n\n    # Step 4: Customized Plot\n    ax.scatter([2, 4, 6], [5, 15, 25], color='darkgreen', marker='^')\n    ax.set_xlim(1, 6.5)\n\n    # Step 5: Save Plot\n    plt.savefig('foo.png')\n\n    # Step 6: Show Plot\n    plt.show()\n        ''')\n    return None\n</pre> # Define the cs_sidebar() function def cs_sidebar():     \"\"\"     Populate the sidebar with various content sections related to Matplotlib.     \"\"\"     st.sidebar.markdown(         '''[](https://streamlit.io/)'''.format(             img_to_bytes(\"https://raw.githubusercontent.com/fralfaro/DS-Cheat-Sheets/main/docs/examples/matplotlib/matplotlib.png\")), unsafe_allow_html=True)      st.sidebar.header('Matplotlib Cheat Sheet')     st.sidebar.markdown(''' [Matplotlib](https://matplotlib.org/) is a Python 2D plotting library which produces publication-quality  figures in a variety of hardcopy formats and interactive environments across platforms.     ''', unsafe_allow_html=True)      # Matplotlib installation and import     st.sidebar.markdown('__Install and import Matplotlib__')     st.sidebar.code('$ pip install matplotlib')     st.sidebar.code(''' # Import Matplotlib convention &gt;&gt;&gt; import matplotlib.pyplot as plt ''')      # Anatomy of a figure     st.sidebar.markdown('__Anatomy of a figure__')     st.sidebar.markdown(         '''[](https://streamlit.io/)'''.format(             img_to_bytes(\"https://raw.githubusercontent.com/fralfaro/DS-Cheat-Sheets/main/docs/examples/matplotlib/mlp_01.png\")), unsafe_allow_html=True)      st.sidebar.markdown('''     In Matplotlib, a figure refers to the overall canvas or window that contains one or more individual plots or subplots.      Understanding the anatomy of a Matplotlib figure is crucial for creating and customizing your visualizations effectively.          ''', unsafe_allow_html=True)       # Example code for the workflow     st.sidebar.code('''     # Workflow     import matplotlib.pyplot as plt          # Step 1: Prepare Data     x = [1, 2, 3, 4]       y = [10, 20, 25, 30]       # Step 2: Create Plot     fig = plt.figure()     ax = fig.add_subplot(111)      # Step 3: Plot     ax.plot(x, y, color='lightblue', linewidth=3)      # Step 4: Customized Plot     ax.scatter([2, 4, 6], [5, 15, 25], color='darkgreen', marker='^')     ax.set_xlim(1, 6.5)      # Step 5: Save Plot     plt.savefig('foo.png')      # Step 6: Show Plot     plt.show()         ''')     return None In\u00a0[\u00a0]: Copied! <pre># Define the cs_body() function\ndef cs_body():\n    \"\"\"\n    Create content sections for the main body of the Streamlit cheat sheet with NumPy examples.\n    \"\"\"\n    col1, col2, col3 = st.columns(3)  # Create columns for layout\n\n    #######################################\n    # COLUMN 1\n    #######################################\n\n    # Prepare the Data\n    col1.subheader('Basic Plots ')\n\n    ## Create a scatter plot\n    col1.code('''\n    # Create a scatter plot\n    X = np.random.uniform(0, 1, 100)\n    Y = np.random.uniform(0, 1, 100)\n    plt.scatter(X, Y)\n        ''')\n\n    ## Create a bar plot\n    col1.code('''\n    # Create a bar plot\n    X = np.arange(10)\n    Y = np.random.uniform(1, 10, 10)\n    plt.bar(X, Y)\n        ''')\n\n    ## Create an image plot using imshow\n    col1.code('''\n    # Create an image plot using imshow\n    Z = np.random.uniform(0, 1, (8, 8))\n    plt.imshow(Z)\n        ''')\n\n    ## Create a contour plot\n    col1.code('''\n    # Create a contour plot\n    Z = np.random.uniform(0, 1, (8, 8))\n    plt.contourf(Z)\n    plt.show()\n        ''')\n\n    ## Create a pie chart\n    col1.code('''\n    # Create a pie chart\n    Z = np.random.uniform(0, 1, 4)\n    plt.pie(Z)\n        ''')\n\n    ## Create a histogram\n    col1.code('''\n    # Create a histogram\n    Z = np.random.normal(0, 1, 100)\n    plt.hist(Z)\n        ''')\n\n    ## Create an error bar plot\n    col1.code('''\n    # Create an error bar plot\n    X = np.arange(5)\n    Y = np.random.uniform(0, 1, 5)\n    plt.errorbar(X, Y, Y / 4)\n        ''')\n\n    ## Create a box plot\n    col1.code('''\n    # Create a box plot\n    Z = np.random.normal(0, 1, (100, 3))\n    plt.boxplot(Z)\n        ''')\n\n    # Tweak\n    col1.subheader('Tweak')\n\n    ## Create a plot with a black solid line\n    col1.code('''\n    # Create a plot with a black solid line\n    X = np.linspace(0, 10, 100)\n    Y = np.sin(X)\n    plt.plot(X, Y, color=\"black\")\n        ''')\n\n    ## Create a plot with a dashed line\n    col1.code('''\n    # Create a plot with a dashed line\n    X = np.linspace(0, 10, 100)\n    Y = np.sin(X)\n    plt.plot(X, Y, linestyle=\"--\")\n        ''')\n\n    ## Create a plot with a thicker line\n    col1.code('''\n    # Create a plot with a thicker line\n    X = np.linspace(0, 10, 100)\n    Y = np.sin(X)\n    plt.plot(X, Y, linewidth=5)\n        ''')\n\n    ## Create a plot with markers\n    col1.code('''\n    # Create a plot with markers\n    X = np.linspace(0, 10, 100)\n    Y = np.sin(X)\n    plt.plot(X, Y, marker=\"o\")\n        ''')\n\n    # Save\n    col1.subheader('Save')\n    col1.code('''\n    # Save the figure as a PNG file with higher resolution (300 dpi)\n    fig.savefig(\"my-first-figure.png\", dpi=300)\n\n    # Save the figure as a PDF file\n    fig.savefig(\"my-first-figure.pdf\")\n        ''')\n\n    #######################################\n    # COLUMN 2\n    #######################################\n\n    # Markers\n    col2.subheader('Organize')\n\n    ## Create a plot with two lines on the same axes\n    col2.code('''\n    # Create a plot with two lines on the same axes\n    X = np.linspace(0, 10, 100)\n    Y1, Y2 = np.sin(X), np.cos(X)\n    plt.plot(X, Y1, X, Y2)\n        ''')\n\n    ## Create a figure with two subplots (vertically stacked)\n    col2.code('''\n    # Create a figure with two subplots (vertically stacked)\n    X = np.linspace(0, 10, 100)\n    Y1, Y2 = np.sin(X), np.cos(X)\n    fig, (ax1, ax2) = plt.subplots(2, 1)\n    ax1.plot(X, Y1, color=\"C1\")\n    ax2.plot(X, Y2, color=\"C0\")\n        ''')\n\n    ## Create a figure with two subplots (horizontally aligned)\n    col2.code('''\n    # Create a figure with two subplots (horizontally aligned)\n    X = np.linspace(0, 10, 100)\n    Y1, Y2 = np.sin(X), np.cos(X)\n    fig, (ax1, ax2) = plt.subplots(1, 2)\n    ax1.plot(Y1, X, color=\"C1\")\n    ax2.plot(Y2, X, color=\"C0\")\n        ''')\n\n    # Label\n    col2.subheader('Label')\n\n    ## Create data and plot a sine wave\n    col2.code('''\n    # Create data and plot a sine wave\n    X = np.linspace(0, 10, 100)\n    Y = np.sin(X)\n    plt.plot(X, Y)\n        ''')\n\n    ## Modify plot properties\n    col2.code('''\n    # Modify plot properties\n    X = np.linspace(0, 10, 100)\n    Y = np.sin(X)\n    plt.plot(X, Y)\n    plt.title(\"A Sine wave\")\n    plt.xlabel(\"Time\")\n    plt.ylabel(None)\n        ''')\n\n    # Figure, axes &amp; spines\n    col2.subheader('Figure, axes &amp; spines')\n    col2.code('''\n    # Create a 3x3 grid of subplots\n    fig, axs = plt.subplots(3, 3)\n\n    # Set face colors for specific subplots\n    axs[0, 0].set_facecolor(\"#ddddff\")\n    axs[2, 2].set_facecolor(\"#ffffdd\")\n        ''')\n\n    col2.code('''\n    # Create a 3x3 grid of subplots\n    fig, axs = plt.subplots(3, 3)\n\n    # Add a grid specification and set face color for a specific subplot\n    gs = fig.add_gridspec(3, 3)\n    ax = fig.add_subplot(gs[0, :])\n    ax.set_facecolor(\"#ddddff\")\n        ''')\n\n    col2.code('''\n    # Create a figure with a single subplot\n    fig, ax = plt.subplots()\n\n    # Remove top and right spines from the subplot\n    ax.spines[\"top\"].set_color(\"None\")\n    ax.spines[\"right\"].set_color(\"None\")\n        ''')\n\n    # Colors\n    col2.subheader('Colors')\n    col2.code('''\n    # Get a list of named colors\n    named_colors = plt.colormaps()  \n    print(\"Colors:\",named_colors)\n        ''')\n\n    #######################################\n    # COLUMN 3\n    #######################################\n\n    # Ticks &amp; labels\n    col3.subheader('Ticks &amp; labels')\n    col3.code('''\n    from matplotlib.ticker import MultipleLocator as ML\n    from matplotlib.ticker import ScalarFormatter as SF\n\n    # Create a figure with a single subplot\n    fig, ax = plt.subplots()\n    \n    # Set minor tick locations and formatter for the x-axis\n    ax.xaxis.set_minor_locator(ML(0.2))\n    ax.xaxis.set_minor_formatter(SF())\n    \n    # Rotate minor tick labels on the x-axis\n    ax.tick_params(axis='x', which='minor', rotation=90)\n        ''')\n\n    # Lines &amp; markers\n    col3.subheader('Lines &amp; markers')\n    col3.code('''\n    # Generate data and create a plot\n    X = np.linspace(0.1, 10 * np.pi, 1000)\n    Y = np.sin(X)\n    plt.plot(X, Y, \"C1o:\", markevery=25, mec=\"1.0\")\n        ''')\n\n    # Scales &amp; projections\n    col3.subheader('Scales &amp; projections')\n    col3.code('''\n    # Create a figure with a single subplot\n    fig, ax = plt.subplots()\n    \n    # Set x-axis scale to logarithmic\n    ax.set_xscale(\"log\")\n    \n    # Plot data with specified formatting\n    ax.plot(X, Y, \"C1o-\", markevery=25, mec=\"1.0\")\n        ''')\n\n    # Text &amp; ornaments\n    col3.subheader('Scales &amp; projections')\n    col3.code('''\n    # Create a figure with a single subplot\n    fig, ax = plt.subplots()\n    \n    # Fill the area between horizontal lines with a curve\n    ax.fill_betweenx([-1, 1], [0], [2*np.pi])\n    \n    # Add a text annotation to the plot\n    ax.text(0, -1, r\" Period $\\Phi$\")\n        ''')\n\n    # Legend\n    col3.subheader('Legend')\n    col3.code('''\n    # Create a figure with a single subplot\n    fig, ax = plt.subplots()\n    \n    # Plot sine and cosine curves with specified colors and labels\n    ax.plot(X, np.sin(X), \"C0\", label=\"Sine\")\n    ax.plot(X, np.cos(X), \"C1\", label=\"Cosine\")\n    \n    # Add a legend with customized positioning and formatting\n    ax.legend(bbox_to_anchor=(0, 1, 1, 0.1), ncol=2, mode=\"expand\", loc=\"lower left\")\n        ''')\n\n    # Annotation\n    col3.subheader('Annotation')\n    col3.code('''\n    # Create a figure with a single subplot\n    fig, ax = plt.subplots()\n    \n    ax.plot(X, Y, \"C1o:\", markevery=25, mec=\"1.0\")\n    \n    # Add an annotation \"A\" with an arrow\n    ax.annotate(\"A\", (X[250], Y[250]), (X[250], -1),\n                ha=\"center\", va=\"center\",\n                arrowprops={\"arrowstyle\": \"-&gt;\", \"color\": \"C1\"})\n        ''')\n</pre> # Define the cs_body() function def cs_body():     \"\"\"     Create content sections for the main body of the Streamlit cheat sheet with NumPy examples.     \"\"\"     col1, col2, col3 = st.columns(3)  # Create columns for layout      #######################################     # COLUMN 1     #######################################      # Prepare the Data     col1.subheader('Basic Plots ')      ## Create a scatter plot     col1.code('''     # Create a scatter plot     X = np.random.uniform(0, 1, 100)     Y = np.random.uniform(0, 1, 100)     plt.scatter(X, Y)         ''')      ## Create a bar plot     col1.code('''     # Create a bar plot     X = np.arange(10)     Y = np.random.uniform(1, 10, 10)     plt.bar(X, Y)         ''')      ## Create an image plot using imshow     col1.code('''     # Create an image plot using imshow     Z = np.random.uniform(0, 1, (8, 8))     plt.imshow(Z)         ''')      ## Create a contour plot     col1.code('''     # Create a contour plot     Z = np.random.uniform(0, 1, (8, 8))     plt.contourf(Z)     plt.show()         ''')      ## Create a pie chart     col1.code('''     # Create a pie chart     Z = np.random.uniform(0, 1, 4)     plt.pie(Z)         ''')      ## Create a histogram     col1.code('''     # Create a histogram     Z = np.random.normal(0, 1, 100)     plt.hist(Z)         ''')      ## Create an error bar plot     col1.code('''     # Create an error bar plot     X = np.arange(5)     Y = np.random.uniform(0, 1, 5)     plt.errorbar(X, Y, Y / 4)         ''')      ## Create a box plot     col1.code('''     # Create a box plot     Z = np.random.normal(0, 1, (100, 3))     plt.boxplot(Z)         ''')      # Tweak     col1.subheader('Tweak')      ## Create a plot with a black solid line     col1.code('''     # Create a plot with a black solid line     X = np.linspace(0, 10, 100)     Y = np.sin(X)     plt.plot(X, Y, color=\"black\")         ''')      ## Create a plot with a dashed line     col1.code('''     # Create a plot with a dashed line     X = np.linspace(0, 10, 100)     Y = np.sin(X)     plt.plot(X, Y, linestyle=\"--\")         ''')      ## Create a plot with a thicker line     col1.code('''     # Create a plot with a thicker line     X = np.linspace(0, 10, 100)     Y = np.sin(X)     plt.plot(X, Y, linewidth=5)         ''')      ## Create a plot with markers     col1.code('''     # Create a plot with markers     X = np.linspace(0, 10, 100)     Y = np.sin(X)     plt.plot(X, Y, marker=\"o\")         ''')      # Save     col1.subheader('Save')     col1.code('''     # Save the figure as a PNG file with higher resolution (300 dpi)     fig.savefig(\"my-first-figure.png\", dpi=300)      # Save the figure as a PDF file     fig.savefig(\"my-first-figure.pdf\")         ''')      #######################################     # COLUMN 2     #######################################      # Markers     col2.subheader('Organize')      ## Create a plot with two lines on the same axes     col2.code('''     # Create a plot with two lines on the same axes     X = np.linspace(0, 10, 100)     Y1, Y2 = np.sin(X), np.cos(X)     plt.plot(X, Y1, X, Y2)         ''')      ## Create a figure with two subplots (vertically stacked)     col2.code('''     # Create a figure with two subplots (vertically stacked)     X = np.linspace(0, 10, 100)     Y1, Y2 = np.sin(X), np.cos(X)     fig, (ax1, ax2) = plt.subplots(2, 1)     ax1.plot(X, Y1, color=\"C1\")     ax2.plot(X, Y2, color=\"C0\")         ''')      ## Create a figure with two subplots (horizontally aligned)     col2.code('''     # Create a figure with two subplots (horizontally aligned)     X = np.linspace(0, 10, 100)     Y1, Y2 = np.sin(X), np.cos(X)     fig, (ax1, ax2) = plt.subplots(1, 2)     ax1.plot(Y1, X, color=\"C1\")     ax2.plot(Y2, X, color=\"C0\")         ''')      # Label     col2.subheader('Label')      ## Create data and plot a sine wave     col2.code('''     # Create data and plot a sine wave     X = np.linspace(0, 10, 100)     Y = np.sin(X)     plt.plot(X, Y)         ''')      ## Modify plot properties     col2.code('''     # Modify plot properties     X = np.linspace(0, 10, 100)     Y = np.sin(X)     plt.plot(X, Y)     plt.title(\"A Sine wave\")     plt.xlabel(\"Time\")     plt.ylabel(None)         ''')      # Figure, axes &amp; spines     col2.subheader('Figure, axes &amp; spines')     col2.code('''     # Create a 3x3 grid of subplots     fig, axs = plt.subplots(3, 3)      # Set face colors for specific subplots     axs[0, 0].set_facecolor(\"#ddddff\")     axs[2, 2].set_facecolor(\"#ffffdd\")         ''')      col2.code('''     # Create a 3x3 grid of subplots     fig, axs = plt.subplots(3, 3)      # Add a grid specification and set face color for a specific subplot     gs = fig.add_gridspec(3, 3)     ax = fig.add_subplot(gs[0, :])     ax.set_facecolor(\"#ddddff\")         ''')      col2.code('''     # Create a figure with a single subplot     fig, ax = plt.subplots()      # Remove top and right spines from the subplot     ax.spines[\"top\"].set_color(\"None\")     ax.spines[\"right\"].set_color(\"None\")         ''')      # Colors     col2.subheader('Colors')     col2.code('''     # Get a list of named colors     named_colors = plt.colormaps()       print(\"Colors:\",named_colors)         ''')      #######################################     # COLUMN 3     #######################################      # Ticks &amp; labels     col3.subheader('Ticks &amp; labels')     col3.code('''     from matplotlib.ticker import MultipleLocator as ML     from matplotlib.ticker import ScalarFormatter as SF      # Create a figure with a single subplot     fig, ax = plt.subplots()          # Set minor tick locations and formatter for the x-axis     ax.xaxis.set_minor_locator(ML(0.2))     ax.xaxis.set_minor_formatter(SF())          # Rotate minor tick labels on the x-axis     ax.tick_params(axis='x', which='minor', rotation=90)         ''')      # Lines &amp; markers     col3.subheader('Lines &amp; markers')     col3.code('''     # Generate data and create a plot     X = np.linspace(0.1, 10 * np.pi, 1000)     Y = np.sin(X)     plt.plot(X, Y, \"C1o:\", markevery=25, mec=\"1.0\")         ''')      # Scales &amp; projections     col3.subheader('Scales &amp; projections')     col3.code('''     # Create a figure with a single subplot     fig, ax = plt.subplots()          # Set x-axis scale to logarithmic     ax.set_xscale(\"log\")          # Plot data with specified formatting     ax.plot(X, Y, \"C1o-\", markevery=25, mec=\"1.0\")         ''')      # Text &amp; ornaments     col3.subheader('Scales &amp; projections')     col3.code('''     # Create a figure with a single subplot     fig, ax = plt.subplots()          # Fill the area between horizontal lines with a curve     ax.fill_betweenx([-1, 1], [0], [2*np.pi])          # Add a text annotation to the plot     ax.text(0, -1, r\" Period $\\Phi$\")         ''')      # Legend     col3.subheader('Legend')     col3.code('''     # Create a figure with a single subplot     fig, ax = plt.subplots()          # Plot sine and cosine curves with specified colors and labels     ax.plot(X, np.sin(X), \"C0\", label=\"Sine\")     ax.plot(X, np.cos(X), \"C1\", label=\"Cosine\")          # Add a legend with customized positioning and formatting     ax.legend(bbox_to_anchor=(0, 1, 1, 0.1), ncol=2, mode=\"expand\", loc=\"lower left\")         ''')      # Annotation     col3.subheader('Annotation')     col3.code('''     # Create a figure with a single subplot     fig, ax = plt.subplots()          ax.plot(X, Y, \"C1o:\", markevery=25, mec=\"1.0\")          # Add an annotation \"A\" with an arrow     ax.annotate(\"A\", (X[250], Y[250]), (X[250], -1),                 ha=\"center\", va=\"center\",                 arrowprops={\"arrowstyle\": \"-&gt;\", \"color\": \"C1\"})         ''') In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre># Run the main function if the script is executed directly\nif __name__ == '__main__':\n    main()\n</pre> # Run the main function if the script is executed directly if __name__ == '__main__':     main()"},{"location":"examples/matplotlib/matplotlib/","title":"Matplotlib","text":"In\u00a0[1]: Copied! <pre># Import matplotlib convention\nimport matplotlib.pyplot as plt\n</pre> # Import matplotlib convention import matplotlib.pyplot as plt In\u00a0[2]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\n\n# Prepare Data\nx = np.linspace(0, 2*np.pi, 100)\ny = np.sin(x)\n\n# Create Plot\nfig, ax = plt.subplots()\n\n# Plot Data\nax.plot(x, y)\n\n# Customize Plot\nax.set_xlabel('X-axis')\nax.set_ylabel('Y-axis')\nax.set_title('Sine Function')\nax.grid(True)\n\n# Save Plot\nplt.savefig('sine_plot.png')\n\n# Show Plot\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt  # Prepare Data x = np.linspace(0, 2*np.pi, 100) y = np.sin(x)  # Create Plot fig, ax = plt.subplots()  # Plot Data ax.plot(x, y)  # Customize Plot ax.set_xlabel('X-axis') ax.set_ylabel('Y-axis') ax.set_title('Sine Function') ax.grid(True)  # Save Plot plt.savefig('sine_plot.png')  # Show Plot plt.show() In\u00a0[3]: Copied! <pre># Create a scatter plot\nX = np.random.uniform(0, 1, 100)\nY = np.random.uniform(0, 1, 100)\nplt.scatter(X, Y)\nplt.show()\n</pre> # Create a scatter plot X = np.random.uniform(0, 1, 100) Y = np.random.uniform(0, 1, 100) plt.scatter(X, Y) plt.show() In\u00a0[4]: Copied! <pre># Create a bar plot\nX = np.arange(10)\nY = np.random.uniform(1, 10, 10)\nplt.bar(X, Y)\nplt.show()\n</pre> # Create a bar plot X = np.arange(10) Y = np.random.uniform(1, 10, 10) plt.bar(X, Y) plt.show() In\u00a0[5]: Copied! <pre># Create an image plot using imshow\nZ = np.random.uniform(0, 1, (8, 8))\nplt.imshow(Z)\nplt.show()\n</pre> # Create an image plot using imshow Z = np.random.uniform(0, 1, (8, 8)) plt.imshow(Z) plt.show() In\u00a0[6]: Copied! <pre># Create a contour plot\nZ = np.random.uniform(0, 1, (8, 8))\nplt.contourf(Z)\nplt.show()\n</pre> # Create a contour plot Z = np.random.uniform(0, 1, (8, 8)) plt.contourf(Z) plt.show() In\u00a0[7]: Copied! <pre># Create a pie chart\nZ = np.random.uniform(0, 1, 4)\nplt.pie(Z)\nplt.show()\n</pre> # Create a pie chart Z = np.random.uniform(0, 1, 4) plt.pie(Z) plt.show() In\u00a0[8]: Copied! <pre># Create a histogram\nZ = np.random.normal(0, 1, 100)\nplt.hist(Z)\nplt.show()\n</pre> # Create a histogram Z = np.random.normal(0, 1, 100) plt.hist(Z) plt.show() In\u00a0[9]: Copied! <pre># Create an error bar plot\nX = np.arange(5)\nY = np.random.uniform(0, 1, 5)\nplt.errorbar(X, Y, Y / 4)\nplt.show()\n</pre> # Create an error bar plot X = np.arange(5) Y = np.random.uniform(0, 1, 5) plt.errorbar(X, Y, Y / 4) plt.show() In\u00a0[10]: Copied! <pre># Create a box plot\nZ = np.random.normal(0, 1, (100, 3))\nplt.boxplot(Z)\nplt.show()\n</pre> # Create a box plot Z = np.random.normal(0, 1, (100, 3)) plt.boxplot(Z) plt.show() In\u00a0[11]: Copied! <pre># Create a plot with a black solid line\nX = np.linspace(0, 10, 100)\nY = np.sin(X)\nplt.plot(X, Y, color=\"black\")\nplt.show()\n</pre> # Create a plot with a black solid line X = np.linspace(0, 10, 100) Y = np.sin(X) plt.plot(X, Y, color=\"black\") plt.show() In\u00a0[12]: Copied! <pre># Create a plot with a dashed line\nX = np.linspace(0, 10, 100)\nY = np.sin(X)\nplt.plot(X, Y, linestyle=\"--\")\nplt.show()\n</pre> # Create a plot with a dashed line X = np.linspace(0, 10, 100) Y = np.sin(X) plt.plot(X, Y, linestyle=\"--\") plt.show() In\u00a0[13]: Copied! <pre># Create a plot with a thicker line\nX = np.linspace(0, 10, 100)\nY = np.sin(X)\nplt.plot(X, Y, linewidth=5)\nplt.show()\n</pre> # Create a plot with a thicker line X = np.linspace(0, 10, 100) Y = np.sin(X) plt.plot(X, Y, linewidth=5) plt.show() In\u00a0[14]: Copied! <pre># Create a plot with markers\nX = np.linspace(0, 10, 100)\nY = np.sin(X)\nplt.plot(X, Y, marker=\"o\")\nplt.show()\n</pre> # Create a plot with markers X = np.linspace(0, 10, 100) Y = np.sin(X) plt.plot(X, Y, marker=\"o\") plt.show() In\u00a0[15]: Copied! <pre># Create a plot with two lines on the same axes\nX = np.linspace(0, 10, 100)\nY1, Y2 = np.sin(X), np.cos(X)\nplt.plot(X, Y1, X, Y2)\nplt.show()\n</pre> # Create a plot with two lines on the same axes X = np.linspace(0, 10, 100) Y1, Y2 = np.sin(X), np.cos(X) plt.plot(X, Y1, X, Y2) plt.show() In\u00a0[16]: Copied! <pre># Create a figure with two subplots (vertically stacked)\nX = np.linspace(0, 10, 100)\nY1, Y2 = np.sin(X), np.cos(X)\nfig, (ax1, ax2) = plt.subplots(2, 1)\nax1.plot(X, Y1, color=\"C1\")\nax2.plot(X, Y2, color=\"C0\")\nplt.show()\n</pre> # Create a figure with two subplots (vertically stacked) X = np.linspace(0, 10, 100) Y1, Y2 = np.sin(X), np.cos(X) fig, (ax1, ax2) = plt.subplots(2, 1) ax1.plot(X, Y1, color=\"C1\") ax2.plot(X, Y2, color=\"C0\") plt.show() In\u00a0[17]: Copied! <pre># Create a figure with two subplots (horizontally aligned)\nX = np.linspace(0, 10, 100)\nY1, Y2 = np.sin(X), np.cos(X)\nfig, (ax1, ax2) = plt.subplots(1, 2)\nax1.plot(Y1, X, color=\"C1\")\nax2.plot(Y2, X, color=\"C0\")\nplt.show()\n</pre> # Create a figure with two subplots (horizontally aligned) X = np.linspace(0, 10, 100) Y1, Y2 = np.sin(X), np.cos(X) fig, (ax1, ax2) = plt.subplots(1, 2) ax1.plot(Y1, X, color=\"C1\") ax2.plot(Y2, X, color=\"C0\") plt.show() In\u00a0[18]: Copied! <pre># Create data and plot a sine wave\nX = np.linspace(0, 10, 100)\nY = np.sin(X)\nplt.plot(X, Y)\nplt.show()\n</pre> # Create data and plot a sine wave X = np.linspace(0, 10, 100) Y = np.sin(X) plt.plot(X, Y) plt.show() In\u00a0[19]: Copied! <pre># Modify plot properties\nX = np.linspace(0, 10, 100)\nY = np.sin(X)\nplt.plot(X, Y)\nplt.title(\"A Sine wave\")\nplt.xlabel(\"Time\")\nplt.ylabel(None)\nplt.show()\n</pre> # Modify plot properties X = np.linspace(0, 10, 100) Y = np.sin(X) plt.plot(X, Y) plt.title(\"A Sine wave\") plt.xlabel(\"Time\") plt.ylabel(None) plt.show() In\u00a0[20]: Copied! <pre># Create a 3x3 grid of subplots\nfig, axs = plt.subplots(3, 3)\n\n# Set face colors for specific subplots\naxs[0, 0].set_facecolor(\"#ddddff\")\naxs[2, 2].set_facecolor(\"#ffffdd\")\n</pre> # Create a 3x3 grid of subplots fig, axs = plt.subplots(3, 3)  # Set face colors for specific subplots axs[0, 0].set_facecolor(\"#ddddff\") axs[2, 2].set_facecolor(\"#ffffdd\") In\u00a0[21]: Copied! <pre># Create a 3x3 grid of subplots\nfig, axs = plt.subplots(3, 3)\n\n# Add a grid specification and set face color for a specific subplot\ngs = fig.add_gridspec(3, 3)\nax = fig.add_subplot(gs[0, :])\nax.set_facecolor(\"#ddddff\")\n</pre> # Create a 3x3 grid of subplots fig, axs = plt.subplots(3, 3)  # Add a grid specification and set face color for a specific subplot gs = fig.add_gridspec(3, 3) ax = fig.add_subplot(gs[0, :]) ax.set_facecolor(\"#ddddff\") In\u00a0[22]: Copied! <pre># Create a figure with a single subplot\nfig, ax = plt.subplots()\n\n# Remove top and right spines from the subplot\nax.spines[\"top\"].set_color(\"None\")\nax.spines[\"right\"].set_color(\"None\")\n</pre> # Create a figure with a single subplot fig, ax = plt.subplots()  # Remove top and right spines from the subplot ax.spines[\"top\"].set_color(\"None\") ax.spines[\"right\"].set_color(\"None\") In\u00a0[23]: Copied! <pre># Import the necessary libraries\nfrom matplotlib.ticker import MultipleLocator as ML\nfrom matplotlib.ticker import ScalarFormatter as SF\n\n\n# Create a figure with a single subplot\nfig, ax = plt.subplots()\n\n# Set minor tick locations and formatter for the x-axis\nax.xaxis.set_minor_locator(ML(0.2))\nax.xaxis.set_minor_formatter(SF())\n\n# Rotate minor tick labels on the x-axis\nax.tick_params(axis='x', which='minor', rotation=90)\n</pre> # Import the necessary libraries from matplotlib.ticker import MultipleLocator as ML from matplotlib.ticker import ScalarFormatter as SF   # Create a figure with a single subplot fig, ax = plt.subplots()  # Set minor tick locations and formatter for the x-axis ax.xaxis.set_minor_locator(ML(0.2)) ax.xaxis.set_minor_formatter(SF())  # Rotate minor tick labels on the x-axis ax.tick_params(axis='x', which='minor', rotation=90) In\u00a0[24]: Copied! <pre># Generate data and create a plot\nX = np.linspace(0.1, 10 * np.pi, 1000)\nY = np.sin(X)\nplt.plot(X, Y, \"C1o:\", markevery=25, mec=\"1.0\")\n\n# Display the plot\nplt.show()\n</pre> # Generate data and create a plot X = np.linspace(0.1, 10 * np.pi, 1000) Y = np.sin(X) plt.plot(X, Y, \"C1o:\", markevery=25, mec=\"1.0\")  # Display the plot plt.show() In\u00a0[25]: Copied! <pre># Create a figure with a single subplot\nfig, ax = plt.subplots()\n\n# Set x-axis scale to logarithmic\nax.set_xscale(\"log\")\n\n# Plot data with specified formatting\nax.plot(X, Y, \"C1o-\", markevery=25, mec=\"1.0\")\n\n# Display the plot\nplt.show()\n</pre> # Create a figure with a single subplot fig, ax = plt.subplots()  # Set x-axis scale to logarithmic ax.set_xscale(\"log\")  # Plot data with specified formatting ax.plot(X, Y, \"C1o-\", markevery=25, mec=\"1.0\")  # Display the plot plt.show() In\u00a0[26]: Copied! <pre># Create a figure with a single subplot\nfig, ax = plt.subplots()\n\n# Fill the area between horizontal lines with a curve\nax.fill_betweenx([-1, 1], [0], [2*np.pi])\n\n# Add a text annotation to the plot\nax.text(0, -1, r\" Period $\\Phi$\")\n\n# Display the plot\nplt.show()\n</pre> # Create a figure with a single subplot fig, ax = plt.subplots()  # Fill the area between horizontal lines with a curve ax.fill_betweenx([-1, 1], [0], [2*np.pi])  # Add a text annotation to the plot ax.text(0, -1, r\" Period $\\Phi$\")  # Display the plot plt.show() In\u00a0[27]: Copied! <pre># Create a figure with a single subplot\nfig, ax = plt.subplots()\n\n# Plot sine and cosine curves with specified colors and labels\nax.plot(X, np.sin(X), \"C0\", label=\"Sine\")\nax.plot(X, np.cos(X), \"C1\", label=\"Cosine\")\n\n# Add a legend with customized positioning and formatting\nax.legend(bbox_to_anchor=(0, 1, 1, 0.1), ncol=2, mode=\"expand\", loc=\"lower left\")\n\n# Display the plot\nplt.show()\n</pre> # Create a figure with a single subplot fig, ax = plt.subplots()  # Plot sine and cosine curves with specified colors and labels ax.plot(X, np.sin(X), \"C0\", label=\"Sine\") ax.plot(X, np.cos(X), \"C1\", label=\"Cosine\")  # Add a legend with customized positioning and formatting ax.legend(bbox_to_anchor=(0, 1, 1, 0.1), ncol=2, mode=\"expand\", loc=\"lower left\")  # Display the plot plt.show() In\u00a0[28]: Copied! <pre># Create a figure with a single subplot\nfig, ax = plt.subplots()\n\nax.plot(X, Y, \"C1o:\", markevery=25, mec=\"1.0\")\n\n# Add an annotation \"A\" with an arrow\nax.annotate(\"A\", (X[250], Y[250]), (X[250], -1),\n            ha=\"center\", va=\"center\",\n            arrowprops={\"arrowstyle\": \"-&gt;\", \"color\": \"C1\"})\n\n# Display the plot\nplt.show()\n</pre> # Create a figure with a single subplot fig, ax = plt.subplots()  ax.plot(X, Y, \"C1o:\", markevery=25, mec=\"1.0\")  # Add an annotation \"A\" with an arrow ax.annotate(\"A\", (X[250], Y[250]), (X[250], -1),             ha=\"center\", va=\"center\",             arrowprops={\"arrowstyle\": \"-&gt;\", \"color\": \"C1\"})  # Display the plot plt.show() In\u00a0[31]: Copied! <pre>import math\n\nfrom matplotlib.patches import Rectangle\nimport matplotlib.pyplot as plt\nimport matplotlib.colors as mcolors\n\n\ndef plot_colortable(colors, *, ncols=4, sort_colors=True):\n\n    cell_width = 212\n    cell_height = 22\n    swatch_width = 48\n    margin = 12\n\n    # Sort colors by hue, saturation, value and name.\n    if sort_colors is True:\n        names = sorted(\n            colors, key=lambda c: tuple(mcolors.rgb_to_hsv(mcolors.to_rgb(c))))\n    else:\n        names = list(colors)\n\n    n = len(names)\n    nrows = math.ceil(n / ncols)\n\n    width = cell_width * 4 + 2 * margin\n    height = cell_height * nrows + 2 * margin\n    dpi = 72\n\n    fig, ax = plt.subplots(figsize=(width / dpi, height / dpi), dpi=dpi)\n    fig.subplots_adjust(margin/width, margin/height,\n                        (width-margin)/width, (height-margin)/height)\n    ax.set_xlim(0, cell_width * 4)\n    ax.set_ylim(cell_height * (nrows-0.5), -cell_height/2.)\n    ax.yaxis.set_visible(False)\n    ax.xaxis.set_visible(False)\n    ax.set_axis_off()\n\n    for i, name in enumerate(names):\n        row = i % nrows\n        col = i // nrows\n        y = row * cell_height\n\n        swatch_start_x = cell_width * col\n        text_pos_x = cell_width * col + swatch_width + 7\n\n        ax.text(text_pos_x, y, name, fontsize=14,\n                horizontalalignment='left',\n                verticalalignment='center')\n\n        ax.add_patch(\n            Rectangle(xy=(swatch_start_x, y-9), width=swatch_width,\n                      height=18, facecolor=colors[name], edgecolor='0.7')\n        )\n\n    return fig\n</pre> import math  from matplotlib.patches import Rectangle import matplotlib.pyplot as plt import matplotlib.colors as mcolors   def plot_colortable(colors, *, ncols=4, sort_colors=True):      cell_width = 212     cell_height = 22     swatch_width = 48     margin = 12      # Sort colors by hue, saturation, value and name.     if sort_colors is True:         names = sorted(             colors, key=lambda c: tuple(mcolors.rgb_to_hsv(mcolors.to_rgb(c))))     else:         names = list(colors)      n = len(names)     nrows = math.ceil(n / ncols)      width = cell_width * 4 + 2 * margin     height = cell_height * nrows + 2 * margin     dpi = 72      fig, ax = plt.subplots(figsize=(width / dpi, height / dpi), dpi=dpi)     fig.subplots_adjust(margin/width, margin/height,                         (width-margin)/width, (height-margin)/height)     ax.set_xlim(0, cell_width * 4)     ax.set_ylim(cell_height * (nrows-0.5), -cell_height/2.)     ax.yaxis.set_visible(False)     ax.xaxis.set_visible(False)     ax.set_axis_off()      for i, name in enumerate(names):         row = i % nrows         col = i // nrows         y = row * cell_height          swatch_start_x = cell_width * col         text_pos_x = cell_width * col + swatch_width + 7          ax.text(text_pos_x, y, name, fontsize=14,                 horizontalalignment='left',                 verticalalignment='center')          ax.add_patch(             Rectangle(xy=(swatch_start_x, y-9), width=swatch_width,                       height=18, facecolor=colors[name], edgecolor='0.7')         )      return fig In\u00a0[33]: Copied! <pre># CSS Colors\nplot_colortable(mcolors.CSS4_COLORS)\nplt.show()\n</pre> # CSS Colors plot_colortable(mcolors.CSS4_COLORS) plt.show() In\u00a0[36]: Copied! <pre># Get a list of named colors\nnamed_colors = plt.colormaps()  \nprint(\"Colors:\",named_colors)\n</pre> # Get a list of named colors named_colors = plt.colormaps()   print(\"Colors:\",named_colors) <pre>Colors: ['magma', 'inferno', 'plasma', 'viridis', 'cividis', 'twilight', 'twilight_shifted', 'turbo', 'Blues', 'BrBG', 'BuGn', 'BuPu', 'CMRmap', 'GnBu', 'Greens', 'Greys', 'OrRd', 'Oranges', 'PRGn', 'PiYG', 'PuBu', 'PuBuGn', 'PuOr', 'PuRd', 'Purples', 'RdBu', 'RdGy', 'RdPu', 'RdYlBu', 'RdYlGn', 'Reds', 'Spectral', 'Wistia', 'YlGn', 'YlGnBu', 'YlOrBr', 'YlOrRd', 'afmhot', 'autumn', 'binary', 'bone', 'brg', 'bwr', 'cool', 'coolwarm', 'copper', 'cubehelix', 'flag', 'gist_earth', 'gist_gray', 'gist_heat', 'gist_ncar', 'gist_rainbow', 'gist_stern', 'gist_yarg', 'gnuplot', 'gnuplot2', 'gray', 'hot', 'hsv', 'jet', 'nipy_spectral', 'ocean', 'pink', 'prism', 'rainbow', 'seismic', 'spring', 'summer', 'terrain', 'winter', 'Accent', 'Dark2', 'Paired', 'Pastel1', 'Pastel2', 'Set1', 'Set2', 'Set3', 'tab10', 'tab20', 'tab20b', 'tab20c', 'magma_r', 'inferno_r', 'plasma_r', 'viridis_r', 'cividis_r', 'twilight_r', 'twilight_shifted_r', 'turbo_r', 'Blues_r', 'BrBG_r', 'BuGn_r', 'BuPu_r', 'CMRmap_r', 'GnBu_r', 'Greens_r', 'Greys_r', 'OrRd_r', 'Oranges_r', 'PRGn_r', 'PiYG_r', 'PuBu_r', 'PuBuGn_r', 'PuOr_r', 'PuRd_r', 'Purples_r', 'RdBu_r', 'RdGy_r', 'RdPu_r', 'RdYlBu_r', 'RdYlGn_r', 'Reds_r', 'Spectral_r', 'Wistia_r', 'YlGn_r', 'YlGnBu_r', 'YlOrBr_r', 'YlOrRd_r', 'afmhot_r', 'autumn_r', 'binary_r', 'bone_r', 'brg_r', 'bwr_r', 'cool_r', 'coolwarm_r', 'copper_r', 'cubehelix_r', 'flag_r', 'gist_earth_r', 'gist_gray_r', 'gist_heat_r', 'gist_ncar_r', 'gist_rainbow_r', 'gist_stern_r', 'gist_yarg_r', 'gnuplot_r', 'gnuplot2_r', 'gray_r', 'hot_r', 'hsv_r', 'jet_r', 'nipy_spectral_r', 'ocean_r', 'pink_r', 'prism_r', 'rainbow_r', 'seismic_r', 'spring_r', 'summer_r', 'terrain_r', 'winter_r', 'Accent_r', 'Dark2_r', 'Paired_r', 'Pastel1_r', 'Pastel2_r', 'Set1_r', 'Set2_r', 'Set3_r', 'tab10_r', 'tab20_r', 'tab20b_r', 'tab20c_r']\n</pre>"},{"location":"examples/matplotlib/matplotlib/#matplotlib","title":"Matplotlib\u00b6","text":"<p>Matplotlib is a Python 2D plotting library which produces publication-quality figures in a variety of hardcopy formats and interactive environments across platforms.</p>"},{"location":"examples/matplotlib/matplotlib/#install-and-import-matplotlib","title":"Install and import Matplotlib\u00b6","text":"<p><code>$ pip install matplotlib</code></p>"},{"location":"examples/matplotlib/matplotlib/#anatomy-of-a-figure","title":"Anatomy of a figure\u00b6","text":"<p>In Matplotlib, a figure refers to the overall canvas or window that contains one or more individual plots or subplots. Understanding the anatomy of a Matplotlib figure is crucial for creating and customizing your visualizations effectively.</p>"},{"location":"examples/matplotlib/matplotlib/#basic-plots","title":"Basic Plots\u00b6","text":""},{"location":"examples/matplotlib/matplotlib/#tweak","title":"Tweak\u00b6","text":""},{"location":"examples/matplotlib/matplotlib/#organize","title":"Organize\u00b6","text":""},{"location":"examples/matplotlib/matplotlib/#label","title":"Label\u00b6","text":""},{"location":"examples/matplotlib/matplotlib/#figure-axes-spines","title":"Figure, axes &amp; spines\u00b6","text":""},{"location":"examples/matplotlib/matplotlib/#ticks-labels","title":"Ticks &amp; labels\u00b6","text":""},{"location":"examples/matplotlib/matplotlib/#lines-markers","title":"Lines &amp; markers\u00b6","text":""},{"location":"examples/matplotlib/matplotlib/#scales-projections","title":"Scales &amp; projections\u00b6","text":""},{"location":"examples/matplotlib/matplotlib/#text-ornaments","title":"Text &amp; ornaments\u00b6","text":""},{"location":"examples/matplotlib/matplotlib/#legend","title":"Legend\u00b6","text":""},{"location":"examples/matplotlib/matplotlib/#annotation","title":"Annotation\u00b6","text":""},{"location":"examples/matplotlib/matplotlib/#colors","title":"Colors\u00b6","text":""},{"location":"examples/matplotlib/matplotlib/#save","title":"Save\u00b6","text":"<pre># Save the figure as a PNG file with higher resolution (300 dpi)\nfig.savefig(\"my-first-figure.png\", dpi=300)\n\n# Save the figure as a PDF file\nfig.savefig(\"my-first-figure.pdf\")\n</pre>"},{"location":"examples/numpy/app/","title":"App","text":"In\u00a0[\u00a0]: Copied! <pre>import streamlit as st\nfrom pathlib import Path\nimport base64\nimport requests\n</pre> import streamlit as st from pathlib import Path import base64 import requests In\u00a0[\u00a0]: Copied! <pre># Initial page config\nst.set_page_config(\n    page_title='NumPy Cheat Sheet',\n    layout=\"wide\",\n    initial_sidebar_state=\"expanded\",\n)\n</pre> # Initial page config st.set_page_config(     page_title='NumPy Cheat Sheet',     layout=\"wide\",     initial_sidebar_state=\"expanded\", ) In\u00a0[\u00a0]: Copied! <pre>def main():\n    \"\"\"\n    Main function to set up the Streamlit app layout.\n    \"\"\"\n    cs_sidebar()\n    cs_body()\n    return None\n</pre> def main():     \"\"\"     Main function to set up the Streamlit app layout.     \"\"\"     cs_sidebar()     cs_body()     return None In\u00a0[\u00a0]: Copied! <pre># Define img_to_bytes() function\ndef img_to_bytes(img_url):\n    response = requests.get(img_url)\n    img_bytes = response.content\n    encoded = base64.b64encode(img_bytes).decode()\n    return encoded\n</pre> # Define img_to_bytes() function def img_to_bytes(img_url):     response = requests.get(img_url)     img_bytes = response.content     encoded = base64.b64encode(img_bytes).decode()     return encoded In\u00a0[\u00a0]: Copied! <pre># Define the cs_sidebar() function\ndef cs_sidebar():\n    \"\"\"\n    Populate the sidebar with various content sections related to NumPy.\n    \"\"\"\n    st.sidebar.markdown(\n        '''[&lt;img src='data:image/png;base64,{}' class='img-fluid' width=95 &gt;](https://streamlit.io/)'''.format(\n            img_to_bytes(\"https://raw.githubusercontent.com/fralfaro/DS-Cheat-Sheets/main/docs/examples/numpy/numpy2.png\")), unsafe_allow_html=True)\n\n    st.sidebar.header('NumPy Cheat Sheet')\n    st.sidebar.markdown('''\n&lt;small&gt;[NumPy](https://numpy.org/) is the core library for scientific computing in\nPython. It provides a high-performance multidimensional array\nobject, and tools for working with these arrays.&lt;/small&gt;\n    ''', unsafe_allow_html=True)\n\n    # NumPy installation and import\n    st.sidebar.markdown('__Install and import NumPy__')\n    st.sidebar.code('$ pip install numpy')\n    st.sidebar.code('''\n# Import NumPy convention\n&gt;&gt;&gt; import numpy as np\n''')\n\n    # NumPy array creation\n    st.sidebar.markdown('__NumPy Arrays__')\n    st.sidebar.markdown(\n        '''[&lt;img src='data:image/png;base64,{}' class='img-fluid' width=300 &gt;](https://streamlit.io/)'''.format(\n            img_to_bytes(\"https://raw.githubusercontent.com/fralfaro/DS-Cheat-Sheets/main/docs/examples/numpy/np_02.png\")), unsafe_allow_html=True)\n\n    st.sidebar.code('''\n            # Create a 1D array\n            a = np.array([1, 2, 3])\n\n            # Create a 2D array with specified dtype\n            b = np.array([\n                (1.5, 2, 3),\n                 (4, 5, 6)\n                 ], dtype=float)\n\n            # Create a 3D array with specified dtype\n            c = np.array([\n                [(1.5, 2, 3), (4, 5, 6)], \n                [(3, 2, 1), (4, 5, 6)]\n                ], dtype=float)\n                ''')\n    return None\n</pre> # Define the cs_sidebar() function def cs_sidebar():     \"\"\"     Populate the sidebar with various content sections related to NumPy.     \"\"\"     st.sidebar.markdown(         '''[](https://streamlit.io/)'''.format(             img_to_bytes(\"https://raw.githubusercontent.com/fralfaro/DS-Cheat-Sheets/main/docs/examples/numpy/numpy2.png\")), unsafe_allow_html=True)      st.sidebar.header('NumPy Cheat Sheet')     st.sidebar.markdown(''' [NumPy](https://numpy.org/) is the core library for scientific computing in Python. It provides a high-performance multidimensional array object, and tools for working with these arrays.     ''', unsafe_allow_html=True)      # NumPy installation and import     st.sidebar.markdown('__Install and import NumPy__')     st.sidebar.code('$ pip install numpy')     st.sidebar.code(''' # Import NumPy convention &gt;&gt;&gt; import numpy as np ''')      # NumPy array creation     st.sidebar.markdown('__NumPy Arrays__')     st.sidebar.markdown(         '''[](https://streamlit.io/)'''.format(             img_to_bytes(\"https://raw.githubusercontent.com/fralfaro/DS-Cheat-Sheets/main/docs/examples/numpy/np_02.png\")), unsafe_allow_html=True)      st.sidebar.code('''             # Create a 1D array             a = np.array([1, 2, 3])              # Create a 2D array with specified dtype             b = np.array([                 (1.5, 2, 3),                  (4, 5, 6)                  ], dtype=float)              # Create a 3D array with specified dtype             c = np.array([                 [(1.5, 2, 3), (4, 5, 6)],                  [(3, 2, 1), (4, 5, 6)]                 ], dtype=float)                 ''')     return None In\u00a0[\u00a0]: Copied! <pre># Define the cs_body() function\ndef cs_body():\n    \"\"\"\n    Create content sections for the main body of the Streamlit cheat sheet with NumPy examples.\n    \"\"\"\n    col1, col2, col3 = st.columns(3)  # Create columns for layout\n\n    #######################################\n    # COLUMN 1\n    #######################################\n\n    # Initial Placeholders\n    col1.subheader('Initial Placeholders')\n    col1.code('''\n    # Create an array of zeros\n    zeros_arr = np.zeros((3, 4))\n\n    # Create an array of ones\n    ones_arr = np.ones((2, 3, 4))\n\n    # Create an array of evenly spaced values (step value)\n    d = np.arange(10, 25, 5)\n\n    # Create an array of evenly spaced values (number of samples)\n    e = np.linspace(0, 2, 9)\n\n    # Create a constant array\n    f = np.full((2, 2), 7)\n\n    # Create a 2X2 identity matrix\n    g = np.eye(2)\n\n    # Create an array with random values\n    random_arr = np.random.random((2, 2))\n\n    # Create an empty array\n    empty_arr = np.empty((3, 2))\n        ''')\n\n    # Saving &amp; Loading On Disk\n    col1.subheader('Saving &amp; Loading On Disk')\n    col1.code('''\n    # Save a NumPy array to a file\n    a = np.array([1, 2, 3])\n    np.save('my_array', a)\n\n    # Save multiple NumPy arrays to a compressed file\n    b = np.array([\n        (1.5, 2, 3), \n        (4, 5, 6)\n        ], dtype=float)\n    np.savez('array.npz', a, b)\n\n    # Load a NumPy array from a file\n    loaded_array = np.load('my_array.npy')\n        ''')\n\n    # Saving &amp; Loading Text Files\n    col1.subheader('Saving &amp; Loading Text Files')\n    col1.code('''\n    # Load data from a text file\n    loaded_txt = np.loadtxt(\"myfile.txt\")\n\n    # Load data from a CSV file with specified delimiter\n    loaded_csv = np.genfromtxt(\n        \"my_file.csv\",\n         delimiter=',')\n\n    # Save a NumPy array to a text file\n    a = np.array([1, 2, 3])\n    np.savetxt(\n        \"myarray.txt\", \n        a, \n        delimiter=\" \")\n        ''')\n\n    # NumPy data types\n    col1.subheader('NumPy Data Types')\n    col1.code('''\n    # Signed 64-bit integer types\n    int64_type = np.int64\n\n    # Standard double-precision floating point\n    float32_type = np.float32\n\n    # Complex numbers represented by 128 floats\n    complex_type = np.complex128\n\n    # Boolean type storing TRUE and FALSE values\n    bool_type = np.bool_\n\n    # Python object type\n    object_type = np.object_\n\n    # Fixed-length string type\n    string_type = np.string_\n\n    # Fixed-length unicode type\n    unicode_type = np.unicode_\n        ''')\n\n\n\n    # Asking for help\n    col1.subheader('Asking for Help')\n    col1.code('''\n    # Get information about a NumPy function or object\n    np.info(np.ndarray.dtype)\n        ''')\n\n    #######################################\n    # COLUMN 2\n    #######################################\n\n    # Inspecting array properties\n    col2.subheader('Inspecting Array Properties')\n    col2.code('''\n    # Array dimensions\n    a_shape = a.shape\n\n    # Length of array\n    a_length = len(a)\n\n    # Number of array dimensions\n    b_ndim = b.ndim\n\n    # Number of array elements\n    e_size = e.size\n\n    # Data type of array elements\n    b_dtype = b.dtype\n\n    # Name of data type\n    b_dtype_name = b.dtype.name\n\n    # Convert an array to a different type\n    b_as_int = b.astype(int)\n        ''')\n\n\n\n    # Arithmetic operations\n    col2.subheader('Arithmetic Operations')\n    col2.code('''\n    # Subtraction\n    subtraction_result = a - b\n    subtraction_np = np.subtract(a, b)\n\n    # Addition\n    addition_result = b + a\n    addition_np = np.add(b, a)\n\n    # Division\n    division_result = a / b\n    division_np = np.divide(a, b)\n\n    # Multiplication\n    multiplication_result = a * b\n    multiplication_np = np.multiply(a, b)\n\n    # Exponentiation\n    exponentiation_result = np.exp(b)\n\n    # Square root\n    sqrt_result = np.sqrt(b)\n\n    # Sine of an array\n    sin_result = np.sin(a)\n\n    # Element-wise cosine\n    cos_result = np.cos(b)\n\n    # Element-wise natural logarithm\n    log_result = np.log(a)\n\n    # Dot product\n    dot_product_result = e.dot(f)\n        ''')\n\n\n    # Aggregate functions\n    col2.subheader('Aggregate Functions')\n    col2.code('''\n    # Array-wise sum\n    array_sum = a.sum()\n\n    # Array-wise minimum value\n    array_min = a.min()\n\n    # Maximum value of an array row\n    row_max = b.max(axis=0)\n\n    # Cumulative sum of the elements\n    cumulative_sum = b.cumsum(axis=1)\n\n    # Mean\n    array_mean = a.mean()\n\n    # Median\n    array_median = b.median()\n\n    # Correlation coefficient\n    corr_coefficient = a.corrcoef()\n\n    # Standard deviation\n    std_deviation = np.std(b)\n        ''')\n\n    #######################################\n    # COLUMN 3\n    #######################################\n\n    # Comparison operations\n    col3.subheader('Comparison Operations')\n    col3.code('''\n    # Element-wise comparison for equality\n    equality_comparison = a == b\n\n    # Element-wise comparison for less than\n    less_than_comparison = a &lt; 2\n\n    # Array-wise comparison using np.array_equal\n    np_equal = np.array_equal(a, b)\n        ''')\n\n    # Copying arrays\n    col3.subheader('Copying Arrays')\n    col3.code('''\n    # Create a view of the array with the same data\n    array_view = a.view()\n\n    # Create a copy of the array\n    array_copy = np.copy(a)\n\n    # Create a deep copy of the array\n    array_deep_copy = a.copy()\n        ''')\n\n    # Sorting arrays\n    col3.subheader('Sorting Arrays')\n    col3.code('''\n    # Sort an array\n    a.sort()\n\n    # Sort the elements of an array's axis\n    c.sort(axis=0)\n        ''')\n\n\n    # Subsetting, Slicing, and Indexing\n    col3.subheader('Subsetting, Slicing, and Indexing')\n    col3.code('''\n    # Subsetting\n    element_at_2nd_index = a[2] \n\n    # Select the element at row 1, column 2\n    element_row_1_col_2 = b[1, 2] \n\n    # Slicing\n    sliced_a = a[0:2]\n\n    # Select items at rows 0 and 1 in column 1\n    sliced_b = b[0:2, 1]\n\n    # Select all items at row 0\n    sliced_c = b[:1] \n\n    # Reversed array\n    reversed_a = a[::-1] \n\n    # Boolean Indexing\n    a_less_than_2 = a[a &lt; 2]\n\n    # Fancy Indexing\n    fancy_indexing_result = b[ \n        [1, 0, 1, 0], \n        [0, 1, 2, 0]\n        ] # array([ 4. , 2. , 6. , 1.5])\n    fancy_indexing_subset = b[[1, 0, 1, 0]][:, [0, 1, 2, 0]] \n        ''')\n\n    # Array Manipulation\n    col3.subheader('Array Manipulation')\n    col3.code('''\n    # Transposing Array\n    transposed_b = np.transpose(b)\n    transposed_b_T = transposed_b.T\n\n    # Changing Array Shape\n    flattened_h = h.ravel()\n    reshaped_g = g.reshape(3, -2)\n\n    # Adding/Removing Elements\n    resized_h = np.resize(h, (2, 6))  # Using np.resize to avoid the error\n    appended_array = np.append(h, g)\n    inserted_array = np.insert(a, 1, 5)\n    deleted_array = np.delete(a, [1])\n\n    # Combining Arrays\n    concatenated_arrays = np.concatenate((a, d), axis=0)\n    vstacked_arrays = np.vstack((a, b))\n    hstacked_arrays = np.hstack((e, f))\n    column_stacked_arrays = np.column_stack((a, d))\n    c_stacked_arrays = np.c_[a, d]\n\n    # Splitting Arrays\n    hsplit_array = np.hsplit(a, 3)\n    vsplit_array = np.vsplit(c, 2)\n        ''')\n</pre> # Define the cs_body() function def cs_body():     \"\"\"     Create content sections for the main body of the Streamlit cheat sheet with NumPy examples.     \"\"\"     col1, col2, col3 = st.columns(3)  # Create columns for layout      #######################################     # COLUMN 1     #######################################      # Initial Placeholders     col1.subheader('Initial Placeholders')     col1.code('''     # Create an array of zeros     zeros_arr = np.zeros((3, 4))      # Create an array of ones     ones_arr = np.ones((2, 3, 4))      # Create an array of evenly spaced values (step value)     d = np.arange(10, 25, 5)      # Create an array of evenly spaced values (number of samples)     e = np.linspace(0, 2, 9)      # Create a constant array     f = np.full((2, 2), 7)      # Create a 2X2 identity matrix     g = np.eye(2)      # Create an array with random values     random_arr = np.random.random((2, 2))      # Create an empty array     empty_arr = np.empty((3, 2))         ''')      # Saving &amp; Loading On Disk     col1.subheader('Saving &amp; Loading On Disk')     col1.code('''     # Save a NumPy array to a file     a = np.array([1, 2, 3])     np.save('my_array', a)      # Save multiple NumPy arrays to a compressed file     b = np.array([         (1.5, 2, 3),          (4, 5, 6)         ], dtype=float)     np.savez('array.npz', a, b)      # Load a NumPy array from a file     loaded_array = np.load('my_array.npy')         ''')      # Saving &amp; Loading Text Files     col1.subheader('Saving &amp; Loading Text Files')     col1.code('''     # Load data from a text file     loaded_txt = np.loadtxt(\"myfile.txt\")      # Load data from a CSV file with specified delimiter     loaded_csv = np.genfromtxt(         \"my_file.csv\",          delimiter=',')      # Save a NumPy array to a text file     a = np.array([1, 2, 3])     np.savetxt(         \"myarray.txt\",          a,          delimiter=\" \")         ''')      # NumPy data types     col1.subheader('NumPy Data Types')     col1.code('''     # Signed 64-bit integer types     int64_type = np.int64      # Standard double-precision floating point     float32_type = np.float32      # Complex numbers represented by 128 floats     complex_type = np.complex128      # Boolean type storing TRUE and FALSE values     bool_type = np.bool_      # Python object type     object_type = np.object_      # Fixed-length string type     string_type = np.string_      # Fixed-length unicode type     unicode_type = np.unicode_         ''')        # Asking for help     col1.subheader('Asking for Help')     col1.code('''     # Get information about a NumPy function or object     np.info(np.ndarray.dtype)         ''')      #######################################     # COLUMN 2     #######################################      # Inspecting array properties     col2.subheader('Inspecting Array Properties')     col2.code('''     # Array dimensions     a_shape = a.shape      # Length of array     a_length = len(a)      # Number of array dimensions     b_ndim = b.ndim      # Number of array elements     e_size = e.size      # Data type of array elements     b_dtype = b.dtype      # Name of data type     b_dtype_name = b.dtype.name      # Convert an array to a different type     b_as_int = b.astype(int)         ''')        # Arithmetic operations     col2.subheader('Arithmetic Operations')     col2.code('''     # Subtraction     subtraction_result = a - b     subtraction_np = np.subtract(a, b)      # Addition     addition_result = b + a     addition_np = np.add(b, a)      # Division     division_result = a / b     division_np = np.divide(a, b)      # Multiplication     multiplication_result = a * b     multiplication_np = np.multiply(a, b)      # Exponentiation     exponentiation_result = np.exp(b)      # Square root     sqrt_result = np.sqrt(b)      # Sine of an array     sin_result = np.sin(a)      # Element-wise cosine     cos_result = np.cos(b)      # Element-wise natural logarithm     log_result = np.log(a)      # Dot product     dot_product_result = e.dot(f)         ''')       # Aggregate functions     col2.subheader('Aggregate Functions')     col2.code('''     # Array-wise sum     array_sum = a.sum()      # Array-wise minimum value     array_min = a.min()      # Maximum value of an array row     row_max = b.max(axis=0)      # Cumulative sum of the elements     cumulative_sum = b.cumsum(axis=1)      # Mean     array_mean = a.mean()      # Median     array_median = b.median()      # Correlation coefficient     corr_coefficient = a.corrcoef()      # Standard deviation     std_deviation = np.std(b)         ''')      #######################################     # COLUMN 3     #######################################      # Comparison operations     col3.subheader('Comparison Operations')     col3.code('''     # Element-wise comparison for equality     equality_comparison = a == b      # Element-wise comparison for less than     less_than_comparison = a &lt; 2      # Array-wise comparison using np.array_equal     np_equal = np.array_equal(a, b)         ''')      # Copying arrays     col3.subheader('Copying Arrays')     col3.code('''     # Create a view of the array with the same data     array_view = a.view()      # Create a copy of the array     array_copy = np.copy(a)      # Create a deep copy of the array     array_deep_copy = a.copy()         ''')      # Sorting arrays     col3.subheader('Sorting Arrays')     col3.code('''     # Sort an array     a.sort()      # Sort the elements of an array's axis     c.sort(axis=0)         ''')       # Subsetting, Slicing, and Indexing     col3.subheader('Subsetting, Slicing, and Indexing')     col3.code('''     # Subsetting     element_at_2nd_index = a[2]       # Select the element at row 1, column 2     element_row_1_col_2 = b[1, 2]       # Slicing     sliced_a = a[0:2]      # Select items at rows 0 and 1 in column 1     sliced_b = b[0:2, 1]      # Select all items at row 0     sliced_c = b[:1]       # Reversed array     reversed_a = a[::-1]       # Boolean Indexing     a_less_than_2 = a[a &lt; 2]      # Fancy Indexing     fancy_indexing_result = b[          [1, 0, 1, 0],          [0, 1, 2, 0]         ] # array([ 4. , 2. , 6. , 1.5])     fancy_indexing_subset = b[[1, 0, 1, 0]][:, [0, 1, 2, 0]]          ''')      # Array Manipulation     col3.subheader('Array Manipulation')     col3.code('''     # Transposing Array     transposed_b = np.transpose(b)     transposed_b_T = transposed_b.T      # Changing Array Shape     flattened_h = h.ravel()     reshaped_g = g.reshape(3, -2)      # Adding/Removing Elements     resized_h = np.resize(h, (2, 6))  # Using np.resize to avoid the error     appended_array = np.append(h, g)     inserted_array = np.insert(a, 1, 5)     deleted_array = np.delete(a, [1])      # Combining Arrays     concatenated_arrays = np.concatenate((a, d), axis=0)     vstacked_arrays = np.vstack((a, b))     hstacked_arrays = np.hstack((e, f))     column_stacked_arrays = np.column_stack((a, d))     c_stacked_arrays = np.c_[a, d]      # Splitting Arrays     hsplit_array = np.hsplit(a, 3)     vsplit_array = np.vsplit(c, 2)         ''') In\u00a0[\u00a0]: Copied! <pre># Run the main function if the script is executed directly\nif __name__ == '__main__':\n    main()\n</pre> # Run the main function if the script is executed directly if __name__ == '__main__':     main()"},{"location":"examples/numpy/numpy/","title":"NumPy","text":"In\u00a0[1]: Copied! <pre># Import NumPy convention\nimport numpy as np\n</pre> # Import NumPy convention import numpy as np In\u00a0[2]: Copied! <pre># Create a 1D array\na = np.array([1, 2, 3])\n\n# Create a 2D array with specified dtype\nb = np.array([\n    (1.5, 2, 3),\n    (4, 5, 6)\n], dtype=float)\n\n# Create a 3D array with specified dtype\nc = np.array([\n    [(1.5, 2, 3), (4, 5, 6)],\n    [(3, 2, 1), (4, 5, 6)]\n], dtype=float)\n\nprint(\"Array a:\")\nprint(a)\n\nprint(\"\\nArray b:\")\nprint(b)\n\nprint(\"\\nArray c:\")\nprint(c)\n</pre> # Create a 1D array a = np.array([1, 2, 3])  # Create a 2D array with specified dtype b = np.array([     (1.5, 2, 3),     (4, 5, 6) ], dtype=float)  # Create a 3D array with specified dtype c = np.array([     [(1.5, 2, 3), (4, 5, 6)],     [(3, 2, 1), (4, 5, 6)] ], dtype=float)  print(\"Array a:\") print(a)  print(\"\\nArray b:\") print(b)  print(\"\\nArray c:\") print(c) <pre>Array a:\n[1 2 3]\n\nArray b:\n[[1.5 2.  3. ]\n [4.  5.  6. ]]\n\nArray c:\n[[[1.5 2.  3. ]\n  [4.  5.  6. ]]\n\n [[3.  2.  1. ]\n  [4.  5.  6. ]]]\n</pre> In\u00a0[3]: Copied! <pre># Create an array of zeros\nzeros_arr = np.zeros((3, 4))\n\n# Create an array of ones\nones_arr = np.ones((2, 3, 4))\n\n# Create an array of evenly spaced values (step value)\nd = np.arange(10, 25, 5)\n\n# Create an array of evenly spaced values (number of samples)\ne = np.linspace(0, 2, 9)\n\n# Create a constant array\nf = np.full((2, 2), 7)\n\n# Create a 2x2 identity matrix\ng = np.eye(2)\n\n# Create an array with random values\nrandom_arr = np.random.random((2, 2))\n\n# Create an empty array\nempty_arr = np.empty((3, 2))\n\nprint(\"zeros_arr:\")\nprint(zeros_arr)\n\nprint(\"\\nones_arr:\")\nprint(ones_arr)\n\nprint(\"\\nd:\")\nprint(d)\n\nprint(\"\\ne:\")\nprint(e)\n\nprint(\"\\nf:\")\nprint(f)\n\nprint(\"\\ng:\")\nprint(g)\n\nprint(\"\\nrandom_arr:\")\nprint(random_arr)\n\nprint(\"\\nempty_arr:\")\nprint(empty_arr)\n</pre> # Create an array of zeros zeros_arr = np.zeros((3, 4))  # Create an array of ones ones_arr = np.ones((2, 3, 4))  # Create an array of evenly spaced values (step value) d = np.arange(10, 25, 5)  # Create an array of evenly spaced values (number of samples) e = np.linspace(0, 2, 9)  # Create a constant array f = np.full((2, 2), 7)  # Create a 2x2 identity matrix g = np.eye(2)  # Create an array with random values random_arr = np.random.random((2, 2))  # Create an empty array empty_arr = np.empty((3, 2))  print(\"zeros_arr:\") print(zeros_arr)  print(\"\\nones_arr:\") print(ones_arr)  print(\"\\nd:\") print(d)  print(\"\\ne:\") print(e)  print(\"\\nf:\") print(f)  print(\"\\ng:\") print(g)  print(\"\\nrandom_arr:\") print(random_arr)  print(\"\\nempty_arr:\") print(empty_arr)  <pre>zeros_arr:\n[[0. 0. 0. 0.]\n [0. 0. 0. 0.]\n [0. 0. 0. 0.]]\n\nones_arr:\n[[[1. 1. 1. 1.]\n  [1. 1. 1. 1.]\n  [1. 1. 1. 1.]]\n\n [[1. 1. 1. 1.]\n  [1. 1. 1. 1.]\n  [1. 1. 1. 1.]]]\n\nd:\n[10 15 20]\n\ne:\n[0.   0.25 0.5  0.75 1.   1.25 1.5  1.75 2.  ]\n\nf:\n[[7 7]\n [7 7]]\n\ng:\n[[1. 0.]\n [0. 1.]]\n\nrandom_arr:\n[[0.00439382 0.02702873]\n [0.19578698 0.34798592]]\n\nempty_arr:\n[[1.5 2. ]\n [3.  4. ]\n [5.  6. ]]\n</pre> In\u00a0[4]: Copied! <pre># Signed 64-bit integer types\nint64_type = np.int64\n\n# Standard double-precision floating point\nfloat32_type = np.float32\n\n# Complex numbers represented by 128 floats\ncomplex_type = np.complex128\n\n# Boolean type storing TRUE and FALSE values\nbool_type = np.bool_\n\n# Python object type\nobject_type = np.object_\n\n# Fixed-length string type\nstring_type = np.string_\n\n# Fixed-length unicode type\nunicode_type = np.unicode_\n\nprint(\"int64_type:\", int64_type)\nprint(\"float32_type:\", float32_type)\nprint(\"complex_type:\", complex_type)\nprint(\"bool_type:\", bool_type)\nprint(\"object_type:\", object_type)\nprint(\"string_type:\", string_type)\nprint(\"unicode_type:\", unicode_type)\n</pre> # Signed 64-bit integer types int64_type = np.int64  # Standard double-precision floating point float32_type = np.float32  # Complex numbers represented by 128 floats complex_type = np.complex128  # Boolean type storing TRUE and FALSE values bool_type = np.bool_  # Python object type object_type = np.object_  # Fixed-length string type string_type = np.string_  # Fixed-length unicode type unicode_type = np.unicode_  print(\"int64_type:\", int64_type) print(\"float32_type:\", float32_type) print(\"complex_type:\", complex_type) print(\"bool_type:\", bool_type) print(\"object_type:\", object_type) print(\"string_type:\", string_type) print(\"unicode_type:\", unicode_type) <pre>int64_type: &lt;class 'numpy.int64'&gt;\nfloat32_type: &lt;class 'numpy.float32'&gt;\ncomplex_type: &lt;class 'numpy.complex128'&gt;\nbool_type: &lt;class 'numpy.bool_'&gt;\nobject_type: &lt;class 'numpy.object_'&gt;\nstring_type: &lt;class 'numpy.bytes_'&gt;\nunicode_type: &lt;class 'numpy.str_'&gt;\n</pre> In\u00a0[5]: Copied! <pre># Array dimensions\na_shape = a.shape\n\n# Length of array\na_length = len(a)\n\n# Number of array dimensions\nb_ndim = b.ndim\n\n# Number of array elements\ne_size = e.size\n\n# Data type of array elements\nb_dtype = b.dtype\n\n# Name of data type\nb_dtype_name = b.dtype.name\n\n# Convert an array to a different type\nb_as_int = b.astype(int)\n\nprint(\"a_shape:\")\nprint(a_shape)\n\nprint(\"\\na_length:\")\nprint(a_length)\n\nprint(\"\\nb_ndim:\")\nprint(b_ndim)\n\nprint(\"\\ne_size:\")\nprint(e_size)\n\nprint(\"\\nb_dtype:\")\nprint(b_dtype)\n\nprint(\"\\nb_dtype_name:\")\nprint(b_dtype_name)\n\nprint(\"\\nb_as_int:\")\nprint(b_as_int)\n</pre> # Array dimensions a_shape = a.shape  # Length of array a_length = len(a)  # Number of array dimensions b_ndim = b.ndim  # Number of array elements e_size = e.size  # Data type of array elements b_dtype = b.dtype  # Name of data type b_dtype_name = b.dtype.name  # Convert an array to a different type b_as_int = b.astype(int)  print(\"a_shape:\") print(a_shape)  print(\"\\na_length:\") print(a_length)  print(\"\\nb_ndim:\") print(b_ndim)  print(\"\\ne_size:\") print(e_size)  print(\"\\nb_dtype:\") print(b_dtype)  print(\"\\nb_dtype_name:\") print(b_dtype_name)  print(\"\\nb_as_int:\") print(b_as_int)  <pre>a_shape:\n(3,)\n\na_length:\n3\n\nb_ndim:\n2\n\ne_size:\n9\n\nb_dtype:\nfloat64\n\nb_dtype_name:\nfloat64\n\nb_as_int:\n[[1 2 3]\n [4 5 6]]\n</pre> In\u00a0[6]: Copied! <pre># Example values for arrays\na = np.array([1, 2, 3])\nb = np.array([\n    (1.5, 2, 3),\n    (4, 5, 6)\n], dtype=float)\ne = np.array([2, 3, 4])\nd = np.arange(10, 25, 5)\n\n# Subtraction\nsubtraction_result = a - b\nsubtraction_np = np.subtract(a, b)\n\n# Addition\naddition_result = b + a\naddition_np = np.add(b, a)\n\n# Division\ndivision_result = a / b\ndivision_np = np.divide(a, b)\n\n# Multiplication\nmultiplication_result = a * b\nmultiplication_np = np.multiply(a, b)\n\n# Exponentiation\nexponentiation_result = np.exp(b)\n\n# Square root\nsqrt_result = np.sqrt(b)\n\n# Sine of an array\nsin_result = np.sin(a)\n\n# Element-wise cosine\ncos_result = np.cos(b)\n\n# Element-wise natural logarithm\nlog_result = np.log(a)\n\n# Dot product\ndot_product_result = np.dot(e, d)\n\nprint(\"subtraction_result:\")\nprint(subtraction_result)\n\nprint(\"\\nsubtraction_np:\")\nprint(subtraction_np)\n\nprint(\"\\naddition_result:\")\nprint(addition_result)\n\nprint(\"\\naddition_np:\")\nprint(addition_np)\n\nprint(\"\\ndivision_result:\")\nprint(division_result)\n\nprint(\"\\ndivision_np:\")\nprint(division_np)\n\nprint(\"\\nmultiplication_result:\")\nprint(multiplication_result)\n\nprint(\"\\nmultiplication_np:\")\nprint(multiplication_np)\n\nprint(\"\\nexponentiation_result:\")\nprint(exponentiation_result)\n\nprint(\"\\nsqrt_result:\")\nprint(sqrt_result)\n\nprint(\"\\nsin_result:\")\nprint(sin_result)\n\nprint(\"\\ncos_result:\")\nprint(cos_result)\n\nprint(\"\\nlog_result:\")\nprint(log_result)\n\nprint(\"\\ndot_product_result:\")\nprint(dot_product_result)\n</pre> # Example values for arrays a = np.array([1, 2, 3]) b = np.array([     (1.5, 2, 3),     (4, 5, 6) ], dtype=float) e = np.array([2, 3, 4]) d = np.arange(10, 25, 5)  # Subtraction subtraction_result = a - b subtraction_np = np.subtract(a, b)  # Addition addition_result = b + a addition_np = np.add(b, a)  # Division division_result = a / b division_np = np.divide(a, b)  # Multiplication multiplication_result = a * b multiplication_np = np.multiply(a, b)  # Exponentiation exponentiation_result = np.exp(b)  # Square root sqrt_result = np.sqrt(b)  # Sine of an array sin_result = np.sin(a)  # Element-wise cosine cos_result = np.cos(b)  # Element-wise natural logarithm log_result = np.log(a)  # Dot product dot_product_result = np.dot(e, d)  print(\"subtraction_result:\") print(subtraction_result)  print(\"\\nsubtraction_np:\") print(subtraction_np)  print(\"\\naddition_result:\") print(addition_result)  print(\"\\naddition_np:\") print(addition_np)  print(\"\\ndivision_result:\") print(division_result)  print(\"\\ndivision_np:\") print(division_np)  print(\"\\nmultiplication_result:\") print(multiplication_result)  print(\"\\nmultiplication_np:\") print(multiplication_np)  print(\"\\nexponentiation_result:\") print(exponentiation_result)  print(\"\\nsqrt_result:\") print(sqrt_result)  print(\"\\nsin_result:\") print(sin_result)  print(\"\\ncos_result:\") print(cos_result)  print(\"\\nlog_result:\") print(log_result)  print(\"\\ndot_product_result:\") print(dot_product_result) <pre>subtraction_result:\n[[-0.5  0.   0. ]\n [-3.  -3.  -3. ]]\n\nsubtraction_np:\n[[-0.5  0.   0. ]\n [-3.  -3.  -3. ]]\n\naddition_result:\n[[2.5 4.  6. ]\n [5.  7.  9. ]]\n\naddition_np:\n[[2.5 4.  6. ]\n [5.  7.  9. ]]\n\ndivision_result:\n[[0.66666667 1.         1.        ]\n [0.25       0.4        0.5       ]]\n\ndivision_np:\n[[0.66666667 1.         1.        ]\n [0.25       0.4        0.5       ]]\n\nmultiplication_result:\n[[ 1.5  4.   9. ]\n [ 4.  10.  18. ]]\n\nmultiplication_np:\n[[ 1.5  4.   9. ]\n [ 4.  10.  18. ]]\n\nexponentiation_result:\n[[  4.48168907   7.3890561   20.08553692]\n [ 54.59815003 148.4131591  403.42879349]]\n\nsqrt_result:\n[[1.22474487 1.41421356 1.73205081]\n [2.         2.23606798 2.44948974]]\n\nsin_result:\n[0.84147098 0.90929743 0.14112001]\n\ncos_result:\n[[ 0.0707372  -0.41614684 -0.9899925 ]\n [-0.65364362  0.28366219  0.96017029]]\n\nlog_result:\n[0.         0.69314718 1.09861229]\n\ndot_product_result:\n145\n</pre> In\u00a0[7]: Copied! <pre># Element-wise comparison for equality\nequality_comparison = a == b\n\n# Element-wise comparison for less than\nless_than_comparison = a &lt; 2\n\n# Array-wise comparison using np.array_equal\nnp_equal = np.array_equal(a, b)\n\nprint(\"equality_comparison:\")\nprint(equality_comparison)\n\nprint(\"\\nless_than_comparison:\")\nprint(less_than_comparison)\n\nprint(\"\\nnp_equal:\")\nprint(np_equal)\n</pre> # Element-wise comparison for equality equality_comparison = a == b  # Element-wise comparison for less than less_than_comparison = a &lt; 2  # Array-wise comparison using np.array_equal np_equal = np.array_equal(a, b)  print(\"equality_comparison:\") print(equality_comparison)  print(\"\\nless_than_comparison:\") print(less_than_comparison)  print(\"\\nnp_equal:\") print(np_equal) <pre>equality_comparison:\n[[False  True  True]\n [False False False]]\n\nless_than_comparison:\n[ True False False]\n\nnp_equal:\nFalse\n</pre> In\u00a0[8]: Copied! <pre># Array-wise sum\narray_sum = a.sum()\n\n# Array-wise minimum value\narray_min = a.min()\n\n# Maximum value of an array row\nrow_max = b.max(axis=0)\n\n# Cumulative sum of the elements\ncumulative_sum = b.cumsum(axis=1)\n\n# Mean\narray_mean = a.mean()\n\n# Median\narray_median = np.median(b)\n\n# Correlation coefficient (not valid for 1D array)\ncorr_coefficient = np.corrcoef(a, b[0])\n\n# Standard deviation\nstd_deviation = np.std(b)\n\nprint(\"array_sum:\")\nprint(array_sum)\n\nprint(\"\\narray_min:\")\nprint(array_min)\n\nprint(\"\\nrow_max:\")\nprint(row_max)\n\nprint(\"\\ncumulative_sum:\")\nprint(cumulative_sum)\n\nprint(\"\\narray_mean:\")\nprint(array_mean)\n\nprint(\"\\narray_median:\")\nprint(array_median)\n\nprint(\"\\ncorr_coefficient:\")\nprint(corr_coefficient)\n\nprint(\"\\nstd_deviation:\")\nprint(std_deviation)\n</pre> # Array-wise sum array_sum = a.sum()  # Array-wise minimum value array_min = a.min()  # Maximum value of an array row row_max = b.max(axis=0)  # Cumulative sum of the elements cumulative_sum = b.cumsum(axis=1)  # Mean array_mean = a.mean()  # Median array_median = np.median(b)  # Correlation coefficient (not valid for 1D array) corr_coefficient = np.corrcoef(a, b[0])  # Standard deviation std_deviation = np.std(b)  print(\"array_sum:\") print(array_sum)  print(\"\\narray_min:\") print(array_min)  print(\"\\nrow_max:\") print(row_max)  print(\"\\ncumulative_sum:\") print(cumulative_sum)  print(\"\\narray_mean:\") print(array_mean)  print(\"\\narray_median:\") print(array_median)  print(\"\\ncorr_coefficient:\") print(corr_coefficient)  print(\"\\nstd_deviation:\") print(std_deviation) <pre>array_sum:\n6\n\narray_min:\n1\n\nrow_max:\n[4. 5. 6.]\n\ncumulative_sum:\n[[ 1.5  3.5  6.5]\n [ 4.   9.  15. ]]\n\narray_mean:\n2.0\n\narray_median:\n3.5\n\ncorr_coefficient:\n[[1.         0.98198051]\n [0.98198051 1.        ]]\n\nstd_deviation:\n1.5920810978785667\n</pre> In\u00a0[9]: Copied! <pre># Create a view of the array with the same data\narray_view = a.view()\n\n# Create a copy of the array\narray_copy = np.copy(a)\n\n# Create a deep copy of the array\narray_deep_copy = a.copy()\n\n# Sort an array\na.sort()\n\n# Sort the elements of an array's axis\nc.sort(axis=0)\n\nprint(\"array_view:\")\nprint(array_view)\n\nprint(\"\\narray_copy:\")\nprint(array_copy)\n\nprint(\"\\narray_deep_copy:\")\nprint(array_deep_copy)\n</pre> # Create a view of the array with the same data array_view = a.view()  # Create a copy of the array array_copy = np.copy(a)  # Create a deep copy of the array array_deep_copy = a.copy()  # Sort an array a.sort()  # Sort the elements of an array's axis c.sort(axis=0)  print(\"array_view:\") print(array_view)  print(\"\\narray_copy:\") print(array_copy)  print(\"\\narray_deep_copy:\") print(array_deep_copy) <pre>array_view:\n[1 2 3]\n\narray_copy:\n[1 2 3]\n\narray_deep_copy:\n[1 2 3]\n</pre> In\u00a0[10]: Copied! <pre># Sort an array\na.sort()\n\n# Sort the elements of an array's axis\nc.sort(axis=0)\n\nprint(\"Sorted a:\")\nprint(a)\n\nprint(\"\\nSorted c (axis=0):\")\nprint(c)\n</pre> # Sort an array a.sort()  # Sort the elements of an array's axis c.sort(axis=0)  print(\"Sorted a:\") print(a)  print(\"\\nSorted c (axis=0):\") print(c) <pre>Sorted a:\n[1 2 3]\n\nSorted c (axis=0):\n[[[1.5 2.  1. ]\n  [4.  5.  6. ]]\n\n [[3.  2.  3. ]\n  [4.  5.  6. ]]]\n</pre> In\u00a0[11]: Copied! <pre># Subsetting\nelement_at_2nd_index = a[2] \n\n# Select the element at row 1, column 2\nelement_row_1_col_2 = b[1, 2] \n\n# Slicing\nsliced_a = a[0:2]\n\n# Select items at rows 0 and 1 in column 1\nsliced_b = b[0:2, 1]\n\n# Select all items at row 0\nsliced_c = b[:1] \n\n# Reversed array\nreversed_a = a[::-1] \n\n# Boolean Indexing\na_less_than_2 = a[a &lt; 2]\n\n# Fancy Indexing\nfancy_indexing_result = b[ \n    [1, 0, 1, 0], \n    [0, 1, 2, 0]\n]\nfancy_indexing_subset = b[[1, 0, 1, 0]][:, [0, 1, 2, 0]]\n\nprint(\"element_at_2nd_index:\")\nprint(element_at_2nd_index)\n\nprint(\"\\nelement_row_1_col_2:\")\nprint(element_row_1_col_2)\n\nprint(\"\\nsliced_a:\")\nprint(sliced_a)\n\nprint(\"\\nsliced_b:\")\nprint(sliced_b)\n\nprint(\"\\nsliced_c:\")\nprint(sliced_c)\n\nprint(\"\\nreversed_a:\")\nprint(reversed_a)\n\nprint(\"\\na_less_than_2:\")\nprint(a_less_than_2)\n\nprint(\"\\nfancy_indexing_result:\")\nprint(fancy_indexing_result)\n\nprint(\"\\nfancy_indexing_subset:\")\nprint(fancy_indexing_subset)\n</pre> # Subsetting element_at_2nd_index = a[2]   # Select the element at row 1, column 2 element_row_1_col_2 = b[1, 2]   # Slicing sliced_a = a[0:2]  # Select items at rows 0 and 1 in column 1 sliced_b = b[0:2, 1]  # Select all items at row 0 sliced_c = b[:1]   # Reversed array reversed_a = a[::-1]   # Boolean Indexing a_less_than_2 = a[a &lt; 2]  # Fancy Indexing fancy_indexing_result = b[      [1, 0, 1, 0],      [0, 1, 2, 0] ] fancy_indexing_subset = b[[1, 0, 1, 0]][:, [0, 1, 2, 0]]  print(\"element_at_2nd_index:\") print(element_at_2nd_index)  print(\"\\nelement_row_1_col_2:\") print(element_row_1_col_2)  print(\"\\nsliced_a:\") print(sliced_a)  print(\"\\nsliced_b:\") print(sliced_b)  print(\"\\nsliced_c:\") print(sliced_c)  print(\"\\nreversed_a:\") print(reversed_a)  print(\"\\na_less_than_2:\") print(a_less_than_2)  print(\"\\nfancy_indexing_result:\") print(fancy_indexing_result)  print(\"\\nfancy_indexing_subset:\") print(fancy_indexing_subset) <pre>element_at_2nd_index:\n3\n\nelement_row_1_col_2:\n6.0\n\nsliced_a:\n[1 2]\n\nsliced_b:\n[2. 5.]\n\nsliced_c:\n[[1.5 2.  3. ]]\n\nreversed_a:\n[3 2 1]\n\na_less_than_2:\n[1]\n\nfancy_indexing_result:\n[4.  2.  6.  1.5]\n\nfancy_indexing_subset:\n[[4.  5.  6.  4. ]\n [1.5 2.  3.  1.5]\n [4.  5.  6.  4. ]\n [1.5 2.  3.  1.5]]\n</pre> In\u00a0[12]: Copied! <pre># Example values for arrays\na = np.array([3, 1, 2])\nb = np.array([\n    (1.5, 2, 3),\n    (4, 5, 6)\n], dtype=float)\nh = np.array([\n    [1, 2, 3],\n    [4, 5, 6]\n])\ng = np.array([7, 8, 9])\nd = np.array([4, 5, 6])\ne = np.array([10, 11])\nf = np.array([12, 13])\nc = np.array([\n    (3, 1, 2),\n    (6, 4, 5)\n], dtype=int)\n\n# Transposing Array\ntransposed_b = np.transpose(b)\ntransposed_b_T = transposed_b.T\n\n# Changing Array Shape\nflattened_h = h.ravel()\nreshaped_g = g.reshape(3, -2)\n\n# Adding/Removing Elements\nresized_h = np.resize(h, (2, 6))  # Using np.resize to avoid the error\nappended_array = np.append(h, g)\ninserted_array = np.insert(a, 1, 5)\ndeleted_array = np.delete(a, [1])\n\n# Combining Arrays\nconcatenated_arrays = np.concatenate((a, d), axis=0)\nvstacked_arrays = np.vstack((a, b))\nhstacked_arrays = np.hstack((e, f))\ncolumn_stacked_arrays = np.column_stack((a, d))\nc_stacked_arrays = np.c_[a, d]\n\n# Splitting Arrays\nhsplit_array = np.hsplit(a, 3)\nvsplit_array = np.vsplit(c, 2)\n\nprint(\"transposed_b:\")\nprint(transposed_b)\n\nprint(\"\\ntransposed_b_T:\")\nprint(transposed_b_T)\n\nprint(\"\\nflattened_h:\")\nprint(flattened_h)\n\nprint(\"\\nreshaped_g:\")\nprint(reshaped_g)\n\nprint(\"\\nresized_h:\")\nprint(resized_h)\n\nprint(\"\\nappended_array:\")\nprint(appended_array)\n\nprint(\"\\ninserted_array:\")\nprint(inserted_array)\n\nprint(\"\\ndeleted_array:\")\nprint(deleted_array)\n\nprint(\"\\nconcatenated_arrays:\")\nprint(concatenated_arrays)\n\nprint(\"\\nvstacked_arrays:\")\nprint(vstacked_arrays)\n\nprint(\"\\nhstacked_arrays:\")\nprint(hstacked_arrays)\n\nprint(\"\\ncolumn_stacked_arrays:\")\nprint(column_stacked_arrays)\n\nprint(\"\\nc_stacked_arrays:\")\nprint(c_stacked_arrays)\n\nprint(\"\\nhsplit_array:\")\nprint(hsplit_array)\n\nprint(\"\\nvsplit_array:\")\nprint(vsplit_array)\n</pre> # Example values for arrays a = np.array([3, 1, 2]) b = np.array([     (1.5, 2, 3),     (4, 5, 6) ], dtype=float) h = np.array([     [1, 2, 3],     [4, 5, 6] ]) g = np.array([7, 8, 9]) d = np.array([4, 5, 6]) e = np.array([10, 11]) f = np.array([12, 13]) c = np.array([     (3, 1, 2),     (6, 4, 5) ], dtype=int)  # Transposing Array transposed_b = np.transpose(b) transposed_b_T = transposed_b.T  # Changing Array Shape flattened_h = h.ravel() reshaped_g = g.reshape(3, -2)  # Adding/Removing Elements resized_h = np.resize(h, (2, 6))  # Using np.resize to avoid the error appended_array = np.append(h, g) inserted_array = np.insert(a, 1, 5) deleted_array = np.delete(a, [1])  # Combining Arrays concatenated_arrays = np.concatenate((a, d), axis=0) vstacked_arrays = np.vstack((a, b)) hstacked_arrays = np.hstack((e, f)) column_stacked_arrays = np.column_stack((a, d)) c_stacked_arrays = np.c_[a, d]  # Splitting Arrays hsplit_array = np.hsplit(a, 3) vsplit_array = np.vsplit(c, 2)  print(\"transposed_b:\") print(transposed_b)  print(\"\\ntransposed_b_T:\") print(transposed_b_T)  print(\"\\nflattened_h:\") print(flattened_h)  print(\"\\nreshaped_g:\") print(reshaped_g)  print(\"\\nresized_h:\") print(resized_h)  print(\"\\nappended_array:\") print(appended_array)  print(\"\\ninserted_array:\") print(inserted_array)  print(\"\\ndeleted_array:\") print(deleted_array)  print(\"\\nconcatenated_arrays:\") print(concatenated_arrays)  print(\"\\nvstacked_arrays:\") print(vstacked_arrays)  print(\"\\nhstacked_arrays:\") print(hstacked_arrays)  print(\"\\ncolumn_stacked_arrays:\") print(column_stacked_arrays)  print(\"\\nc_stacked_arrays:\") print(c_stacked_arrays)  print(\"\\nhsplit_array:\") print(hsplit_array)  print(\"\\nvsplit_array:\") print(vsplit_array)  <pre>transposed_b:\n[[1.5 4. ]\n [2.  5. ]\n [3.  6. ]]\n\ntransposed_b_T:\n[[1.5 2.  3. ]\n [4.  5.  6. ]]\n\nflattened_h:\n[1 2 3 4 5 6]\n\nreshaped_g:\n[[7]\n [8]\n [9]]\n\nresized_h:\n[[1 2 3 4 5 6]\n [1 2 3 4 5 6]]\n\nappended_array:\n[1 2 3 4 5 6 7 8 9]\n\ninserted_array:\n[3 5 1 2]\n\ndeleted_array:\n[3 2]\n\nconcatenated_arrays:\n[3 1 2 4 5 6]\n\nvstacked_arrays:\n[[3.  1.  2. ]\n [1.5 2.  3. ]\n [4.  5.  6. ]]\n\nhstacked_arrays:\n[10 11 12 13]\n\ncolumn_stacked_arrays:\n[[3 4]\n [1 5]\n [2 6]]\n\nc_stacked_arrays:\n[[3 4]\n [1 5]\n [2 6]]\n\nhsplit_array:\n[array([3]), array([1]), array([2])]\n\nvsplit_array:\n[array([[3, 1, 2]]), array([[6, 4, 5]])]\n</pre> In\u00a0[13]: Copied! <pre># Get information about a NumPy function or object\nnp.info(np.ndarray.dtype)\n</pre> # Get information about a NumPy function or object np.info(np.ndarray.dtype) <pre>Data-type of the array's elements.\n\nParameters\n----------\nNone\n\nReturns\n-------\nd : numpy dtype object\n\nSee Also\n--------\nnumpy.dtype\n\nExamples\n--------\n&gt;&gt;&gt; x\narray([[0, 1],\n       [2, 3]])\n&gt;&gt;&gt; x.dtype\ndtype('int32')\n&gt;&gt;&gt; type(x.dtype)\n&lt;type 'numpy.dtype'&gt;\n</pre>"},{"location":"examples/numpy/numpy/#numpy","title":"NumPy\u00b6","text":"<p>NumPy is the core library for scientific computing in Python. It provides a high-performance multidimensional array object, and tools for working with these arrays.</p>"},{"location":"examples/numpy/numpy/#install-and-import-numpy","title":"Install and import NumPy\u00b6","text":"<p><code>$ pip install numpy</code></p>"},{"location":"examples/numpy/numpy/#numpy-arrays","title":"NumPy Arrays\u00b6","text":""},{"location":"examples/numpy/numpy/#initial-placeholders","title":"Initial Placeholders\u00b6","text":""},{"location":"examples/numpy/numpy/#numpy-data-types","title":"NumPy Data Types\u00b6","text":""},{"location":"examples/numpy/numpy/#inspecting-array-properties","title":"Inspecting Array Properties\u00b6","text":""},{"location":"examples/numpy/numpy/#arithmetic-operations","title":"Arithmetic Operations\u00b6","text":""},{"location":"examples/numpy/numpy/#comparison-operations","title":"Comparison Operations\u00b6","text":""},{"location":"examples/numpy/numpy/#aggregate-functions","title":"Aggregate Functions\u00b6","text":""},{"location":"examples/numpy/numpy/#copying-arrays","title":"Copying Arrays\u00b6","text":""},{"location":"examples/numpy/numpy/#sorting-arrays","title":"Sorting Arrays\u00b6","text":""},{"location":"examples/numpy/numpy/#subsetting-slicing-and-indexing","title":"Subsetting, Slicing, and Indexing\u00b6","text":""},{"location":"examples/numpy/numpy/#array-manipulation","title":"Array Manipulation\u00b6","text":""},{"location":"examples/numpy/numpy/#asking-for-help","title":"Asking for Help\u00b6","text":""},{"location":"examples/numpy/numpy/#saving-loading","title":"Saving &amp; Loading\u00b6","text":"<p>On Disk</p> <pre># Save a NumPy array to a file\na = np.array([1, 2, 3])\nnp.save('my_array', a)\n\n# Save multiple NumPy arrays to a compressed file\nb = np.array([\n    (1.5, 2, 3), \n    (4, 5, 6)\n    ], dtype=float)\nnp.savez('array.npz', a=a, b=b)\n\n# Load a NumPy array from a file\nloaded_array = np.load('my_array.npy')\n</pre> <p>Text Files</p> <pre># Load data from a text file\nloaded_txt = np.loadtxt(\"myfile.txt\")\n\n# Load data from a CSV file with specified delimiter\nloaded_csv = np.genfromtxt(\n    \"my_file.csv\",\n     delimiter=',')\n\n# Save a NumPy array to a text file\na = np.array([1, 2, 3])\nnp.savetxt(\n    \"myarray.txt\", \n    a, \n    delimiter=\" \")\n</pre>"},{"location":"examples/pandas/app/","title":"App","text":"In\u00a0[\u00a0]: Copied! <pre>import streamlit as st\nfrom pathlib import Path\nimport base64\nimport requests\n</pre> import streamlit as st from pathlib import Path import base64 import requests In\u00a0[\u00a0]: Copied! <pre># Initial page config\nst.set_page_config(\n    page_title='Pandas Cheat Sheet',\n    layout=\"wide\",\n    initial_sidebar_state=\"expanded\",\n)\n</pre> # Initial page config st.set_page_config(     page_title='Pandas Cheat Sheet',     layout=\"wide\",     initial_sidebar_state=\"expanded\", ) In\u00a0[\u00a0]: Copied! <pre>def main():\n    \"\"\"\n    Main function to set up the Streamlit app layout.\n    \"\"\"\n    cs_sidebar()\n    cs_body()\n    return None\n</pre> def main():     \"\"\"     Main function to set up the Streamlit app layout.     \"\"\"     cs_sidebar()     cs_body()     return None In\u00a0[\u00a0]: Copied! <pre># Define img_to_bytes() function\ndef img_to_bytes(img_url):\n    response = requests.get(img_url)\n    img_bytes = response.content\n    encoded = base64.b64encode(img_bytes).decode()\n    return encoded\n</pre> # Define img_to_bytes() function def img_to_bytes(img_url):     response = requests.get(img_url)     img_bytes = response.content     encoded = base64.b64encode(img_bytes).decode()     return encoded In\u00a0[\u00a0]: Copied! <pre># Define the cs_sidebar() function\ndef cs_sidebar():\n    \"\"\"\n    Populate the sidebar with various content sections related to Pandas.\n    \"\"\"\n    st.sidebar.markdown(\n        '''[&lt;img src='data:image/png;base64,{}' class='img-fluid' width=200 &gt;](https://streamlit.io/)'''.format(\n            img_to_bytes(\"https://raw.githubusercontent.com/fralfaro/DS-Cheat-Sheets/main/docs/examples/pandas/pandas.png\")), unsafe_allow_html=True)\n\n    st.sidebar.header('Pandas Cheat Sheet')\n    st.sidebar.markdown('''\n&lt;small&gt;[Pandas](https://pandas.pydata.org/) is built on NumPy and provides easy-to-use\ndata structures and data analysis tools for the Python\nprogramming language.&lt;/small&gt;\n    ''', unsafe_allow_html=True)\n\n    # Pandas installation and import\n    st.sidebar.markdown('__Install and import Pandas__')\n    st.sidebar.code('$ pip install pandas')\n    st.sidebar.code('''\n# Import Pandas convention\n&gt;&gt;&gt; import pandas as pd\n''')\n\n    # Pandas array creation\n    st.sidebar.subheader('Pandas Data Structures')\n    st.sidebar.markdown('__Series__')\n    st.sidebar.markdown(\n        '''[&lt;img src='data:image/png;base64,{}' class='img-fluid' width=100 &gt;](https://streamlit.io/)'''.format(\n            img_to_bytes(\"https://raw.githubusercontent.com/fralfaro/DS-Cheat-Sheets/main/docs/examples/pandas/serie.png\")), unsafe_allow_html=True)\n\n    st.sidebar.markdown('''\n    &lt;small&gt;A **one-dimensional** labeled array a capable of holding any data type.&lt;/small&gt;\n        ''', unsafe_allow_html=True)\n\n    st.sidebar.code('''\n    # Create a pandas Series\n    s = pd.Series(\n        [3, -5, 7, 4],\n        index=['a', 'b', 'c', 'd']\n    )\n    ''')\n\n    st.sidebar.markdown('__DataFrame__')\n    st.sidebar.markdown('''\n        &lt;small&gt;A **two-dimensional** labeled data structure with columns of potentially different types.&lt;/small&gt;\n            ''', unsafe_allow_html=True)\n    st.sidebar.markdown(\n        '''[&lt;img src='data:image/png;base64,{}' class='img-fluid' width=300 &gt;](https://streamlit.io/)'''.format(\n            img_to_bytes(\"https://raw.githubusercontent.com/fralfaro/DS-Cheat-Sheets/main/docs/examples/pandas/df.png\")), unsafe_allow_html=True)\n\n    st.sidebar.code('''\n    # Create a pandas DataFrame\n    data = {\n        'Country': ['Belgium', 'India', 'Brazil'],\n        'Capital': ['Brussels', 'New Delhi', 'Bras\u00edlia'],\n        'Population': [11190846, 1303171035, 207847528]\n    }\n    df = pd.DataFrame(\n        data,\n        columns=['Country', 'Capital', 'Population']\n    )\n    ''')\n\n    return None\n</pre> # Define the cs_sidebar() function def cs_sidebar():     \"\"\"     Populate the sidebar with various content sections related to Pandas.     \"\"\"     st.sidebar.markdown(         '''[](https://streamlit.io/)'''.format(             img_to_bytes(\"https://raw.githubusercontent.com/fralfaro/DS-Cheat-Sheets/main/docs/examples/pandas/pandas.png\")), unsafe_allow_html=True)      st.sidebar.header('Pandas Cheat Sheet')     st.sidebar.markdown(''' [Pandas](https://pandas.pydata.org/) is built on NumPy and provides easy-to-use data structures and data analysis tools for the Python programming language.     ''', unsafe_allow_html=True)      # Pandas installation and import     st.sidebar.markdown('__Install and import Pandas__')     st.sidebar.code('$ pip install pandas')     st.sidebar.code(''' # Import Pandas convention &gt;&gt;&gt; import pandas as pd ''')      # Pandas array creation     st.sidebar.subheader('Pandas Data Structures')     st.sidebar.markdown('__Series__')     st.sidebar.markdown(         '''[](https://streamlit.io/)'''.format(             img_to_bytes(\"https://raw.githubusercontent.com/fralfaro/DS-Cheat-Sheets/main/docs/examples/pandas/serie.png\")), unsafe_allow_html=True)      st.sidebar.markdown('''     A **one-dimensional** labeled array a capable of holding any data type.         ''', unsafe_allow_html=True)      st.sidebar.code('''     # Create a pandas Series     s = pd.Series(         [3, -5, 7, 4],         index=['a', 'b', 'c', 'd']     )     ''')      st.sidebar.markdown('__DataFrame__')     st.sidebar.markdown('''         A **two-dimensional** labeled data structure with columns of potentially different types.             ''', unsafe_allow_html=True)     st.sidebar.markdown(         '''[](https://streamlit.io/)'''.format(             img_to_bytes(\"https://raw.githubusercontent.com/fralfaro/DS-Cheat-Sheets/main/docs/examples/pandas/df.png\")), unsafe_allow_html=True)      st.sidebar.code('''     # Create a pandas DataFrame     data = {         'Country': ['Belgium', 'India', 'Brazil'],         'Capital': ['Brussels', 'New Delhi', 'Bras\u00edlia'],         'Population': [11190846, 1303171035, 207847528]     }     df = pd.DataFrame(         data,         columns=['Country', 'Capital', 'Population']     )     ''')      return None In\u00a0[\u00a0]: Copied! <pre># Define the cs_body() function\ndef cs_body():\n    \"\"\"\n    Create content sections for the main body of the Streamlit cheat sheet with Pandas examples.\n    \"\"\"\n    col1, col2, col3 = st.columns(3)  # Create columns for layout\n\n    #######################################\n    # COLUMN 1\n    #######################################\n\n    # Read and Write to CSV\n    col1.subheader('Read and Write to CSV')\n    col1.code('''\n    # Read from CSV\n    df_read = pd.read_csv(\n        'file.csv',\n         header=None, \n         nrows=5\n    )\n\n    # Write to CSV\n    df.to_csv('myDataFrame.csv')\n        ''')\n\n    # Read and Write to Excel\n    col1.subheader('Read and Write to Excel')\n    col1.code('''\n    # Read from Excel\n    df_read_excel = pd.read_excel('file.xlsx')\n\n    # Write to Excel\n    df.to_excel(\n        'dir/myDataFrame.xlsx', \n        sheet_name='Sheet1'\n    )\n\n    # Read multiple sheets from the same file\n    xlsx = pd.ExcelFile('file.xls')\n    df_from_sheet1 = pd.read_excel(xlsx, 'Sheet1')\n        ''')\n\n    # Read and Write to SQL Query or Database Table\n    col1.subheader('Read and Write to SQL Query or Database Table')\n    col1.code('''\n    from sqlalchemy import create_engine\n    engine = create_engine('sqlite:///:memory:')\n\n    # Read from SQL Query\n    pd.read_sql(\"SELECT * FROM my_table;\", engine)\n\n    # Read from Database Table\n    pd.read_sql_table('my_table', engine)\n\n    # Read from SQL Query using read_sql_query()\n    pd.read_sql_query(\"SELECT * FROM my_table;\", engine)\n\n    # Write DataFrame to SQL Table\n    pd.to_sql('myDf', engine)\n        ''')\n\n\n    # Getting Elements from Series and DataFrame\n    col1.subheader('Getting Elements')\n    col1.code('''\n    # Get one element from a Series\n    s['b']\n    # Output: -5\n\n    # Get subset of a DataFrame\n    df[1:]\n    # Output:\n    #    Country     Capital  Population\n    # 1    India   New Delhi  1303171035\n    # 2   Brazil    Bras\u00edlia   207847528\n        ''')\n\n    # Asking For Help\n    col1.subheader('Asking For Help')\n    col1.code('''\n    # Display help for a function or object\n    help(pd.Series.loc)\n        ''')\n\n    #######################################\n    # COLUMN 2\n    #######################################\n\n    # Selecting, Boolean Indexing &amp; Setting\n    col2.subheader('Selecting, Boolean Indexing &amp; Setting')\n    col2.code('''\n    # Select single value by row &amp; 'Belgium' column\n    df.iloc[[0],[0]]\n    # Output: 'Belgium'\n\n    # Select single value by row &amp; 'Belgium' column labels\n    df.loc[[0], ['Country']]\n    # Output: 'Belgium'\n\n    # Select single row of subset of rows\n    df.loc[2]\n    # Output:\n    # Country     Brazil\n    # Capital    Bras\u00edlia\n    # Population 207847528\n\n    # Select a single column of subset of columns\n    df.loc[:,'Capital']\n    # Output:\n    # 0     Brussels\n    # 1    New Delhi\n    # 2     Bras\u00edlia\n\n    # Boolean indexing - Series s where value is not &gt; 1\n    s[~(s &gt; 1)]\n\n    # Boolean indexing - s where value is &lt;-1 or &gt;2\n    s[(s &lt; -1) | (s &gt; 2)]\n\n    # Use filter to adjust DataFrame\n    df[df['Population'] &gt; 1200000000]\n\n    # Setting index a of Series s to 6\n    s['a'] = 6\n        ''')\n\n    # Dropping\n    col2.subheader('Dropping')\n    col2.code('''\n    # Drop values from rows (axis=0)\n    s.drop(['a', 'c'])\n\n    # Drop values from columns (axis=1)\n    df.drop('Country', axis=1)\n        ''')\n\n    # Sort &amp; Rank\n    col2.subheader('Sort &amp; Rank')\n    col2.code('''\n    # Sort by labels along an axis\n    df.sort_index()\n\n    # Sort by the values along an axis\n    df.sort_values(by='Country')\n\n    # Assign ranks to entries\n    df.rank()\n        ''')\n\n    # Applying Functions\n    col2.subheader('Applying Functions')\n    col2.code('''\n    # Define a function\n    f = lambda x: x*2\n\n    # Apply function to DataFrame\n    df.apply(f)\n\n    # Apply function element-wise\n    df.applymap(f)\n        ''')\n\n    #######################################\n    # COLUMN 3\n    #######################################\n\n    # Basic Information\n    col3.subheader('Basic Information')\n    col3.code('''\n    # Get the shape (rows, columns)\n    df.shape\n\n    # Describe index\n    df.index\n\n    # Describe DataFrame columns\n    df.columns\n\n    # Info on DataFrame\n    df.info()\n\n    # Number of non-NA values\n    df.count()\n        ''')\n\n    # Summary\n    col3.subheader('Summary')\n    col3.code('''\n    # Sum of values\n    df[col].sum()\n\n    # Cumulative sum of values\n    df[col].cumsum()\n\n    # Minimum/maximum values\n    df[col].min()\n    df[col].max()\n\n    # Index of minimum/maximum values\n    df[col].idxmin()\n    df[col].idxmax()\n\n    # Summary statistics\n    df[col].describe()\n\n    # Mean of values\n    df[col].mean()\n\n    # Median of values\n    df[col].median()\n        ''')\n\n    # Internal Data Alignment\n    col3.subheader('Internal Data Alignment')\n    col3.code('''\n    # Create Series with different indices\n    s3 = pd.Series([7, -2, 3], index=['a', 'c', 'd'])\n\n    # Add two Series with different indices\n    result = s + s3\n        ''')\n\n    # Arithmetic Operations with Fill Methods\n    col3.subheader('Arithmetic Operations with Fill Methods')\n    col3.code('''\n    # Perform arithmetic operations with fill methods\n    result_add = s.add(s3, fill_value=0)\n    result_sub = s.sub(s3, fill_value=2)\n    result_div = s.div(s3, fill_value=4)\n    result_mul = s.mul(s3, fill_value=3)\n        ''')\n</pre> # Define the cs_body() function def cs_body():     \"\"\"     Create content sections for the main body of the Streamlit cheat sheet with Pandas examples.     \"\"\"     col1, col2, col3 = st.columns(3)  # Create columns for layout      #######################################     # COLUMN 1     #######################################      # Read and Write to CSV     col1.subheader('Read and Write to CSV')     col1.code('''     # Read from CSV     df_read = pd.read_csv(         'file.csv',          header=None,           nrows=5     )      # Write to CSV     df.to_csv('myDataFrame.csv')         ''')      # Read and Write to Excel     col1.subheader('Read and Write to Excel')     col1.code('''     # Read from Excel     df_read_excel = pd.read_excel('file.xlsx')      # Write to Excel     df.to_excel(         'dir/myDataFrame.xlsx',          sheet_name='Sheet1'     )      # Read multiple sheets from the same file     xlsx = pd.ExcelFile('file.xls')     df_from_sheet1 = pd.read_excel(xlsx, 'Sheet1')         ''')      # Read and Write to SQL Query or Database Table     col1.subheader('Read and Write to SQL Query or Database Table')     col1.code('''     from sqlalchemy import create_engine     engine = create_engine('sqlite:///:memory:')      # Read from SQL Query     pd.read_sql(\"SELECT * FROM my_table;\", engine)      # Read from Database Table     pd.read_sql_table('my_table', engine)      # Read from SQL Query using read_sql_query()     pd.read_sql_query(\"SELECT * FROM my_table;\", engine)      # Write DataFrame to SQL Table     pd.to_sql('myDf', engine)         ''')       # Getting Elements from Series and DataFrame     col1.subheader('Getting Elements')     col1.code('''     # Get one element from a Series     s['b']     # Output: -5      # Get subset of a DataFrame     df[1:]     # Output:     #    Country     Capital  Population     # 1    India   New Delhi  1303171035     # 2   Brazil    Bras\u00edlia   207847528         ''')      # Asking For Help     col1.subheader('Asking For Help')     col1.code('''     # Display help for a function or object     help(pd.Series.loc)         ''')      #######################################     # COLUMN 2     #######################################      # Selecting, Boolean Indexing &amp; Setting     col2.subheader('Selecting, Boolean Indexing &amp; Setting')     col2.code('''     # Select single value by row &amp; 'Belgium' column     df.iloc[[0],[0]]     # Output: 'Belgium'      # Select single value by row &amp; 'Belgium' column labels     df.loc[[0], ['Country']]     # Output: 'Belgium'      # Select single row of subset of rows     df.loc[2]     # Output:     # Country     Brazil     # Capital    Bras\u00edlia     # Population 207847528      # Select a single column of subset of columns     df.loc[:,'Capital']     # Output:     # 0     Brussels     # 1    New Delhi     # 2     Bras\u00edlia      # Boolean indexing - Series s where value is not &gt; 1     s[~(s &gt; 1)]      # Boolean indexing - s where value is &lt;-1 or &gt;2     s[(s &lt; -1) | (s &gt; 2)]      # Use filter to adjust DataFrame     df[df['Population'] &gt; 1200000000]      # Setting index a of Series s to 6     s['a'] = 6         ''')      # Dropping     col2.subheader('Dropping')     col2.code('''     # Drop values from rows (axis=0)     s.drop(['a', 'c'])      # Drop values from columns (axis=1)     df.drop('Country', axis=1)         ''')      # Sort &amp; Rank     col2.subheader('Sort &amp; Rank')     col2.code('''     # Sort by labels along an axis     df.sort_index()      # Sort by the values along an axis     df.sort_values(by='Country')      # Assign ranks to entries     df.rank()         ''')      # Applying Functions     col2.subheader('Applying Functions')     col2.code('''     # Define a function     f = lambda x: x*2      # Apply function to DataFrame     df.apply(f)      # Apply function element-wise     df.applymap(f)         ''')      #######################################     # COLUMN 3     #######################################      # Basic Information     col3.subheader('Basic Information')     col3.code('''     # Get the shape (rows, columns)     df.shape      # Describe index     df.index      # Describe DataFrame columns     df.columns      # Info on DataFrame     df.info()      # Number of non-NA values     df.count()         ''')      # Summary     col3.subheader('Summary')     col3.code('''     # Sum of values     df[col].sum()      # Cumulative sum of values     df[col].cumsum()      # Minimum/maximum values     df[col].min()     df[col].max()      # Index of minimum/maximum values     df[col].idxmin()     df[col].idxmax()      # Summary statistics     df[col].describe()      # Mean of values     df[col].mean()      # Median of values     df[col].median()         ''')      # Internal Data Alignment     col3.subheader('Internal Data Alignment')     col3.code('''     # Create Series with different indices     s3 = pd.Series([7, -2, 3], index=['a', 'c', 'd'])      # Add two Series with different indices     result = s + s3         ''')      # Arithmetic Operations with Fill Methods     col3.subheader('Arithmetic Operations with Fill Methods')     col3.code('''     # Perform arithmetic operations with fill methods     result_add = s.add(s3, fill_value=0)     result_sub = s.sub(s3, fill_value=2)     result_div = s.div(s3, fill_value=4)     result_mul = s.mul(s3, fill_value=3)         ''') In\u00a0[\u00a0]: Copied! <pre># Run the main function if the script is executed directly\nif __name__ == '__main__':\n    main()\n</pre> # Run the main function if the script is executed directly if __name__ == '__main__':     main()"},{"location":"examples/pandas/pandas/","title":"Pandas","text":"In\u00a0[1]: Copied! <pre># Import Pandas convention\nimport pandas as pd\n</pre> # Import Pandas convention import pandas as pd In\u00a0[2]: Copied! <pre># Create a pandas Series\ns = pd.Series(\n    [3, -5, 7, 4],\n    index=['a', 'b', 'c', 'd']\n)\n\n# Print the pandas Series\nprint(\"s:\")\ns\n</pre> # Create a pandas Series s = pd.Series(     [3, -5, 7, 4],     index=['a', 'b', 'c', 'd'] )  # Print the pandas Series print(\"s:\") s <pre>s:\n</pre> Out[2]: <pre>a    3\nb   -5\nc    7\nd    4\ndtype: int64</pre> <p>DataFrame</p> <p>two-dimensional labeled data structure with columns of potentially different types.</p> In\u00a0[3]: Copied! <pre># Create a pandas DataFrame\ndata = {\n    'Country': ['Belgium', 'India', 'Brazil'],\n    'Capital': ['Brussels', 'New Delhi', 'Bras\u00edlia'],\n    'Population': [11190846, 1303171035, 207847528]\n}\ndf = pd.DataFrame(\n    data,\n    columns=['Country', 'Capital', 'Population']\n)\n\n# Print the DataFrame 'df'\nprint(\"\\ndf:\")\ndf\n</pre> # Create a pandas DataFrame data = {     'Country': ['Belgium', 'India', 'Brazil'],     'Capital': ['Brussels', 'New Delhi', 'Bras\u00edlia'],     'Population': [11190846, 1303171035, 207847528] } df = pd.DataFrame(     data,     columns=['Country', 'Capital', 'Population'] )  # Print the DataFrame 'df' print(\"\\ndf:\") df <pre>\ndf:\n</pre> Out[3]: Country Capital Population 0 Belgium Brussels 11190846 1 India New Delhi 1303171035 2 Brazil Bras\u00edlia 207847528 In\u00a0[4]: Copied! <pre># Get one element from a Series\ns['b']\n</pre> # Get one element from a Series s['b'] Out[4]: <pre>-5</pre> In\u00a0[5]: Copied! <pre># Get subset of a DataFrame\ndf[1:]\n</pre> # Get subset of a DataFrame df[1:] Out[5]: Country Capital Population 1 India New Delhi 1303171035 2 Brazil Bras\u00edlia 207847528 In\u00a0[6]: Copied! <pre># Select single value by row &amp; 'Belgium' column\ndf.iloc[[0],[0]]\n# Output: 'Belgium'\n</pre> # Select single value by row &amp; 'Belgium' column df.iloc[[0],[0]] # Output: 'Belgium' Out[6]: Country 0 Belgium In\u00a0[7]: Copied! <pre># Select single value by row &amp; 'Belgium' column labels\ndf.loc[[0], ['Country']]\n# Output: 'Belgium'\n</pre> # Select single value by row &amp; 'Belgium' column labels df.loc[[0], ['Country']] # Output: 'Belgium' Out[7]: Country 0 Belgium In\u00a0[8]: Copied! <pre># Select single row of subset of rows\ndf.loc[2]\n# Output:\n# Country     Brazil\n# Capital    Bras\u00edlia\n# Population 207847528\n</pre> # Select single row of subset of rows df.loc[2] # Output: # Country     Brazil # Capital    Bras\u00edlia # Population 207847528 Out[8]: <pre>Country          Brazil\nCapital        Bras\u00edlia\nPopulation    207847528\nName: 2, dtype: object</pre> In\u00a0[9]: Copied! <pre># Select a single column of subset of columns\ndf.loc[:,'Capital']\n# Output:\n# 0     Brussels\n# 1    New Delhi\n# 2     Bras\u00edlia\n</pre> # Select a single column of subset of columns df.loc[:,'Capital'] # Output: # 0     Brussels # 1    New Delhi # 2     Bras\u00edlia Out[9]: <pre>0     Brussels\n1    New Delhi\n2     Bras\u00edlia\nName: Capital, dtype: object</pre> In\u00a0[10]: Copied! <pre># Boolean indexing - Series s where value is not &gt; 1\ns[~(s &gt; 1)]\n</pre> # Boolean indexing - Series s where value is not &gt; 1 s[~(s &gt; 1)] Out[10]: <pre>b   -5\ndtype: int64</pre> In\u00a0[11]: Copied! <pre># Boolean indexing - s where value is &lt;-1 or &gt;2\ns[(s &lt; -1) | (s &gt; 2)]\n</pre> # Boolean indexing - s where value is &lt;-1 or &gt;2 s[(s &lt; -1) | (s &gt; 2)] Out[11]: <pre>a    3\nb   -5\nc    7\nd    4\ndtype: int64</pre> In\u00a0[12]: Copied! <pre># Use filter to adjust DataFrame\ndf[df['Population'] &gt; 1200000000]\n</pre> # Use filter to adjust DataFrame df[df['Population'] &gt; 1200000000] Out[12]: Country Capital Population 1 India New Delhi 1303171035 In\u00a0[13]: Copied! <pre># Setting index a of Series s to 6\ns['a'] = 6\ns\n</pre> # Setting index a of Series s to 6 s['a'] = 6 s Out[13]: <pre>a    6\nb   -5\nc    7\nd    4\ndtype: int64</pre> In\u00a0[14]: Copied! <pre># Drop values from rows (axis=0)\ns.drop(['a', 'c'])\n</pre> # Drop values from rows (axis=0) s.drop(['a', 'c']) Out[14]: <pre>b   -5\nd    4\ndtype: int64</pre> In\u00a0[15]: Copied! <pre># Drop values from columns (axis=1)\ndf.drop('Country', axis=1)\n</pre> # Drop values from columns (axis=1) df.drop('Country', axis=1) Out[15]: Capital Population 0 Brussels 11190846 1 New Delhi 1303171035 2 Bras\u00edlia 207847528 In\u00a0[16]: Copied! <pre># Sort by labels along an axis\ndf.sort_index()\n</pre> # Sort by labels along an axis df.sort_index() Out[16]: Country Capital Population 0 Belgium Brussels 11190846 1 India New Delhi 1303171035 2 Brazil Bras\u00edlia 207847528 In\u00a0[17]: Copied! <pre># Sort by the values along an axis\ndf.sort_values(by='Country')\n</pre> # Sort by the values along an axis df.sort_values(by='Country') Out[17]: Country Capital Population 0 Belgium Brussels 11190846 2 Brazil Bras\u00edlia 207847528 1 India New Delhi 1303171035 In\u00a0[18]: Copied! <pre># Assign ranks to entries\ndf.rank()\n</pre> # Assign ranks to entries df.rank() Out[18]: Country Capital Population 0 1.0 2.0 1.0 1 3.0 3.0 3.0 2 2.0 1.0 2.0 In\u00a0[19]: Copied! <pre># Define a function\nf = lambda x: x*2\n</pre> # Define a function f = lambda x: x*2 In\u00a0[20]: Copied! <pre># Apply function to DataFrame\ndf.apply(f)\n</pre> # Apply function to DataFrame df.apply(f) Out[20]: Country Capital Population 0 BelgiumBelgium BrusselsBrussels 22381692 1 IndiaIndia New DelhiNew Delhi 2606342070 2 BrazilBrazil Bras\u00edliaBras\u00edlia 415695056 In\u00a0[21]: Copied! <pre># Apply function element-wise\ndf.applymap(f)\n</pre> # Apply function element-wise df.applymap(f) Out[21]: Country Capital Population 0 BelgiumBelgium BrusselsBrussels 22381692 1 IndiaIndia New DelhiNew Delhi 2606342070 2 BrazilBrazil Bras\u00edliaBras\u00edlia 415695056 In\u00a0[22]: Copied! <pre># Get the shape (rows, columns)\ndf.shape\n</pre> # Get the shape (rows, columns) df.shape Out[22]: <pre>(3, 3)</pre> In\u00a0[23]: Copied! <pre># Describe index\ndf.index\n</pre> # Describe index df.index Out[23]: <pre>RangeIndex(start=0, stop=3, step=1)</pre> In\u00a0[24]: Copied! <pre># Describe DataFrame columns\ndf.columns\n</pre> # Describe DataFrame columns df.columns Out[24]: <pre>Index(['Country', 'Capital', 'Population'], dtype='object')</pre> In\u00a0[25]: Copied! <pre># Info on DataFrame\ndf.info()\n</pre> # Info on DataFrame df.info() <pre>&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 3 entries, 0 to 2\nData columns (total 3 columns):\n #   Column      Non-Null Count  Dtype \n---  ------      --------------  ----- \n 0   Country     3 non-null      object\n 1   Capital     3 non-null      object\n 2   Population  3 non-null      int64 \ndtypes: int64(1), object(2)\nmemory usage: 200.0+ bytes\n</pre> In\u00a0[26]: Copied! <pre># Number of non-NA values\ndf.count()\n</pre> # Number of non-NA values df.count() Out[26]: <pre>Country       3\nCapital       3\nPopulation    3\ndtype: int64</pre> In\u00a0[27]: Copied! <pre># Sum of values\nsum_values = df['Population'].sum()\n\n# Cumulative sum of values\ncumulative_sum_values = df['Population'].cumsum()\n\n# Minimum/maximum values\nmin_values = df['Population'].min()\nmax_values = df['Population'].max()\n\n# Index of minimum/maximum values\nidx_min_values = df['Population'].idxmin()\nidx_max_values = df['Population'].idxmax()\n\n# Summary statistics\nsummary_stats = df['Population'].describe()\n\n# Mean of values\nmean_values = df['Population'].mean()\n\n# Median of values\nmedian_values = df['Population'].median()\n\nprint(\"Example DataFrame:\")\nprint(df)\n\nprint(\"\\nSum of values:\")\nprint(sum_values)\n\nprint(\"\\nCumulative sum of values:\")\nprint(cumulative_sum_values)\n\nprint(\"\\nMinimum values:\")\nprint(min_values)\n\nprint(\"\\nMaximum values:\")\nprint(max_values)\n\nprint(\"\\nIndex of minimum values:\")\nprint(idx_min_values)\n\nprint(\"\\nIndex of maximum values:\")\nprint(idx_max_values)\n\nprint(\"\\nSummary statistics:\")\nprint(summary_stats)\n\nprint(\"\\nMean values:\")\nprint(mean_values)\n\nprint(\"\\nMedian values:\")\nprint(median_values)\n</pre> # Sum of values sum_values = df['Population'].sum()  # Cumulative sum of values cumulative_sum_values = df['Population'].cumsum()  # Minimum/maximum values min_values = df['Population'].min() max_values = df['Population'].max()  # Index of minimum/maximum values idx_min_values = df['Population'].idxmin() idx_max_values = df['Population'].idxmax()  # Summary statistics summary_stats = df['Population'].describe()  # Mean of values mean_values = df['Population'].mean()  # Median of values median_values = df['Population'].median()  print(\"Example DataFrame:\") print(df)  print(\"\\nSum of values:\") print(sum_values)  print(\"\\nCumulative sum of values:\") print(cumulative_sum_values)  print(\"\\nMinimum values:\") print(min_values)  print(\"\\nMaximum values:\") print(max_values)  print(\"\\nIndex of minimum values:\") print(idx_min_values)  print(\"\\nIndex of maximum values:\") print(idx_max_values)  print(\"\\nSummary statistics:\") print(summary_stats)  print(\"\\nMean values:\") print(mean_values)  print(\"\\nMedian values:\") print(median_values)  <pre>Example DataFrame:\n   Country    Capital  Population\n0  Belgium   Brussels    11190846\n1    India  New Delhi  1303171035\n2   Brazil   Bras\u00edlia   207847528\n\nSum of values:\n1522209409\n\nCumulative sum of values:\n0      11190846\n1    1314361881\n2    1522209409\nName: Population, dtype: int64\n\nMinimum values:\n11190846\n\nMaximum values:\n1303171035\n\nIndex of minimum values:\n0\n\nIndex of maximum values:\n1\n\nSummary statistics:\ncount    3.000000e+00\nmean     5.074031e+08\nstd      6.961346e+08\nmin      1.119085e+07\n25%      1.095192e+08\n50%      2.078475e+08\n75%      7.555093e+08\nmax      1.303171e+09\nName: Population, dtype: float64\n\nMean values:\n507403136.3333333\n\nMedian values:\n207847528.0\n</pre> In\u00a0[28]: Copied! <pre># Create Series with different indices\ns3 = pd.Series([7, -2, 3], index=['a', 'c', 'd'])\ns3\n</pre> # Create Series with different indices s3 = pd.Series([7, -2, 3], index=['a', 'c', 'd']) s3 Out[28]: <pre>a    7\nc   -2\nd    3\ndtype: int64</pre> In\u00a0[29]: Copied! <pre># Add two Series with different indices\nresult = s + s3\nresult\n</pre> # Add two Series with different indices result = s + s3 result Out[29]: <pre>a    13.0\nb     NaN\nc     5.0\nd     7.0\ndtype: float64</pre> In\u00a0[30]: Copied! <pre># Example Series\ns = pd.Series([3, -5, 7, 4], index=['a', 'b', 'c', 'd'])\ns3 = pd.Series([10, 2, 4, 8], index=['a', 'b', 'd', 'e'])\n\n# Perform arithmetic operations with fill methods\nresult_add = s.add(s3, fill_value=0)\nresult_sub = s.sub(s3, fill_value=2)\nresult_div = s.div(s3, fill_value=4)\nresult_mul = s.mul(s3, fill_value=3)\n\nprint(\"result_add:\")\nprint(result_add)\n\nprint(\"\\nresult_sub:\")\nprint(result_sub)\n\nprint(\"\\nresult_div:\")\nprint(result_div)\n\nprint(\"\\nresult_mul:\")\nprint(result_mul)\n</pre> # Example Series s = pd.Series([3, -5, 7, 4], index=['a', 'b', 'c', 'd']) s3 = pd.Series([10, 2, 4, 8], index=['a', 'b', 'd', 'e'])  # Perform arithmetic operations with fill methods result_add = s.add(s3, fill_value=0) result_sub = s.sub(s3, fill_value=2) result_div = s.div(s3, fill_value=4) result_mul = s.mul(s3, fill_value=3)  print(\"result_add:\") print(result_add)  print(\"\\nresult_sub:\") print(result_sub)  print(\"\\nresult_div:\") print(result_div)  print(\"\\nresult_mul:\") print(result_mul) <pre>result_add:\na    13.0\nb    -3.0\nc     7.0\nd     8.0\ne     8.0\ndtype: float64\n\nresult_sub:\na   -7.0\nb   -7.0\nc    5.0\nd    0.0\ne   -6.0\ndtype: float64\n\nresult_div:\na    0.30\nb   -2.50\nc    1.75\nd    1.00\ne    0.50\ndtype: float64\n\nresult_mul:\na    30.0\nb   -10.0\nc    21.0\nd    16.0\ne    24.0\ndtype: float64\n</pre> In\u00a0[31]: Copied! <pre># Display help for a function or object\nhelp(pd.Series.loc)\n</pre> # Display help for a function or object help(pd.Series.loc) <pre>Help on property:\n\n    Access a group of rows and columns by label(s) or a boolean array.\n    \n    ``.loc[]`` is primarily label based, but may also be used with a\n    boolean array.\n    \n    Allowed inputs are:\n    \n    - A single label, e.g. ``5`` or ``'a'``, (note that ``5`` is\n      interpreted as a *label* of the index, and **never** as an\n      integer position along the index).\n    - A list or array of labels, e.g. ``['a', 'b', 'c']``.\n    - A slice object with labels, e.g. ``'a':'f'``.\n    \n      .. warning:: Note that contrary to usual python slices, **both** the\n          start and the stop are included\n    \n    - A boolean array of the same length as the axis being sliced,\n      e.g. ``[True, False, True]``.\n    - An alignable boolean Series. The index of the key will be aligned before\n      masking.\n    - An alignable Index. The Index of the returned selection will be the input.\n    - A ``callable`` function with one argument (the calling Series or\n      DataFrame) and that returns valid output for indexing (one of the above)\n    \n    See more at :ref:`Selection by Label &lt;indexing.label&gt;`.\n    \n    Raises\n    ------\n    KeyError\n        If any items are not found.\n    IndexingError\n        If an indexed key is passed and its index is unalignable to the frame index.\n    \n    See Also\n    --------\n    DataFrame.at : Access a single value for a row/column label pair.\n    DataFrame.iloc : Access group of rows and columns by integer position(s).\n    DataFrame.xs : Returns a cross-section (row(s) or column(s)) from the\n        Series/DataFrame.\n    Series.loc : Access group of values using labels.\n    \n    Examples\n    --------\n    **Getting values**\n    \n    &gt;&gt;&gt; df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],\n    ...      index=['cobra', 'viper', 'sidewinder'],\n    ...      columns=['max_speed', 'shield'])\n    &gt;&gt;&gt; df\n                max_speed  shield\n    cobra               1       2\n    viper               4       5\n    sidewinder          7       8\n    \n    Single label. Note this returns the row as a Series.\n    \n    &gt;&gt;&gt; df.loc['viper']\n    max_speed    4\n    shield       5\n    Name: viper, dtype: int64\n    \n    List of labels. Note using ``[[]]`` returns a DataFrame.\n    \n    &gt;&gt;&gt; df.loc[['viper', 'sidewinder']]\n                max_speed  shield\n    viper               4       5\n    sidewinder          7       8\n    \n    Single label for row and column\n    \n    &gt;&gt;&gt; df.loc['cobra', 'shield']\n    2\n    \n    Slice with labels for row and single label for column. As mentioned\n    above, note that both the start and stop of the slice are included.\n    \n    &gt;&gt;&gt; df.loc['cobra':'viper', 'max_speed']\n    cobra    1\n    viper    4\n    Name: max_speed, dtype: int64\n    \n    Boolean list with the same length as the row axis\n    \n    &gt;&gt;&gt; df.loc[[False, False, True]]\n                max_speed  shield\n    sidewinder          7       8\n    \n    Alignable boolean Series:\n    \n    &gt;&gt;&gt; df.loc[pd.Series([False, True, False],\n    ...        index=['viper', 'sidewinder', 'cobra'])]\n                max_speed  shield\n    sidewinder          7       8\n    \n    Index (same behavior as ``df.reindex``)\n    \n    &gt;&gt;&gt; df.loc[pd.Index([\"cobra\", \"viper\"], name=\"foo\")]\n           max_speed  shield\n    foo\n    cobra          1       2\n    viper          4       5\n    \n    Conditional that returns a boolean Series\n    \n    &gt;&gt;&gt; df.loc[df['shield'] &gt; 6]\n                max_speed  shield\n    sidewinder          7       8\n    \n    Conditional that returns a boolean Series with column labels specified\n    \n    &gt;&gt;&gt; df.loc[df['shield'] &gt; 6, ['max_speed']]\n                max_speed\n    sidewinder          7\n    \n    Callable that returns a boolean Series\n    \n    &gt;&gt;&gt; df.loc[lambda df: df['shield'] == 8]\n                max_speed  shield\n    sidewinder          7       8\n    \n    **Setting values**\n    \n    Set value for all items matching the list of labels\n    \n    &gt;&gt;&gt; df.loc[['viper', 'sidewinder'], ['shield']] = 50\n    &gt;&gt;&gt; df\n                max_speed  shield\n    cobra               1       2\n    viper               4      50\n    sidewinder          7      50\n    \n    Set value for an entire row\n    \n    &gt;&gt;&gt; df.loc['cobra'] = 10\n    &gt;&gt;&gt; df\n                max_speed  shield\n    cobra              10      10\n    viper               4      50\n    sidewinder          7      50\n    \n    Set value for an entire column\n    \n    &gt;&gt;&gt; df.loc[:, 'max_speed'] = 30\n    &gt;&gt;&gt; df\n                max_speed  shield\n    cobra              30      10\n    viper              30      50\n    sidewinder         30      50\n    \n    Set value for rows matching callable condition\n    \n    &gt;&gt;&gt; df.loc[df['shield'] &gt; 35] = 0\n    &gt;&gt;&gt; df\n                max_speed  shield\n    cobra              30      10\n    viper               0       0\n    sidewinder          0       0\n    \n    **Getting values on a DataFrame with an index that has integer labels**\n    \n    Another example using integers for the index\n    \n    &gt;&gt;&gt; df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],\n    ...      index=[7, 8, 9], columns=['max_speed', 'shield'])\n    &gt;&gt;&gt; df\n       max_speed  shield\n    7          1       2\n    8          4       5\n    9          7       8\n    \n    Slice with integer labels for rows. As mentioned above, note that both\n    the start and stop of the slice are included.\n    \n    &gt;&gt;&gt; df.loc[7:9]\n       max_speed  shield\n    7          1       2\n    8          4       5\n    9          7       8\n    \n    **Getting values with a MultiIndex**\n    \n    A number of examples using a DataFrame with a MultiIndex\n    \n    &gt;&gt;&gt; tuples = [\n    ...    ('cobra', 'mark i'), ('cobra', 'mark ii'),\n    ...    ('sidewinder', 'mark i'), ('sidewinder', 'mark ii'),\n    ...    ('viper', 'mark ii'), ('viper', 'mark iii')\n    ... ]\n    &gt;&gt;&gt; index = pd.MultiIndex.from_tuples(tuples)\n    &gt;&gt;&gt; values = [[12, 2], [0, 4], [10, 20],\n    ...         [1, 4], [7, 1], [16, 36]]\n    &gt;&gt;&gt; df = pd.DataFrame(values, columns=['max_speed', 'shield'], index=index)\n    &gt;&gt;&gt; df\n                         max_speed  shield\n    cobra      mark i           12       2\n               mark ii           0       4\n    sidewinder mark i           10      20\n               mark ii           1       4\n    viper      mark ii           7       1\n               mark iii         16      36\n    \n    Single label. Note this returns a DataFrame with a single index.\n    \n    &gt;&gt;&gt; df.loc['cobra']\n             max_speed  shield\n    mark i          12       2\n    mark ii          0       4\n    \n    Single index tuple. Note this returns a Series.\n    \n    &gt;&gt;&gt; df.loc[('cobra', 'mark ii')]\n    max_speed    0\n    shield       4\n    Name: (cobra, mark ii), dtype: int64\n    \n    Single label for row and column. Similar to passing in a tuple, this\n    returns a Series.\n    \n    &gt;&gt;&gt; df.loc['cobra', 'mark i']\n    max_speed    12\n    shield        2\n    Name: (cobra, mark i), dtype: int64\n    \n    Single tuple. Note using ``[[]]`` returns a DataFrame.\n    \n    &gt;&gt;&gt; df.loc[[('cobra', 'mark ii')]]\n                   max_speed  shield\n    cobra mark ii          0       4\n    \n    Single tuple for the index with a single label for the column\n    \n    &gt;&gt;&gt; df.loc[('cobra', 'mark i'), 'shield']\n    2\n    \n    Slice from index tuple to single label\n    \n    &gt;&gt;&gt; df.loc[('cobra', 'mark i'):'viper']\n                         max_speed  shield\n    cobra      mark i           12       2\n               mark ii           0       4\n    sidewinder mark i           10      20\n               mark ii           1       4\n    viper      mark ii           7       1\n               mark iii         16      36\n    \n    Slice from index tuple to index tuple\n    \n    &gt;&gt;&gt; df.loc[('cobra', 'mark i'):('viper', 'mark ii')]\n                        max_speed  shield\n    cobra      mark i          12       2\n               mark ii          0       4\n    sidewinder mark i          10      20\n               mark ii          1       4\n    viper      mark ii          7       1\n\n</pre>"},{"location":"examples/pandas/pandas/#pandas","title":"Pandas\u00b6","text":"<p>Pandas is built on NumPy and provides easy-to-use data structures and data analysis tools for the Python programming language.</p>"},{"location":"examples/pandas/pandas/#install-and-import-pandas","title":"Install and import Pandas\u00b6","text":"<p><code>$ pip install pandas</code></p>"},{"location":"examples/pandas/pandas/#pandas-data-structures","title":"Pandas Data Structures\u00b6","text":"<p>Series</p> <p>A one-dimensional labeled array a capable of holding any data type.</p>"},{"location":"examples/pandas/pandas/#getting-elements","title":"Getting Elements\u00b6","text":""},{"location":"examples/pandas/pandas/#selecting-boolean-indexing-setting","title":"Selecting, Boolean Indexing &amp; Setting\u00b6","text":""},{"location":"examples/pandas/pandas/#dropping","title":"Dropping\u00b6","text":""},{"location":"examples/pandas/pandas/#sort-rank","title":"Sort &amp; Rank\u00b6","text":""},{"location":"examples/pandas/pandas/#applying-functions","title":"Applying Functions\u00b6","text":""},{"location":"examples/pandas/pandas/#basic-information","title":"Basic Information\u00b6","text":""},{"location":"examples/pandas/pandas/#summary","title":"Summary\u00b6","text":""},{"location":"examples/pandas/pandas/#internal-data-alignment","title":"Internal Data Alignment\u00b6","text":""},{"location":"examples/pandas/pandas/#arithmetic-operations-with-fill-methods","title":"Arithmetic Operations with Fill Methods\u00b6","text":""},{"location":"examples/pandas/pandas/#asking-for-help","title":"Asking For Help\u00b6","text":""},{"location":"examples/pandas/pandas/#read-and-write","title":"Read and Write\u00b6","text":"<p>CSV</p> <pre># Read from CSV\ndf_read = pd.read_csv(\n    'file.csv',\n     header=None, \n     nrows=5\n)\n\n# Write to CSV\ndf.to_csv('myDataFrame.csv')\n</pre> <p>Excel</p> <pre># Read from Excel\ndf_read_excel = pd.read_excel('file.xlsx')\n\n# Write to Excel\ndf.to_excel(\n    'dir/myDataFrame.xlsx', \n    sheet_name='Sheet1'\n)\n\n# Read multiple sheets from the same file\nxlsx = pd.ExcelFile('file.xls')\ndf_from_sheet1 = pd.read_excel(xlsx, 'Sheet1')\n</pre> <p>SQL Query</p> <pre>from sqlalchemy import create_engine\nengine = create_engine('sqlite:///:memory:')\n\n# Read from SQL Query\npd.read_sql(\"SELECT * FROM my_table;\", engine)\n\n# Read from Database Table\npd.read_sql_table('my_table', engine)\n\n# Read from SQL Query using read_sql_query()\npd.read_sql_query(\"SELECT * FROM my_table;\", engine)\n\n# Write DataFrame to SQL Table\npd.to_sql('myDf', engine)\n</pre>"},{"location":"examples/polars/app/","title":"App","text":"In\u00a0[\u00a0]: Copied! <pre>import streamlit as st\nfrom pathlib import Path\nimport base64\nimport requests\n</pre> import streamlit as st from pathlib import Path import base64 import requests In\u00a0[\u00a0]: Copied! <pre># Initial page config\nst.set_page_config(\n    page_title='Polars Cheat Sheet',\n    layout=\"wide\",\n    initial_sidebar_state=\"expanded\",\n)\n</pre> # Initial page config st.set_page_config(     page_title='Polars Cheat Sheet',     layout=\"wide\",     initial_sidebar_state=\"expanded\", ) In\u00a0[\u00a0]: Copied! <pre>def main():\n    \"\"\"\n    Main function to set up the Streamlit app layout.\n    \"\"\"\n    cs_sidebar()\n    cs_body()\n    return None\n</pre> def main():     \"\"\"     Main function to set up the Streamlit app layout.     \"\"\"     cs_sidebar()     cs_body()     return None In\u00a0[\u00a0]: Copied! <pre># Define img_to_bytes() function\ndef img_to_bytes(img_url):\n    response = requests.get(img_url)\n    img_bytes = response.content\n    encoded = base64.b64encode(img_bytes).decode()\n    return encoded\n</pre> # Define img_to_bytes() function def img_to_bytes(img_url):     response = requests.get(img_url)     img_bytes = response.content     encoded = base64.b64encode(img_bytes).decode()     return encoded In\u00a0[\u00a0]: Copied! <pre># Define the cs_sidebar() function\ndef cs_sidebar():\n    \"\"\"\n    Populate the sidebar with various content sections related to Polars.\n    \"\"\"\n    st.sidebar.markdown(\n        '''[&lt;img src='data:image/svg;base64,{}' class='img-fluid' width=200 &gt;](https://streamlit.io/)'''.format(\n            img_to_bytes(\"https://raw.githubusercontent.com/fralfaro/DS-Cheat-Sheets/main/docs/examples/polars/polars.png\")), unsafe_allow_html=True)\n\n    st.sidebar.header('Polars Cheat Sheet')\n    st.sidebar.markdown('''\n&lt;small&gt;[Polars](https://pola-rs.github.io/polars-book/) is a highly performant DataFrame library for manipulating structured data. The core is written in Rust, but the library is also available in Python. &lt;/small&gt;\n    ''', unsafe_allow_html=True)\n\n    # Polars installation and import\n    st.sidebar.markdown('__Install and import Polars__')\n    st.sidebar.code('$ pip install polars')\n    st.sidebar.code('''\n# Import Polars convention\n&gt;&gt;&gt; import polars as pl\n''')\n\n    # Creating/reading DataFrames\n    st.sidebar.subheader('Creating/reading DataFrames')\n    st.sidebar.markdown('__Create DataFrame__')\n    st.sidebar.code('''\n            # Create a DataFrame\n            df = pd.DataFrame(\n                {\n                    \"nrs\": [1, 2, 3, None, 5],\n                    \"names\": [\"foo\", \"ham\", \"spam\", \"egg\", None],\n                    \"random\": [0.3, 0.7, 0.1, 0.9, 0.6],\n                    \"groups\": [\"A\", \"A\", \"B\", \"C\", \"B\"],\n                }\n            )\n            ''')\n    st.sidebar.markdown('__Read CSV__')\n    st.sidebar.code('''\n    # Read CSV\n    df = pl.read_csv(\n        \"https://j.mp/iriscsv\",\n         has_header=True\n    )\n            ''')\n    st.sidebar.markdown('__Read parquet__')\n    st.sidebar.code('''\n    # Read a Parquet file with selected columns\n    df = pd.read_parquet(\n        \"path.parquet\", \n        columns=[\"select\", \"columns\"]\n    )\n            ''')\n\n    # Expressions\n    st.sidebar.subheader('Expressions')\n    st.sidebar.markdown('''\n    &lt;small&gt;Polars expressions can be performed in sequence. This improves readability of code. &lt;/small&gt;\n        ''', unsafe_allow_html=True)\n    st.sidebar.code('''\n            # Filter rows where 'nrs' column is less than 4,\n            # then group by 'groups' column and calculate the sum\n            df.filter(pl.col(\"nrs\") &lt; 4).groupby(\"groups\").agg(pl.all().sum())\n            ''')\n\n\n\n    return None\n</pre> # Define the cs_sidebar() function def cs_sidebar():     \"\"\"     Populate the sidebar with various content sections related to Polars.     \"\"\"     st.sidebar.markdown(         '''[](https://streamlit.io/)'''.format(             img_to_bytes(\"https://raw.githubusercontent.com/fralfaro/DS-Cheat-Sheets/main/docs/examples/polars/polars.png\")), unsafe_allow_html=True)      st.sidebar.header('Polars Cheat Sheet')     st.sidebar.markdown(''' [Polars](https://pola-rs.github.io/polars-book/) is a highly performant DataFrame library for manipulating structured data. The core is written in Rust, but the library is also available in Python.      ''', unsafe_allow_html=True)      # Polars installation and import     st.sidebar.markdown('__Install and import Polars__')     st.sidebar.code('$ pip install polars')     st.sidebar.code(''' # Import Polars convention &gt;&gt;&gt; import polars as pl ''')      # Creating/reading DataFrames     st.sidebar.subheader('Creating/reading DataFrames')     st.sidebar.markdown('__Create DataFrame__')     st.sidebar.code('''             # Create a DataFrame             df = pd.DataFrame(                 {                     \"nrs\": [1, 2, 3, None, 5],                     \"names\": [\"foo\", \"ham\", \"spam\", \"egg\", None],                     \"random\": [0.3, 0.7, 0.1, 0.9, 0.6],                     \"groups\": [\"A\", \"A\", \"B\", \"C\", \"B\"],                 }             )             ''')     st.sidebar.markdown('__Read CSV__')     st.sidebar.code('''     # Read CSV     df = pl.read_csv(         \"https://j.mp/iriscsv\",          has_header=True     )             ''')     st.sidebar.markdown('__Read parquet__')     st.sidebar.code('''     # Read a Parquet file with selected columns     df = pd.read_parquet(         \"path.parquet\",          columns=[\"select\", \"columns\"]     )             ''')      # Expressions     st.sidebar.subheader('Expressions')     st.sidebar.markdown('''     Polars expressions can be performed in sequence. This improves readability of code.          ''', unsafe_allow_html=True)     st.sidebar.code('''             # Filter rows where 'nrs' column is less than 4,             # then group by 'groups' column and calculate the sum             df.filter(pl.col(\"nrs\") &lt; 4).groupby(\"groups\").agg(pl.all().sum())             ''')        return None In\u00a0[\u00a0]: Copied! <pre># Define the cs_body() function\ndef cs_body():\n    \"\"\"\n    Create content sections for the main body of the Streamlit cheat sheet with Polars examples.\n    \"\"\"\n    col1, col2, col3 = st.columns(3)  # Create columns for layout\n\n    #######################################\n    # COLUMN 1\n    #######################################\n\n    # Filter\n    col1.subheader(\"Filter\")\n    col1.code('''\n            # Extract rows where 'random' column is greater than 0.5\n            df.filter(pl.col(\"random\") &gt; 0.5)\n\n            # Extract rows where 'groups' is \"B\" and 'random' is greater than 0.5\n            df.filter((pl.col(\"groups\") == \"B\") &amp; (pl.col(\"random\") &gt; 0.5))\n            ''')\n\n    # Sample\n    col1.subheader(\"Sample\")\n    col1.code('''\n            # Randomly select fraction of rows\n            df.sample(frac=0.5)\n\n            # Randomly select n rows\n            df.sample(n=2)\n\n            # Select first n rows\n            df.head(n=2)\n\n            # Select last n rows\n            df.tail(n=2)\n            ''')\n\n    # Expressions Example\n    col1.subheader(\"Expressions Example\")\n    col1.code('''\n            # Filter rows where 'nrs' column is less than 4,\n            # then group by 'groups' column and calculate the sum\n            df.filter(pl.col(\"nrs\") &lt; 4).groupby(\"groups\").agg(pl.all().sum())\n            ''')\n\n    # Subsets - rows and columns\n    col1.subheader(\"Subsets - rows and columns\")\n    col1.code('''\n    # Select rows 2-4\n    df[2:4, :]\n    ''')\n    col1.code('''\n    # Select columns in positions 1 and 3 (first column is 0)\n    df[:, [1, 3]]\n    ''')\n    col1.code('''\n    # Select rows meeting logical condition and specific columns\n    df[df[\"random\"] &gt; 0.5, [\"names\", \"groups\"]]\n    ''')\n\n\n\n    #######################################\n    # COLUMN 2\n    #######################################\n\n    # Reshaping Data \u2013 Change layout, sorting, renaming\n    col1.subheader(\"Reshaping Data \u2013 Change layout, sorting, renaming\")\n    col1.code('''\n            # Append rows of DataFrames\n            pl.concat([df, df2])\n            ''')\n    col1.code('''\n            # Append columns of DataFrames\n            pl.concat([df, df3], how=\"horizontal\")\n            ''')\n    col1.code('''\n            # Gather columns into rows\n            df.melt(id_vars=\"nrs\", value_vars=[\"names\", \"groups\"])\n            ''')\n    col1.code('''\n            # Spread rows into columns\n            df.pivot(values=\"nrs\", index=\"groups\", columns=\"names\")\n            ''')\n    col1.code('''\n            # Order rows by values of a column (low to high)\n            df.sort(\"random\")\n            ''')\n    col1.code('''\n            # Order rows by values of a column (high to low)\n            df.sort(\"random\", reverse=True)\n            ''')\n    col1.code('''\n            # Rename the columns of a DataFrame\n            df.rename({\"nrs\": \"idx\"})\n            ''')\n    col1.code('''\n            # Drop columns from DataFrame\n            df.drop([\"names\", \"random\"])\n            ''')\n\n    #######################################\n    # COLUMN 3\n    #######################################\n\n    # Summarize Data\n    col2.subheader(\"Summarize Data\")\n\n    col2.code('''\n            # Count number of rows with each unique value of variable\n            df[\"groups\"].value_counts()\n            ''')\n\n    col2.code('''\n            # rows in DataFrame (or df.height)\n            len(df) \n            ''')\n\n    col2.code('''\n            # Tuple of # of rows, # of columns in DataFrame\n            df.shape\n            ''')\n\n    col2.code('''\n            # of distinct values in a column\n            df[\"groups\"].n_unique()\n            ''')\n\n    col2.code('''\n            # Basic descriptive and statistics for each column\n            df.describe()\n            ''')\n\n    col2.code('''\n            df.select(\n                [\n                    # Sum values\n                    pl.sum(\"random\").alias(\"sum\"),\n                    # Minimum value\n                    pl.min(\"random\").alias(\"min\"),\n                    # Maximum value\n                    pl.max(\"random\").alias(\"max\"),\n                    # or\n                    pl.col(\"random\").max().alias(\"other_max\"),\n                    # Standard deviation\n                    pl.std(\"random\").alias(\"std_dev\"),\n                    # Variance\n                    pl.var(\"random\").alias(\"variance\"),\n                    # Median\n                    pl.median(\"random\").alias(\"median\"),\n                    # Mean\n                    pl.mean(\"random\").alias(\"mean\"),\n                    # Quantile\n                    pl.quantile(\"random\", 0.75).alias(\"quantile_0.75\"),\n                    # or\n                    pl.col(\"random\").quantile(0.75).alias(\"other_quantile_0.75\"),\n                    # First value\n                    pl.first(\"random\").alias(\"first\"),\n                ]\n            )\n            ''')\n\n    # Group Data\n    col2.subheader(\"Group Data\")\n\n    col2.code('''\n            # Group by values in column named 'col', returning a GroupBy object\n            df.groupby(\"groups\")\n            ''')\n\n    col2.code('''\n            # All of the aggregation functions from above can be applied to a group as well\n            df.groupby(by=\"groups\").agg(\n                [\n                    # Sum values\n                    pl.sum(\"random\").alias(\"sum\"),\n                    # Minimum value\n                    pl.min(\"random\").alias(\"min\"),\n                    # Maximum value\n                    pl.max(\"random\").alias(\"max\"),\n                    # Standard deviation\n                    pl.std(\"random\").alias(\"std_dev\"),\n                    # Variance\n                    pl.var(\"random\").alias(\"variance\"),\n                    # Median\n                    pl.median(\"random\").alias(\"median\"),\n                    # Mean\n                    pl.mean(\"random\").alias(\"mean\"),\n                    # Quantile\n                    pl.quantile(\"random\", 0.75).alias(\"quantile_0.75\"),\n                    # First value\n                    pl.first(\"random\").alias(\"first\"),\n                ]\n            )\n            ''')\n\n    col2.code('''\n            # Additional GroupBy functions\n            df.groupby(by=\"groups\").agg(\n                [\n                    # Count the number of values in each group\n                    pl.count(\"random\").alias(\"size\"),\n                    # Sample one element in each group\n                    pl.col(\"names\").apply(lambda group_df: group_df.sample(1)),\n                ]\n            )\n            ''')\n\n    # Handling Missing Data\n    col3.subheader(\"Handling Missing Data\")\n\n    col3.code('''\n            # Drop rows with any column having a null value\n            df.drop_nulls()\n            ''')\n\n    col3.code('''\n            # Replace null values with given value\n            df.fill_null(42)\n            ''')\n\n    col3.code('''\n            # Replace null values using forward strategy\n            df.fill_null(strategy=\"forward\")\n            # Other fill strategies are \"backward\", \"min\", \"max\", \"mean\", \"zero\", and \"one\"\n            ''')\n\n    col3.code('''\n            # Replace floating point NaN values with given value\n            df.fill_nan(42)\n            ''')\n\n    # Combine Data Sets\n    col3.subheader(\"Combine Data Sets\")\n\n    col3.code('''\n            df4 = pl.DataFrame(\n                {\n                    \"nrs\": [1, 2, 5, 6],\n                    \"animals\": [\"cheetah\", \"lion\", \"leopard\", \"tiger\"],\n                }\n            )\n\n            # Inner join\n            df.join(df4, on=\"nrs\", how=\"inner\")\n\n            # Left join\n            df.join(df4, on=\"nrs\", how=\"left\")\n\n            # Outer join\n            df.join(df4, on=\"nrs\", how=\"outer\")\n\n            # Anti join\n            df.join(df4, on=\"nrs\", how=\"anti\")\n            ''')\n\n    # Make New Columns\n    col3.subheader(\"Make New Columns\")\n\n    col3.code('''\n            # Add a new column to the DataFrame\n            df.with_column((pl.col(\"random\") * pl.col(\"nrs\")).alias(\"product\"))\n            ''')\n\n    col3.code('''\n            # Add several new columns to the DataFrame\n            df.with_columns(\n                [\n                    (pl.col(\"random\") * pl.col(\"nrs\")).alias(\"product\"),\n                    pl.col(\"names\").str.lengths().alias(\"names_lengths\"),\n                ]\n            )\n            ''')\n\n    col3.code('''\n            # Add a column at index 0 that counts the rows\n            df.with_row_count()\n            ''')\n\n    # Rolling Functions\n    col3.subheader(\"Rolling Functions\")\n\n    col3.code('''\n            # Rolling Functions\n            df.select(\n                [\n                    pl.col(\"random\"),\n                    # Rolling maximum value\n                    pl.col(\"random\").rolling_max(window_size=2).alias(\"rolling_max\"),\n                    # Rolling mean value\n                    pl.col(\"random\").rolling_mean(window_size=2).alias(\"rolling_mean\"),\n                    # Rolling median value\n                    pl.col(\"random\")\n                    .rolling_median(window_size=2, min_periods=2)\n                    .alias(\"rolling_median\"),\n                    # ... (other rolling functions)\n                ]\n            )\n            ''')\n\n    # Window Functions\n    col3.subheader(\"Window Functions\")\n    col3.code('''\n            # Window Functions\n            df.select(\n                [\n                    \"names\",\n                    \"groups\",\n                    pl.col(\"random\").sum().over(\"names\").alias(\"sum_by_names\"),\n                    pl.col(\"random\").sum().over(\"groups\").alias(\"sum_by_groups\"),\n                ]\n            )\n            ''')\n</pre> # Define the cs_body() function def cs_body():     \"\"\"     Create content sections for the main body of the Streamlit cheat sheet with Polars examples.     \"\"\"     col1, col2, col3 = st.columns(3)  # Create columns for layout      #######################################     # COLUMN 1     #######################################      # Filter     col1.subheader(\"Filter\")     col1.code('''             # Extract rows where 'random' column is greater than 0.5             df.filter(pl.col(\"random\") &gt; 0.5)              # Extract rows where 'groups' is \"B\" and 'random' is greater than 0.5             df.filter((pl.col(\"groups\") == \"B\") &amp; (pl.col(\"random\") &gt; 0.5))             ''')      # Sample     col1.subheader(\"Sample\")     col1.code('''             # Randomly select fraction of rows             df.sample(frac=0.5)              # Randomly select n rows             df.sample(n=2)              # Select first n rows             df.head(n=2)              # Select last n rows             df.tail(n=2)             ''')      # Expressions Example     col1.subheader(\"Expressions Example\")     col1.code('''             # Filter rows where 'nrs' column is less than 4,             # then group by 'groups' column and calculate the sum             df.filter(pl.col(\"nrs\") &lt; 4).groupby(\"groups\").agg(pl.all().sum())             ''')      # Subsets - rows and columns     col1.subheader(\"Subsets - rows and columns\")     col1.code('''     # Select rows 2-4     df[2:4, :]     ''')     col1.code('''     # Select columns in positions 1 and 3 (first column is 0)     df[:, [1, 3]]     ''')     col1.code('''     # Select rows meeting logical condition and specific columns     df[df[\"random\"] &gt; 0.5, [\"names\", \"groups\"]]     ''')        #######################################     # COLUMN 2     #######################################      # Reshaping Data \u2013 Change layout, sorting, renaming     col1.subheader(\"Reshaping Data \u2013 Change layout, sorting, renaming\")     col1.code('''             # Append rows of DataFrames             pl.concat([df, df2])             ''')     col1.code('''             # Append columns of DataFrames             pl.concat([df, df3], how=\"horizontal\")             ''')     col1.code('''             # Gather columns into rows             df.melt(id_vars=\"nrs\", value_vars=[\"names\", \"groups\"])             ''')     col1.code('''             # Spread rows into columns             df.pivot(values=\"nrs\", index=\"groups\", columns=\"names\")             ''')     col1.code('''             # Order rows by values of a column (low to high)             df.sort(\"random\")             ''')     col1.code('''             # Order rows by values of a column (high to low)             df.sort(\"random\", reverse=True)             ''')     col1.code('''             # Rename the columns of a DataFrame             df.rename({\"nrs\": \"idx\"})             ''')     col1.code('''             # Drop columns from DataFrame             df.drop([\"names\", \"random\"])             ''')      #######################################     # COLUMN 3     #######################################      # Summarize Data     col2.subheader(\"Summarize Data\")      col2.code('''             # Count number of rows with each unique value of variable             df[\"groups\"].value_counts()             ''')      col2.code('''             # rows in DataFrame (or df.height)             len(df)              ''')      col2.code('''             # Tuple of # of rows, # of columns in DataFrame             df.shape             ''')      col2.code('''             # of distinct values in a column             df[\"groups\"].n_unique()             ''')      col2.code('''             # Basic descriptive and statistics for each column             df.describe()             ''')      col2.code('''             df.select(                 [                     # Sum values                     pl.sum(\"random\").alias(\"sum\"),                     # Minimum value                     pl.min(\"random\").alias(\"min\"),                     # Maximum value                     pl.max(\"random\").alias(\"max\"),                     # or                     pl.col(\"random\").max().alias(\"other_max\"),                     # Standard deviation                     pl.std(\"random\").alias(\"std_dev\"),                     # Variance                     pl.var(\"random\").alias(\"variance\"),                     # Median                     pl.median(\"random\").alias(\"median\"),                     # Mean                     pl.mean(\"random\").alias(\"mean\"),                     # Quantile                     pl.quantile(\"random\", 0.75).alias(\"quantile_0.75\"),                     # or                     pl.col(\"random\").quantile(0.75).alias(\"other_quantile_0.75\"),                     # First value                     pl.first(\"random\").alias(\"first\"),                 ]             )             ''')      # Group Data     col2.subheader(\"Group Data\")      col2.code('''             # Group by values in column named 'col', returning a GroupBy object             df.groupby(\"groups\")             ''')      col2.code('''             # All of the aggregation functions from above can be applied to a group as well             df.groupby(by=\"groups\").agg(                 [                     # Sum values                     pl.sum(\"random\").alias(\"sum\"),                     # Minimum value                     pl.min(\"random\").alias(\"min\"),                     # Maximum value                     pl.max(\"random\").alias(\"max\"),                     # Standard deviation                     pl.std(\"random\").alias(\"std_dev\"),                     # Variance                     pl.var(\"random\").alias(\"variance\"),                     # Median                     pl.median(\"random\").alias(\"median\"),                     # Mean                     pl.mean(\"random\").alias(\"mean\"),                     # Quantile                     pl.quantile(\"random\", 0.75).alias(\"quantile_0.75\"),                     # First value                     pl.first(\"random\").alias(\"first\"),                 ]             )             ''')      col2.code('''             # Additional GroupBy functions             df.groupby(by=\"groups\").agg(                 [                     # Count the number of values in each group                     pl.count(\"random\").alias(\"size\"),                     # Sample one element in each group                     pl.col(\"names\").apply(lambda group_df: group_df.sample(1)),                 ]             )             ''')      # Handling Missing Data     col3.subheader(\"Handling Missing Data\")      col3.code('''             # Drop rows with any column having a null value             df.drop_nulls()             ''')      col3.code('''             # Replace null values with given value             df.fill_null(42)             ''')      col3.code('''             # Replace null values using forward strategy             df.fill_null(strategy=\"forward\")             # Other fill strategies are \"backward\", \"min\", \"max\", \"mean\", \"zero\", and \"one\"             ''')      col3.code('''             # Replace floating point NaN values with given value             df.fill_nan(42)             ''')      # Combine Data Sets     col3.subheader(\"Combine Data Sets\")      col3.code('''             df4 = pl.DataFrame(                 {                     \"nrs\": [1, 2, 5, 6],                     \"animals\": [\"cheetah\", \"lion\", \"leopard\", \"tiger\"],                 }             )              # Inner join             df.join(df4, on=\"nrs\", how=\"inner\")              # Left join             df.join(df4, on=\"nrs\", how=\"left\")              # Outer join             df.join(df4, on=\"nrs\", how=\"outer\")              # Anti join             df.join(df4, on=\"nrs\", how=\"anti\")             ''')      # Make New Columns     col3.subheader(\"Make New Columns\")      col3.code('''             # Add a new column to the DataFrame             df.with_column((pl.col(\"random\") * pl.col(\"nrs\")).alias(\"product\"))             ''')      col3.code('''             # Add several new columns to the DataFrame             df.with_columns(                 [                     (pl.col(\"random\") * pl.col(\"nrs\")).alias(\"product\"),                     pl.col(\"names\").str.lengths().alias(\"names_lengths\"),                 ]             )             ''')      col3.code('''             # Add a column at index 0 that counts the rows             df.with_row_count()             ''')      # Rolling Functions     col3.subheader(\"Rolling Functions\")      col3.code('''             # Rolling Functions             df.select(                 [                     pl.col(\"random\"),                     # Rolling maximum value                     pl.col(\"random\").rolling_max(window_size=2).alias(\"rolling_max\"),                     # Rolling mean value                     pl.col(\"random\").rolling_mean(window_size=2).alias(\"rolling_mean\"),                     # Rolling median value                     pl.col(\"random\")                     .rolling_median(window_size=2, min_periods=2)                     .alias(\"rolling_median\"),                     # ... (other rolling functions)                 ]             )             ''')      # Window Functions     col3.subheader(\"Window Functions\")     col3.code('''             # Window Functions             df.select(                 [                     \"names\",                     \"groups\",                     pl.col(\"random\").sum().over(\"names\").alias(\"sum_by_names\"),                     pl.col(\"random\").sum().over(\"groups\").alias(\"sum_by_groups\"),                 ]             )             ''') In\u00a0[\u00a0]: Copied! <pre># Run the main function if the script is executed directly\nif __name__ == '__main__':\n    main()\n</pre> # Run the main function if the script is executed directly if __name__ == '__main__':     main()"},{"location":"examples/polars/polars/","title":"Polars","text":"In\u00a0[\u00a0]: Copied! <pre># Import Polars convention\nimport polars as pl\n</pre> # Import Polars convention import polars as pl In\u00a0[\u00a0]: Copied! <pre># Create DataFrame\ndf = pl.DataFrame(\n    {\n        \"nrs\": [1, 2, 3, None, 5],\n        \"names\": [\"foo\", \"ham\", \"spam\", \"egg\", None],\n        \"random\": [0.3, 0.7, 0.1, 0.9, 0.6],\n        \"groups\": [\"A\", \"A\", \"B\", \"C\", \"B\"],\n    }\n)\n</pre> # Create DataFrame df = pl.DataFrame(     {         \"nrs\": [1, 2, 3, None, 5],         \"names\": [\"foo\", \"ham\", \"spam\", \"egg\", None],         \"random\": [0.3, 0.7, 0.1, 0.9, 0.6],         \"groups\": [\"A\", \"A\", \"B\", \"C\", \"B\"],     } ) In\u00a0[\u00a0]: Copied! <pre># Read CSV\ndf = pl.read_csv(\"https://j.mp/iriscsv\", has_header=True)\n</pre> # Read CSV df = pl.read_csv(\"https://j.mp/iriscsv\", has_header=True) In\u00a0[\u00a0]: Copied! <pre># Read parquet\ndf = pl.read_parquet(\"path.parquet\", columns=[\"select\", \"columns\"])\n</pre> # Read parquet df = pl.read_parquet(\"path.parquet\", columns=[\"select\", \"columns\"]) In\u00a0[\u00a0]: Copied! <pre>df.filter(pl.col(\"nrs\") &lt; 4).groupby(\"groups\").agg(pl.all().sum())\n</pre> df.filter(pl.col(\"nrs\") &lt; 4).groupby(\"groups\").agg(pl.all().sum()) In\u00a0[\u00a0]: Copied! <pre># Filter: Extract rows that meet logical criteria.\ndf.filter(pl.col(\"random\") &gt; 0.5)\ndf.filter((pl.col(\"groups\") == \"B\") &amp; (pl.col(\"random\") &gt; 0.5))\n</pre> # Filter: Extract rows that meet logical criteria. df.filter(pl.col(\"random\") &gt; 0.5) df.filter((pl.col(\"groups\") == \"B\") &amp; (pl.col(\"random\") &gt; 0.5)) In\u00a0[\u00a0]: Copied! <pre># Sample\n# Randomly select fraction of rows.\n#df.sample(frac=0.5)\n\n# Randomly select n rows.\ndf.sample(n=2)\n</pre> # Sample # Randomly select fraction of rows. #df.sample(frac=0.5)  # Randomly select n rows. df.sample(n=2) In\u00a0[\u00a0]: Copied! <pre># Select first n rows\ndf.head(n=2)\n\n# Select last n rows.\ndf.tail(n=2)\n</pre> # Select first n rows df.head(n=2)  # Select last n rows. df.tail(n=2) In\u00a0[\u00a0]: Copied! <pre># Select multiple columns with specific names.\ndf.select([\"nrs\", \"names\"])\n</pre> # Select multiple columns with specific names. df.select([\"nrs\", \"names\"]) In\u00a0[\u00a0]: Copied! <pre># Select columns whose name matches regular expression regex.\ndf.select(pl.col(\"^n.*$\"))\n</pre> # Select columns whose name matches regular expression regex. df.select(pl.col(\"^n.*$\")) In\u00a0[\u00a0]: Copied! <pre># Select rows 2-4.\ndf[2:4, :]\n</pre> # Select rows 2-4. df[2:4, :] In\u00a0[\u00a0]: Copied! <pre># Select columns in positions 1 and 3 (first column is 0).\ndf[:, [1, 3]]\n</pre> # Select columns in positions 1 and 3 (first column is 0). df[:, [1, 3]] In\u00a0[\u00a0]: Copied! <pre># Select rows meeting logical condition, and only the specific columns.\ndf[df[\"random\"] &gt; 0.5, [\"names\", \"groups\"]]\n</pre> # Select rows meeting logical condition, and only the specific columns. df[df[\"random\"] &gt; 0.5, [\"names\", \"groups\"]] In\u00a0[\u00a0]: Copied! <pre>df2 = pl.DataFrame(\n    {\n        \"nrs\": [6],\n        \"names\": [\"wow\"],\n        \"random\": [0.9],\n        \"groups\": [\"B\"],\n    }\n)\n\ndf3 = pl.DataFrame(\n    {\n        \"primes\": [2, 3, 5, 7, 11],\n    }\n)\n</pre> df2 = pl.DataFrame(     {         \"nrs\": [6],         \"names\": [\"wow\"],         \"random\": [0.9],         \"groups\": [\"B\"],     } )  df3 = pl.DataFrame(     {         \"primes\": [2, 3, 5, 7, 11],     } ) In\u00a0[\u00a0]: Copied! <pre># Append rows of DataFrames.\npl.concat([df, df2])\n</pre> # Append rows of DataFrames. pl.concat([df, df2]) In\u00a0[\u00a0]: Copied! <pre># Append columns of DataFrames\npl.concat([df, df3], how=\"horizontal\")\n</pre> # Append columns of DataFrames pl.concat([df, df3], how=\"horizontal\") In\u00a0[\u00a0]: Copied! <pre># Gather columns into rows\ndf.melt(id_vars=\"nrs\", value_vars=[\"names\", \"groups\"])\n</pre> # Gather columns into rows df.melt(id_vars=\"nrs\", value_vars=[\"names\", \"groups\"]) In\u00a0[\u00a0]: Copied! <pre># Spread rows into columns\ndf.pivot(values=\"nrs\", index=\"groups\", columns=\"names\")\n</pre> # Spread rows into columns df.pivot(values=\"nrs\", index=\"groups\", columns=\"names\") In\u00a0[\u00a0]: Copied! <pre># Order rows by values of a column (low to high)\ndf.sort(\"random\")\n</pre> # Order rows by values of a column (low to high) df.sort(\"random\") In\u00a0[\u00a0]: Copied! <pre># Order rows by values of a column (high to low)\ndf.sort(\"random\", reverse=True)\n</pre> # Order rows by values of a column (high to low) df.sort(\"random\", reverse=True) In\u00a0[\u00a0]: Copied! <pre># Rename the columns of a DataFrame\ndf.rename({\"nrs\": \"idx\"})\n</pre> # Rename the columns of a DataFrame df.rename({\"nrs\": \"idx\"}) In\u00a0[\u00a0]: Copied! <pre># Drop columns from DataFrame\ndf.drop([\"names\", \"random\"])\n</pre> # Drop columns from DataFrame df.drop([\"names\", \"random\"]) In\u00a0[\u00a0]: Copied! <pre># Count number of rows with each unique value of variable\ndf[\"groups\"].value_counts()\n</pre> # Count number of rows with each unique value of variable df[\"groups\"].value_counts() In\u00a0[\u00a0]: Copied! <pre># # of rows in DataFrame\nlen(df)\n# or\ndf.height\n</pre> # # of rows in DataFrame len(df) # or df.height In\u00a0[\u00a0]: Copied! <pre># Tuple of # of rows, # of columns in DataFrame\ndf.shape\n</pre> # Tuple of # of rows, # of columns in DataFrame df.shape In\u00a0[\u00a0]: Copied! <pre># # of distinct values in a column\ndf[\"groups\"].n_unique()\n</pre> # # of distinct values in a column df[\"groups\"].n_unique() In\u00a0[\u00a0]: Copied! <pre># Basic descriptive and statistics for each column\ndf.describe()\n</pre> # Basic descriptive and statistics for each column df.describe() In\u00a0[\u00a0]: Copied! <pre># Aggregation functions\ndf.select(\n    [\n        # Sum values\n        pl.sum(\"random\").alias(\"sum\"),\n        # Minimum value\n        pl.min(\"random\").alias(\"min\"),\n        # Maximum value\n        pl.max(\"random\").alias(\"max\"),\n        # or\n        pl.col(\"random\").max().alias(\"other_max\"),\n        # Standard deviation\n        pl.std(\"random\").alias(\"std_dev\"),\n        # Variance\n        pl.var(\"random\").alias(\"variance\"),\n        # Median\n        pl.median(\"random\").alias(\"median\"),\n        # Mean\n        pl.mean(\"random\").alias(\"mean\"),\n        # Quantile\n        pl.quantile(\"random\", 0.75).alias(\"quantile_0.75\"),\n        # or\n        pl.col(\"random\").quantile(0.75).alias(\"other_quantile_0.75\"),\n        # First value\n        pl.first(\"random\").alias(\"first\"),\n    ]\n)\n</pre> # Aggregation functions df.select(     [         # Sum values         pl.sum(\"random\").alias(\"sum\"),         # Minimum value         pl.min(\"random\").alias(\"min\"),         # Maximum value         pl.max(\"random\").alias(\"max\"),         # or         pl.col(\"random\").max().alias(\"other_max\"),         # Standard deviation         pl.std(\"random\").alias(\"std_dev\"),         # Variance         pl.var(\"random\").alias(\"variance\"),         # Median         pl.median(\"random\").alias(\"median\"),         # Mean         pl.mean(\"random\").alias(\"mean\"),         # Quantile         pl.quantile(\"random\", 0.75).alias(\"quantile_0.75\"),         # or         pl.col(\"random\").quantile(0.75).alias(\"other_quantile_0.75\"),         # First value         pl.first(\"random\").alias(\"first\"),     ] ) In\u00a0[\u00a0]: Copied! <pre># Group by values in column named \"col\", returning a GroupBy object\ndf.groupby(\"groups\")\n</pre> # Group by values in column named \"col\", returning a GroupBy object df.groupby(\"groups\") In\u00a0[\u00a0]: Copied! <pre># All of the aggregation functions from above can be applied to a group as well\ndf.groupby(by=\"groups\").agg(\n    [\n        # Sum values\n        pl.sum(\"random\").alias(\"sum\"),\n        # Minimum value\n        pl.min(\"random\").alias(\"min\"),\n        # Maximum value\n        pl.max(\"random\").alias(\"max\"),\n        # or\n        pl.col(\"random\").max().alias(\"other_max\"),\n        # Standard deviation\n        pl.std(\"random\").alias(\"std_dev\"),\n        # Variance\n        pl.var(\"random\").alias(\"variance\"),\n        # Median\n        pl.median(\"random\").alias(\"median\"),\n        # Mean\n        pl.mean(\"random\").alias(\"mean\"),\n        # Quantile\n        pl.quantile(\"random\", 0.75).alias(\"quantile_0.75\"),\n        # or\n        pl.col(\"random\").quantile(0.75).alias(\"other_quantile_0.75\"),\n        # First value\n        pl.first(\"random\").alias(\"first\"),\n    ]\n)\n</pre> # All of the aggregation functions from above can be applied to a group as well df.groupby(by=\"groups\").agg(     [         # Sum values         pl.sum(\"random\").alias(\"sum\"),         # Minimum value         pl.min(\"random\").alias(\"min\"),         # Maximum value         pl.max(\"random\").alias(\"max\"),         # or         pl.col(\"random\").max().alias(\"other_max\"),         # Standard deviation         pl.std(\"random\").alias(\"std_dev\"),         # Variance         pl.var(\"random\").alias(\"variance\"),         # Median         pl.median(\"random\").alias(\"median\"),         # Mean         pl.mean(\"random\").alias(\"mean\"),         # Quantile         pl.quantile(\"random\", 0.75).alias(\"quantile_0.75\"),         # or         pl.col(\"random\").quantile(0.75).alias(\"other_quantile_0.75\"),         # First value         pl.first(\"random\").alias(\"first\"),     ] ) In\u00a0[\u00a0]: Copied! <pre># Additional GroupBy functions\ndf.groupby(by=\"groups\").agg(\n    [\n        # Count the number of values in each group\n        pl.count(\"random\").alias(\"size\"),\n        # Sample one element in each group\n        pl.col(\"names\").apply(lambda group_df: group_df.sample(1)),\n    ]\n)\n</pre> # Additional GroupBy functions df.groupby(by=\"groups\").agg(     [         # Count the number of values in each group         pl.count(\"random\").alias(\"size\"),         # Sample one element in each group         pl.col(\"names\").apply(lambda group_df: group_df.sample(1)),     ] ) In\u00a0[\u00a0]: Copied! <pre># Drop rows with any column having a null value\ndf.drop_nulls()\n</pre> # Drop rows with any column having a null value df.drop_nulls() In\u00a0[\u00a0]: Copied! <pre># Replace null values with given value\ndf.fill_null(42)\n</pre> # Replace null values with given value df.fill_null(42) In\u00a0[\u00a0]: Copied! <pre># Replace null values using forward strategy\ndf.fill_null(strategy=\"forward\")\n# Other fill strategies are \"backward\", \"min\", \"max\", \"mean\", \"zero\" and \"one\"\n</pre> # Replace null values using forward strategy df.fill_null(strategy=\"forward\") # Other fill strategies are \"backward\", \"min\", \"max\", \"mean\", \"zero\" and \"one\" In\u00a0[\u00a0]: Copied! <pre># Replace floating point NaN values with given value\ndf.fill_nan(42)\n</pre> # Replace floating point NaN values with given value df.fill_nan(42) In\u00a0[\u00a0]: Copied! <pre># Add a new column to the DataFrame\ndf.with_column((pl.col(\"random\") * pl.col(\"nrs\")).alias(\"product\"))\n</pre> # Add a new column to the DataFrame df.with_column((pl.col(\"random\") * pl.col(\"nrs\")).alias(\"product\")) In\u00a0[\u00a0]: Copied! <pre># Add several new columns to the DataFrame\ndf.with_columns(\n    [\n        (pl.col(\"random\") * pl.col(\"nrs\")).alias(\"product\"),\n        pl.col(\"names\").str.lengths().alias(\"names_lengths\"),\n    ]\n)\n</pre> # Add several new columns to the DataFrame df.with_columns(     [         (pl.col(\"random\") * pl.col(\"nrs\")).alias(\"product\"),         pl.col(\"names\").str.lengths().alias(\"names_lengths\"),     ] ) In\u00a0[\u00a0]: Copied! <pre># Add a column at index 0 that counts the rows\ndf.with_row_count()\n</pre> # Add a column at index 0 that counts the rows df.with_row_count() In\u00a0[\u00a0]: Copied! <pre># The following rolling functions are available\nimport numpy as np\n\ndf.select(\n    [\n        pl.col(\"random\"),\n        # Rolling maximum value\n        pl.col(\"random\").rolling_max(window_size=2).alias(\"rolling_max\"),\n        # Rolling mean value\n        pl.col(\"random\").rolling_mean(window_size=2).alias(\"rolling_mean\"),\n        # Rolling median value\n        pl.col(\"random\")\n        .rolling_median(window_size=2, min_periods=2)\n        .alias(\"rolling_median\"),\n        # Rolling minimum value\n        pl.col(\"random\").rolling_min(window_size=2).alias(\"rolling_min\"),\n        # Rolling standard deviation\n        pl.col(\"random\").rolling_std(window_size=2).alias(\"rolling_std\"),\n        # Rolling sum values\n        pl.col(\"random\").rolling_sum(window_size=2).alias(\"rolling_sum\"),\n        # Rolling variance\n        pl.col(\"random\").rolling_var(window_size=2).alias(\"rolling_var\"),\n        # Rolling quantile\n        pl.col(\"random\")\n        .rolling_quantile(quantile=0.75, window_size=2, min_periods=2)\n        .alias(\"rolling_quantile\"),\n        # Rolling skew\n        pl.col(\"random\").rolling_skew(window_size=2).alias(\"rolling_skew\"),\n        # Rolling custom function\n        pl.col(\"random\")\n        .rolling_apply(function=np.nanstd, window_size=2)\n        .alias(\"rolling_apply\"),\n    ]\n)\n</pre> # The following rolling functions are available import numpy as np  df.select(     [         pl.col(\"random\"),         # Rolling maximum value         pl.col(\"random\").rolling_max(window_size=2).alias(\"rolling_max\"),         # Rolling mean value         pl.col(\"random\").rolling_mean(window_size=2).alias(\"rolling_mean\"),         # Rolling median value         pl.col(\"random\")         .rolling_median(window_size=2, min_periods=2)         .alias(\"rolling_median\"),         # Rolling minimum value         pl.col(\"random\").rolling_min(window_size=2).alias(\"rolling_min\"),         # Rolling standard deviation         pl.col(\"random\").rolling_std(window_size=2).alias(\"rolling_std\"),         # Rolling sum values         pl.col(\"random\").rolling_sum(window_size=2).alias(\"rolling_sum\"),         # Rolling variance         pl.col(\"random\").rolling_var(window_size=2).alias(\"rolling_var\"),         # Rolling quantile         pl.col(\"random\")         .rolling_quantile(quantile=0.75, window_size=2, min_periods=2)         .alias(\"rolling_quantile\"),         # Rolling skew         pl.col(\"random\").rolling_skew(window_size=2).alias(\"rolling_skew\"),         # Rolling custom function         pl.col(\"random\")         .rolling_apply(function=np.nanstd, window_size=2)         .alias(\"rolling_apply\"),     ] ) In\u00a0[\u00a0]: Copied! <pre># Window functions allow to group by several columns simultaneously\ndf.select(\n    [\n        \"names\",\n        \"groups\",\n        pl.col(\"random\").sum().over(\"names\").alias(\"sum_by_names\"),\n        pl.col(\"random\").sum().over(\"groups\").alias(\"sum_by_groups\"),\n    ]\n)\n</pre> # Window functions allow to group by several columns simultaneously df.select(     [         \"names\",         \"groups\",         pl.col(\"random\").sum().over(\"names\").alias(\"sum_by_names\"),         pl.col(\"random\").sum().over(\"groups\").alias(\"sum_by_groups\"),     ] ) In\u00a0[\u00a0]: Copied! <pre>df4 = pl.DataFrame(\n    {\n        \"nrs\": [1, 2, 5, 6],\n        \"animals\": [\"cheetah\", \"lion\", \"leopard\", \"tiger\"],\n    }\n)\n</pre> df4 = pl.DataFrame(     {         \"nrs\": [1, 2, 5, 6],         \"animals\": [\"cheetah\", \"lion\", \"leopard\", \"tiger\"],     } ) In\u00a0[\u00a0]: Copied! <pre># Inner join\n# Retains only rows with a match in the other set.\ndf.join(df4, on=\"nrs\")\n# or\ndf.join(df4, on=\"nrs\", how=\"inner\")\n</pre> # Inner join # Retains only rows with a match in the other set. df.join(df4, on=\"nrs\") # or df.join(df4, on=\"nrs\", how=\"inner\") In\u00a0[\u00a0]: Copied! <pre># Left join\n# Retains each row from \"left\" set (df).\ndf.join(df4, on=\"nrs\", how=\"left\")\n</pre> # Left join # Retains each row from \"left\" set (df). df.join(df4, on=\"nrs\", how=\"left\") In\u00a0[\u00a0]: Copied! <pre># Outer join\n# Retains each row, even if no other matching row exists.\ndf.join(df4, on=\"nrs\", how=\"outer\")\n</pre> # Outer join # Retains each row, even if no other matching row exists. df.join(df4, on=\"nrs\", how=\"outer\") In\u00a0[\u00a0]: Copied! <pre># Anti join\n# Contains all rows from df that do not have a match in df4.\ndf.join(df4, on=\"nrs\", how=\"anti\")\n</pre> # Anti join # Contains all rows from df that do not have a match in df4. df.join(df4, on=\"nrs\", how=\"anti\")"},{"location":"examples/polars/polars/#polars","title":"Polars\u00b6","text":"<p>Polars is a highly performant DataFrame library for manipulating structured data. The core is written in Rust, but the library is also available in Python.</p>"},{"location":"examples/polars/polars/#install-and-import-polars","title":"Install and import Polars\u00b6","text":"<p><code>$ pip install polars</code></p>"},{"location":"examples/polars/polars/#creatingreading-dataframes","title":"Creating/reading DataFrames\u00b6","text":""},{"location":"examples/polars/polars/#expressions","title":"Expressions\u00b6","text":"<p>Polars expressions can be performed in sequence. This improves readability of code.</p>"},{"location":"examples/polars/polars/#subset-observations-rows","title":"Subset Observations - rows\u00b6","text":""},{"location":"examples/polars/polars/#subset-variables-columns","title":"Subset Variables - columns\u00b6","text":""},{"location":"examples/polars/polars/#subsets-rows-and-columns","title":"Subsets - rows and columns\u00b6","text":""},{"location":"examples/polars/polars/#reshaping-data-change-layout-sorting-renaming","title":"Reshaping Data \u2013 Change layout, sorting, renaming\u00b6","text":""},{"location":"examples/polars/polars/#summarize-data","title":"Summarize Data\u00b6","text":""},{"location":"examples/polars/polars/#group-data","title":"Group Data\u00b6","text":""},{"location":"examples/polars/polars/#handling-missing-data","title":"Handling Missing Data\u00b6","text":""},{"location":"examples/polars/polars/#make-new-columns","title":"Make New Columns\u00b6","text":""},{"location":"examples/polars/polars/#rolling-functions","title":"Rolling Functions\u00b6","text":""},{"location":"examples/polars/polars/#window-functions","title":"Window functions\u00b6","text":""},{"location":"examples/polars/polars/#combine-data-sets","title":"Combine Data Sets\u00b6","text":""},{"location":"examples/python/app/","title":"App","text":"In\u00a0[\u00a0]: Copied! <pre>import streamlit as st\nfrom pathlib import Path\nimport base64\nimport requests\n</pre> import streamlit as st from pathlib import Path import base64 import requests In\u00a0[\u00a0]: Copied! <pre># Initial page config\nst.set_page_config(\n    page_title='Python Cheat Sheet',\n    layout=\"wide\",\n    initial_sidebar_state=\"expanded\",\n)\n</pre> # Initial page config st.set_page_config(     page_title='Python Cheat Sheet',     layout=\"wide\",     initial_sidebar_state=\"expanded\", ) In\u00a0[\u00a0]: Copied! <pre>def main():\n    \"\"\"\n    Main function to set up the Streamlit app layout.\n    \"\"\"\n    cs_sidebar()\n    cs_body()\n    return None\n</pre> def main():     \"\"\"     Main function to set up the Streamlit app layout.     \"\"\"     cs_sidebar()     cs_body()     return None In\u00a0[\u00a0]: Copied! <pre># Define img_to_bytes() function\ndef img_to_bytes(img_url):\n    response = requests.get(img_url)\n    img_bytes = response.content\n    encoded = base64.b64encode(img_bytes).decode()\n    return encoded\n</pre> # Define img_to_bytes() function def img_to_bytes(img_url):     response = requests.get(img_url)     img_bytes = response.content     encoded = base64.b64encode(img_bytes).decode()     return encoded In\u00a0[\u00a0]: Copied! <pre># Define the cs_sidebar() function\ndef cs_sidebar():\n    \"\"\"\n    Populate the sidebar with various content sections related to Python.\n    \"\"\"\n    st.sidebar.markdown(\n        '''[&lt;img src='data:image/png;base64,{}' class='img-fluid' width=95 &gt;](https://streamlit.io/)'''.format(\n            img_to_bytes(\"https://raw.githubusercontent.com/fralfaro/DS-Cheat-Sheets/main/docs/examples/python/python.png\")), unsafe_allow_html=True)\n\n    st.sidebar.header('Python Cheat Sheet')\n    st.sidebar.markdown('''\n&lt;small&gt;[Python](https://www.python.org/) is a high-level, interpreted programming\n language known for its simplicity, readability, and versatility. \n Created by Guido van Rossum and first released in 1991,\n  Python has gained immense popularity in various domains,\n   including web development, data science, automation, and more.&lt;/small&gt;\n    ''', unsafe_allow_html=True)\n\n    # why python ?\n    st.sidebar.markdown('__Why Python?__')\n    st.sidebar.markdown('''\n    &lt;small&gt;  Python has experienced a remarkable surge in popularity over the years and has become one of the most \n    widely used programming languages across various fields. &lt;/small&gt; ''', unsafe_allow_html=True)\n\n    st.sidebar.markdown(\n        '''[&lt;img src='data:image/png;base64,{}' class='img-fluid' width=300 &gt;](https://streamlit.io/)'''.format(\n            img_to_bytes(\"https://raw.githubusercontent.com/fralfaro/DS-Cheat-Sheets/main/docs/examples/python/survey2.png\")), unsafe_allow_html=True)\n\n    return None\n</pre> # Define the cs_sidebar() function def cs_sidebar():     \"\"\"     Populate the sidebar with various content sections related to Python.     \"\"\"     st.sidebar.markdown(         '''[](https://streamlit.io/)'''.format(             img_to_bytes(\"https://raw.githubusercontent.com/fralfaro/DS-Cheat-Sheets/main/docs/examples/python/python.png\")), unsafe_allow_html=True)      st.sidebar.header('Python Cheat Sheet')     st.sidebar.markdown(''' [Python](https://www.python.org/) is a high-level, interpreted programming  language known for its simplicity, readability, and versatility.   Created by Guido van Rossum and first released in 1991,   Python has gained immense popularity in various domains,    including web development, data science, automation, and more.     ''', unsafe_allow_html=True)      # why python ?     st.sidebar.markdown('__Why Python?__')     st.sidebar.markdown('''       Python has experienced a remarkable surge in popularity over the years and has become one of the most      widely used programming languages across various fields.  ''', unsafe_allow_html=True)      st.sidebar.markdown(         '''[](https://streamlit.io/)'''.format(             img_to_bytes(\"https://raw.githubusercontent.com/fralfaro/DS-Cheat-Sheets/main/docs/examples/python/survey2.png\")), unsafe_allow_html=True)      return None In\u00a0[\u00a0]: Copied! <pre># Define the cs_body() function\ndef cs_body():\n    \"\"\"\n    Create content sections for the main body of the Streamlit cheat sheet with Python examples.\n    \"\"\"\n    col1, col2, col3 = st.columns(3)  # Create columns for layout\n\n    #######################################\n    # COLUMN 1\n    #######################################\n\n    # Hello, World!\n    col1.subheader('Hello, World!')\n    col1.code('''\n    print(\"Hello, World!\")\n        ''')\n\n    # Comments\n    col1.subheader('Comments')\n    col1.code('''\n    # This is a comment\n        ''')\n\n    # Variables and Data Types\n    col1.subheader('Variables and Data Types')\n    col1.code('''\n    x = 5               # Integer\n    y = 3.14            # Float\n    name = \"John\"       # String\n    is_student = True   # Boolean\n        ''')\n\n    # Basic Operations\n    col1.subheader('Basic Operations')\n    col1.code('''\n    # Perform basic arithmetic operations\n    sum_result = x + y\n    sub_result = x - y\n    mul_result = x * y\n    div_result = x / y\n        ''')\n\n\n    # String Operations\n    col1.subheader('String Operations')\n    col1.code('''\n    # String concatenation\n    full_name = name + \" Doe\"\n\n    # Formatted string\n    formatted_string = f\"Hello, {name}!\"\n        ''')\n\n    # Input and Output\n    col1.subheader('Input and Output')\n    col1.code('''\n    # Get user input and display it\n    user_input = input(\"Enter a number: \")\n    print(\"You entered:\", user_input)\n        ''')\n\n    # File Handling\n    col1.subheader('File Handling')\n    col1.code('''\n    # Read content from a file\n    with open(\"file.txt\", \"r\") as file:\n        content = file.read()\n\n    # Write content to a new file\n    with open(\"new_file.txt\", \"w\") as new_file:\n        new_file.write(\"Hello, world!\")\n        ''')\n\n    # Conditional Statements\n    col1.subheader('Conditional Statements')\n    col1.code('''\n    # Check if x is greater than y\n    if x &gt; y:\n        print(\"x is greater\")\n    # If not, check if x is less than y\n    elif x &lt; y:\n        print(\"y is greater\")\n    # If neither condition is true, they must be equal\n    else:\n        print(\"x and y are equal\")\n        ''')\n\n    #######################################\n    # COLUMN 2\n    #######################################\n\n    # Creating lists\n    col2.subheader('Creating Lists')\n    col2.code('''\n    # Create lists with [], elements separated by commas\n    x = [1, 3, 2]\n        ''')\n\n    # List functions and methods\n    col2.subheader('List Functions and Methods')\n    col2.code('''\n    # Return a sorted copy of the list e.g., [1,2,3]\n    sorted_list = sorted(x)\n\n    # Sorts the list in place (replaces x)\n    x.sort()\n\n    # Reverse the order of elements in x e.g., [2,3,1]\n    reversed_list = list(reversed(x))\n\n    # Reverse the list in place\n    x.reverse()\n\n    # Count the number of element 2 in the list\n    count_2 = x.count(2)\n        ''')\n\n    # Selecting list elements\n    col2.subheader('Selecting List Elements')\n    col2.code('''\n    # Select the 0th element in the list\n    element_0 = x[0]\n\n    # Select the last element in the list\n    last_element = x[-1]\n\n    # Select 1st (inclusive) to 3rd (exclusive)\n    subset_1_to_3 = x[1:3]\n\n    # Select the 2nd to the end\n    subset_2_to_end = x[2:]\n\n    # Select 0th to 3rd (exclusive)\n    subset_0_to_3 = x[:3]\n        ''')\n\n    # Concatenating lists\n    col2.subheader('Concatenating Lists')\n    col2.code('''\n    # Define the x and y lists\n    x = [1, 3, 6]\n    y = [10, 15, 21]\n\n    # Concatenate lists using '+'\n    concatenated_list = x + y\n\n    # Replicate elements in a list using '*'\n    replicated_list = 3 * x\n        ''')\n\n    # Creating dictionaries\n    col2.subheader('Creating Dictionaries')\n    col2.code('''\n    # Create a dictionary with {}\n    my_dict = {'a': 1, 'b': 2, 'c': 3}\n\n        ''')\n\n    # Dictionary functions and methods\n    col2.subheader('Dictionary Functions and Methods')\n    col2.code('''\n    # Get the keys of a dictionary\n    my_dict.keys()  # Returns dict_keys(['a', 'b', 'c'])\n\n    # Get the values of a dictionary\n    my_dict.values()  # Returns dict_values([1, 2, 3])\n    \n    # Get a value from a dictionary by specifying the key\n    my_dict['a']  # Returns 1  \n        ''')\n\n    #######################################\n    # COLUMN 3\n    #######################################\n\n    # Loops\n    col3.subheader('Loops')\n    col3.code('''\n    # For loop\n    numbers = [1, 2, 3, 4, 5]\n    for num in numbers:\n        print(num)\n\n    # While loop\n    x = 5\n    while x &gt; 0:\n        print(x)\n        x -= 1\n        ''')\n\n    # Error Handling\n    col3.subheader('Error Handling')\n    col3.code('''\n    # Try to perform division\n    try:\n        result = x / y  # Attempt to divide x by y\n    except ZeroDivisionError as e:  # If a ZeroDivisionError occurs\n        print(\"Cannot divide by zero\")  \n        print(e)\n        ''')\n\n    # List Comprehensions\n    col3.subheader('List Comprehensions')\n    col3.code('''\n    # Create a list of squared numbers using a list comprehension\n    squared_numbers = [num**2 for num in numbers]\n\n    # Create a list of even numbers using a list comprehension with condition\n    even_numbers = [num for num in numbers if num % 2 == 0]\n        ''')\n\n    # Functions\n    col3.subheader('Functions')\n    col3.code('''\n    # Define a function that takes a name parameter\n    def greet(name):\n        return f\"Hello, {name}!\"\n\n    # Call the greet function with the argument \"Alice\"\n    greeting = greet(\"Alice\")\n        ''')\n\n    # Built-in Functions\n    col3.subheader('Built-in Functions')\n    col3.code('''\n    # Get the length of a list\n    len_fruits = len(fruits)\n\n    # Find the maximum value in a list\n    max_number = max(numbers)\n\n    # Find the minimum value in a list\n    min_number = min(numbers)\n        ''')\n\n    # Importing Modules\n    col3.subheader('Importing Modules')\n    col3.code('''\n    import math\n    sqrt_result = math.sqrt(x)  # Calculate square root using math module\n\n    from random import randint\n    random_number = randint(1, 10)  # Generate a random number between 1 and 10\n\n    import math\n    sqrt_result = math.sqrt(x)  # Reusing the math module for another calculation\n        ''')\n\n    # Classes and Objects\n    col3.subheader('Classes and Objects')\n    col3.code('''\n    class Dog:\n        def __init__(self, name, age):\n            self.name = name\n            self.age = age\n\n        def bark(self):\n            return \"Woof!\"\n\n    my_dog = Dog(\"Buddy\", 3)\n        ''')\n</pre> # Define the cs_body() function def cs_body():     \"\"\"     Create content sections for the main body of the Streamlit cheat sheet with Python examples.     \"\"\"     col1, col2, col3 = st.columns(3)  # Create columns for layout      #######################################     # COLUMN 1     #######################################      # Hello, World!     col1.subheader('Hello, World!')     col1.code('''     print(\"Hello, World!\")         ''')      # Comments     col1.subheader('Comments')     col1.code('''     # This is a comment         ''')      # Variables and Data Types     col1.subheader('Variables and Data Types')     col1.code('''     x = 5               # Integer     y = 3.14            # Float     name = \"John\"       # String     is_student = True   # Boolean         ''')      # Basic Operations     col1.subheader('Basic Operations')     col1.code('''     # Perform basic arithmetic operations     sum_result = x + y     sub_result = x - y     mul_result = x * y     div_result = x / y         ''')       # String Operations     col1.subheader('String Operations')     col1.code('''     # String concatenation     full_name = name + \" Doe\"      # Formatted string     formatted_string = f\"Hello, {name}!\"         ''')      # Input and Output     col1.subheader('Input and Output')     col1.code('''     # Get user input and display it     user_input = input(\"Enter a number: \")     print(\"You entered:\", user_input)         ''')      # File Handling     col1.subheader('File Handling')     col1.code('''     # Read content from a file     with open(\"file.txt\", \"r\") as file:         content = file.read()      # Write content to a new file     with open(\"new_file.txt\", \"w\") as new_file:         new_file.write(\"Hello, world!\")         ''')      # Conditional Statements     col1.subheader('Conditional Statements')     col1.code('''     # Check if x is greater than y     if x &gt; y:         print(\"x is greater\")     # If not, check if x is less than y     elif x &lt; y:         print(\"y is greater\")     # If neither condition is true, they must be equal     else:         print(\"x and y are equal\")         ''')      #######################################     # COLUMN 2     #######################################      # Creating lists     col2.subheader('Creating Lists')     col2.code('''     # Create lists with [], elements separated by commas     x = [1, 3, 2]         ''')      # List functions and methods     col2.subheader('List Functions and Methods')     col2.code('''     # Return a sorted copy of the list e.g., [1,2,3]     sorted_list = sorted(x)      # Sorts the list in place (replaces x)     x.sort()      # Reverse the order of elements in x e.g., [2,3,1]     reversed_list = list(reversed(x))      # Reverse the list in place     x.reverse()      # Count the number of element 2 in the list     count_2 = x.count(2)         ''')      # Selecting list elements     col2.subheader('Selecting List Elements')     col2.code('''     # Select the 0th element in the list     element_0 = x[0]      # Select the last element in the list     last_element = x[-1]      # Select 1st (inclusive) to 3rd (exclusive)     subset_1_to_3 = x[1:3]      # Select the 2nd to the end     subset_2_to_end = x[2:]      # Select 0th to 3rd (exclusive)     subset_0_to_3 = x[:3]         ''')      # Concatenating lists     col2.subheader('Concatenating Lists')     col2.code('''     # Define the x and y lists     x = [1, 3, 6]     y = [10, 15, 21]      # Concatenate lists using '+'     concatenated_list = x + y      # Replicate elements in a list using '*'     replicated_list = 3 * x         ''')      # Creating dictionaries     col2.subheader('Creating Dictionaries')     col2.code('''     # Create a dictionary with {}     my_dict = {'a': 1, 'b': 2, 'c': 3}          ''')      # Dictionary functions and methods     col2.subheader('Dictionary Functions and Methods')     col2.code('''     # Get the keys of a dictionary     my_dict.keys()  # Returns dict_keys(['a', 'b', 'c'])      # Get the values of a dictionary     my_dict.values()  # Returns dict_values([1, 2, 3])          # Get a value from a dictionary by specifying the key     my_dict['a']  # Returns 1           ''')      #######################################     # COLUMN 3     #######################################      # Loops     col3.subheader('Loops')     col3.code('''     # For loop     numbers = [1, 2, 3, 4, 5]     for num in numbers:         print(num)      # While loop     x = 5     while x &gt; 0:         print(x)         x -= 1         ''')      # Error Handling     col3.subheader('Error Handling')     col3.code('''     # Try to perform division     try:         result = x / y  # Attempt to divide x by y     except ZeroDivisionError as e:  # If a ZeroDivisionError occurs         print(\"Cannot divide by zero\")           print(e)         ''')      # List Comprehensions     col3.subheader('List Comprehensions')     col3.code('''     # Create a list of squared numbers using a list comprehension     squared_numbers = [num**2 for num in numbers]      # Create a list of even numbers using a list comprehension with condition     even_numbers = [num for num in numbers if num % 2 == 0]         ''')      # Functions     col3.subheader('Functions')     col3.code('''     # Define a function that takes a name parameter     def greet(name):         return f\"Hello, {name}!\"      # Call the greet function with the argument \"Alice\"     greeting = greet(\"Alice\")         ''')      # Built-in Functions     col3.subheader('Built-in Functions')     col3.code('''     # Get the length of a list     len_fruits = len(fruits)      # Find the maximum value in a list     max_number = max(numbers)      # Find the minimum value in a list     min_number = min(numbers)         ''')      # Importing Modules     col3.subheader('Importing Modules')     col3.code('''     import math     sqrt_result = math.sqrt(x)  # Calculate square root using math module      from random import randint     random_number = randint(1, 10)  # Generate a random number between 1 and 10      import math     sqrt_result = math.sqrt(x)  # Reusing the math module for another calculation         ''')      # Classes and Objects     col3.subheader('Classes and Objects')     col3.code('''     class Dog:         def __init__(self, name, age):             self.name = name             self.age = age          def bark(self):             return \"Woof!\"      my_dog = Dog(\"Buddy\", 3)         ''') In\u00a0[\u00a0]: Copied! <pre># Run the main function if the script is executed directly\nif __name__ == '__main__':\n    main()\n</pre> # Run the main function if the script is executed directly if __name__ == '__main__':     main()"},{"location":"examples/python/python/","title":"Python","text":"In\u00a0[1]: Copied! <pre>print(\"Hello, World!\")\n</pre> print(\"Hello, World!\") <pre>Hello, World!\n</pre> In\u00a0[2]: Copied! <pre># This is a comment\n</pre> # This is a comment In\u00a0[3]: Copied! <pre># Define an integer variable\nx = 5               # Integer\n\n# Define a float variable\ny = 3.14            # Float\n\n# Define a string variable\nname = \"John\"       # String\n\n# Define a boolean variable\nis_student = True   # Boolean\n\n# Print the values of the variables\nprint(\"x:\", x)\nprint(\"y:\", y)\nprint(\"name:\", name)\nprint(\"is_student:\", is_student)\n</pre> # Define an integer variable x = 5               # Integer  # Define a float variable y = 3.14            # Float  # Define a string variable name = \"John\"       # String  # Define a boolean variable is_student = True   # Boolean  # Print the values of the variables print(\"x:\", x) print(\"y:\", y) print(\"name:\", name) print(\"is_student:\", is_student) <pre>x: 5\ny: 3.14\nname: John\nis_student: True\n</pre> In\u00a0[4]: Copied! <pre># Perform basic arithmetic operations\nsum_result = x + y  # Add x and y\nsub_result = x - y  # Subtract y from x\nmul_result = x * y  # Multiply x and y\ndiv_result = x / y  # Divide x by y\n\n# Print the results of the arithmetic operations\nprint(\"sum_result:\", sum_result)\nprint(\"sub_result:\", sub_result)\nprint(\"mul_result:\", mul_result)\nprint(\"div_result:\", div_result)\n</pre> # Perform basic arithmetic operations sum_result = x + y  # Add x and y sub_result = x - y  # Subtract y from x mul_result = x * y  # Multiply x and y div_result = x / y  # Divide x by y  # Print the results of the arithmetic operations print(\"sum_result:\", sum_result) print(\"sub_result:\", sub_result) print(\"mul_result:\", mul_result) print(\"div_result:\", div_result) <pre>sum_result: 8.14\nsub_result: 1.8599999999999999\nmul_result: 15.700000000000001\ndiv_result: 1.592356687898089\n</pre> In\u00a0[5]: Copied! <pre># String concatenation\nfull_name = name + \" Doe\"  # Concatenate 'name' and \" Doe\"\n\n# Formatted string\nformatted_string = f\"Hello, {name}!\"  # Create a formatted string using 'name'\n\n# Print the results of string operations\nprint(\"full_name:\", full_name)\nprint(\"formatted_string:\", formatted_string)\n</pre> # String concatenation full_name = name + \" Doe\"  # Concatenate 'name' and \" Doe\"  # Formatted string formatted_string = f\"Hello, {name}!\"  # Create a formatted string using 'name'  # Print the results of string operations print(\"full_name:\", full_name) print(\"formatted_string:\", formatted_string) <pre>full_name: John Doe\nformatted_string: Hello, John!\n</pre> In\u00a0[6]: Copied! <pre># Define the values of x and y\nx = 7\ny = 3.5\n\n# Check if x is greater than y\nif x &gt; y:\n    print(\"x is greater\")\n# If not, check if x is less than y\nelif x &lt; y:\n    print(\"y is greater\")\n# If neither condition is true, they must be equal\nelse:\n    print(\"x and y are equal\")\n</pre> # Define the values of x and y x = 7 y = 3.5  # Check if x is greater than y if x &gt; y:     print(\"x is greater\") # If not, check if x is less than y elif x &lt; y:     print(\"y is greater\") # If neither condition is true, they must be equal else:     print(\"x and y are equal\") <pre>x is greater\n</pre> In\u00a0[7]: Copied! <pre># Create a list with elements 1, 3, and 2\nx = [1, 3, 2]\n\n# Print the list\nprint(\"x:\", x)\n</pre> # Create a list with elements 1, 3, and 2 x = [1, 3, 2]  # Print the list print(\"x:\", x) <pre>x: [1, 3, 2]\n</pre> In\u00a0[8]: Copied! <pre># Return a sorted copy of the list\nsorted_list = sorted(x)  # Creates a new list with elements in sorted order\n\n# Sorts the list in place (replaces x)\nx.sort()  # Modifies the existing list x to be sorted\n\n# Reverse the order of elements in x\nreversed_list = list(reversed(x))  # Creates a new list with elements in reversed order\n\n# Reverse the list in place\nx.reverse()  # Modifies the existing list x to be reversed\n\n# Count the number of element 2 in the list\ncount_2 = x.count(2)  # Counts the occurrences of element 2 in the list x\n\n# Print the results of list operations\nprint(\"sorted_list:\", sorted_list)\nprint(\"reversed_list:\", reversed_list)\nprint(\"count_2:\", count_2)\n</pre> # Return a sorted copy of the list sorted_list = sorted(x)  # Creates a new list with elements in sorted order  # Sorts the list in place (replaces x) x.sort()  # Modifies the existing list x to be sorted  # Reverse the order of elements in x reversed_list = list(reversed(x))  # Creates a new list with elements in reversed order  # Reverse the list in place x.reverse()  # Modifies the existing list x to be reversed  # Count the number of element 2 in the list count_2 = x.count(2)  # Counts the occurrences of element 2 in the list x  # Print the results of list operations print(\"sorted_list:\", sorted_list) print(\"reversed_list:\", reversed_list) print(\"count_2:\", count_2) <pre>sorted_list: [1, 2, 3]\nreversed_list: [3, 2, 1]\ncount_2: 1\n</pre> In\u00a0[9]: Copied! <pre># Select the 0th element in the list\nelement_0 = x[0]  # Assigns the first element of x to element_0\n\n# Select the last element in the list\nlast_element = x[-1]  # Assigns the last element of x to last_element\n\n# Select 1st (inclusive) to 3rd (exclusive)\nsubset_1_to_3 = x[1:3]  # Creates a subset containing elements from index 1 to 2\n\n# Select the 2nd to the end\nsubset_2_to_end = x[2:]  # Creates a subset containing elements from index 2 to the end\n\n# Select 0th to 3rd (exclusive)\nsubset_0_to_3 = x[:3]  # Creates a subset containing elements from index 0 to 2\n\n# Print the selected elements and subsets\nprint(\"element_0:\", element_0)\nprint(\"last_element:\", last_element)\nprint(\"subset_1_to_3:\", subset_1_to_3)\nprint(\"subset_2_to_end:\", subset_2_to_end)\nprint(\"subset_0_to_3:\", subset_0_to_3)\n</pre> # Select the 0th element in the list element_0 = x[0]  # Assigns the first element of x to element_0  # Select the last element in the list last_element = x[-1]  # Assigns the last element of x to last_element  # Select 1st (inclusive) to 3rd (exclusive) subset_1_to_3 = x[1:3]  # Creates a subset containing elements from index 1 to 2  # Select the 2nd to the end subset_2_to_end = x[2:]  # Creates a subset containing elements from index 2 to the end  # Select 0th to 3rd (exclusive) subset_0_to_3 = x[:3]  # Creates a subset containing elements from index 0 to 2  # Print the selected elements and subsets print(\"element_0:\", element_0) print(\"last_element:\", last_element) print(\"subset_1_to_3:\", subset_1_to_3) print(\"subset_2_to_end:\", subset_2_to_end) print(\"subset_0_to_3:\", subset_0_to_3) <pre>element_0: 3\nlast_element: 1\nsubset_1_to_3: [2, 1]\nsubset_2_to_end: [1]\nsubset_0_to_3: [3, 2, 1]\n</pre> In\u00a0[10]: Copied! <pre># Define the x and y lists\nx = [1, 3, 6]\ny = [10, 15, 21]\n\n# Concatenate lists using '+'\nconcatenated_list = x + y  # Creates a new list by concatenating x and y\n\n# Replicate elements in a list using '*'\nreplicated_list = 3 * x  # Creates a new list with elements of x replicated 3 times\n\n# Print the results of list operations\nprint(\"concatenated_list:\", concatenated_list)\nprint(\"replicated_list:\", replicated_list)\n</pre> # Define the x and y lists x = [1, 3, 6] y = [10, 15, 21]  # Concatenate lists using '+' concatenated_list = x + y  # Creates a new list by concatenating x and y  # Replicate elements in a list using '*' replicated_list = 3 * x  # Creates a new list with elements of x replicated 3 times  # Print the results of list operations print(\"concatenated_list:\", concatenated_list) print(\"replicated_list:\", replicated_list) <pre>concatenated_list: [1, 3, 6, 10, 15, 21]\nreplicated_list: [1, 3, 6, 1, 3, 6, 1, 3, 6]\n</pre> In\u00a0[11]: Copied! <pre># Create a dictionary with key-value pairs\nmy_dict = {'a': 1, 'b': 2, 'c': 3}\n\n# Print the dictionary\nprint(\"my_dict:\", my_dict)\n</pre> # Create a dictionary with key-value pairs my_dict = {'a': 1, 'b': 2, 'c': 3}  # Print the dictionary print(\"my_dict:\", my_dict) <pre>my_dict: {'a': 1, 'b': 2, 'c': 3}\n</pre> In\u00a0[12]: Copied! <pre># Get the keys of a dictionary\nkeys = my_dict.keys()  # Returns dict_keys(['a', 'b', 'c'])\n\n# Get the values of a dictionary\nvalues = my_dict.values()  # Returns dict_values([1, 2, 3])\n\n# Get a value from a dictionary by specifying the key\nvalue_a = my_dict['a']  # Returns 1\n\n# Print the results of dictionary operations\nprint(\"keys:\", keys)\nprint(\"values:\", values)\nprint(\"value_a:\", value_a)\n</pre> # Get the keys of a dictionary keys = my_dict.keys()  # Returns dict_keys(['a', 'b', 'c'])  # Get the values of a dictionary values = my_dict.values()  # Returns dict_values([1, 2, 3])  # Get a value from a dictionary by specifying the key value_a = my_dict['a']  # Returns 1  # Print the results of dictionary operations print(\"keys:\", keys) print(\"values:\", values) print(\"value_a:\", value_a) <pre>keys: dict_keys(['a', 'b', 'c'])\nvalues: dict_values([1, 2, 3])\nvalue_a: 1\n</pre> In\u00a0[13]: Copied! <pre># Define a list of numbers\nnumbers = [1, 2, 3, 4, 5]\n\n# For loop\nprint(\"Using a for loop:\")\nfor num in numbers:\n    print(num)\n</pre> # Define a list of numbers numbers = [1, 2, 3, 4, 5]  # For loop print(\"Using a for loop:\") for num in numbers:     print(num) <pre>Using a for loop:\n1\n2\n3\n4\n5\n</pre> In\u00a0[14]: Copied! <pre># While loop\nx = 5\nprint(\"Using a while loop:\")\nwhile x &gt; 0:\n    print(x)\n    x -= 1\n</pre> # While loop x = 5 print(\"Using a while loop:\") while x &gt; 0:     print(x)     x -= 1 <pre>Using a while loop:\n5\n4\n3\n2\n1\n</pre> In\u00a0[15]: Copied! <pre># Define a function that takes a name parameter\ndef greet(name):\n    return f\"Hello, {name}!\"\n\n# Call the greet function with the argument \"Alice\"\ngreeting = greet(\"Alice\")  # Calls the greet function and stores the result in greeting\n\n# Print the greeting\nprint(\"greeting:\", greeting)\n</pre> # Define a function that takes a name parameter def greet(name):     return f\"Hello, {name}!\"  # Call the greet function with the argument \"Alice\" greeting = greet(\"Alice\")  # Calls the greet function and stores the result in greeting  # Print the greeting print(\"greeting:\", greeting) <pre>greeting: Hello, Alice!\n</pre> In\u00a0[16]: Copied! <pre># Define a list of fruits and numbers\nfruits = ['apple', 'banana', 'orange', 'kiwi']\nnumbers = [14, 27, 8, 42, 5]\n\n# Get the length of the list 'fruits'\nlen_fruits = len(fruits)\n\n# Find the maximum value in the list 'numbers'\nmax_number = max(numbers)\n\n# Find the minimum value in the list 'numbers'\nmin_number = min(numbers)\n\n# Print the results\nprint(\"Length of fruits list:\", len_fruits)\nprint(\"Maximum value in numbers list:\", max_number)\nprint(\"Minimum value in numbers list:\", min_number)\n</pre> # Define a list of fruits and numbers fruits = ['apple', 'banana', 'orange', 'kiwi'] numbers = [14, 27, 8, 42, 5]  # Get the length of the list 'fruits' len_fruits = len(fruits)  # Find the maximum value in the list 'numbers' max_number = max(numbers)  # Find the minimum value in the list 'numbers' min_number = min(numbers)  # Print the results print(\"Length of fruits list:\", len_fruits) print(\"Maximum value in numbers list:\", max_number) print(\"Minimum value in numbers list:\", min_number) <pre>Length of fruits list: 4\nMaximum value in numbers list: 42\nMinimum value in numbers list: 5\n</pre> In\u00a0[17]: Copied! <pre>import math\n\n# Calculate square root using math module\nsqrt_result = math.sqrt(x)\n\n# Generate a random number between 1 and 10\nfrom random import randint\nrandom_number = randint(1, 10)\n\n# Reusing the math module for another calculation\nsqrt_result_reuse = math.sqrt(x)\n\n# Print the results\nprint(\"sqrt_result:\", sqrt_result)\nprint(\"random_number:\", random_number)\nprint(\"sqrt_result_reuse:\", sqrt_result_reuse)\n</pre> import math  # Calculate square root using math module sqrt_result = math.sqrt(x)  # Generate a random number between 1 and 10 from random import randint random_number = randint(1, 10)  # Reusing the math module for another calculation sqrt_result_reuse = math.sqrt(x)  # Print the results print(\"sqrt_result:\", sqrt_result) print(\"random_number:\", random_number) print(\"sqrt_result_reuse:\", sqrt_result_reuse) <pre>sqrt_result: 0.0\nrandom_number: 6\nsqrt_result_reuse: 0.0\n</pre> In\u00a0[18]: Copied! <pre>class Dog:\n    def __init__(self, name, age):\n        self.name = name\n        self.age = age\n\n    def bark(self):\n        return \"Woof!\"\n\n# Create an instance of the Dog class\nmy_dog = Dog(\"Buddy\", 3)\n\n# Print the attributes of the instance\nprint(\"my_dog name:\", my_dog.name)\nprint(\"my_dog age:\", my_dog.age)\n\n# Call the bark method of the instance\nbark_result = my_dog.bark()\nprint(\"bark_result:\", bark_result)\n</pre> class Dog:     def __init__(self, name, age):         self.name = name         self.age = age      def bark(self):         return \"Woof!\"  # Create an instance of the Dog class my_dog = Dog(\"Buddy\", 3)  # Print the attributes of the instance print(\"my_dog name:\", my_dog.name) print(\"my_dog age:\", my_dog.age)  # Call the bark method of the instance bark_result = my_dog.bark() print(\"bark_result:\", bark_result) <pre>my_dog name: Buddy\nmy_dog age: 3\nbark_result: Woof!\n</pre> <p>File Handling</p> <pre># Read content from a file\nwith open(\"file.txt\", \"r\") as file:\n    content = file.read()\n\n# Write content to a new file\nwith open(\"new_file.txt\", \"w\") as new_file:\n    new_file.write(\"Hello, world!\")\n</pre>"},{"location":"examples/python/python/#python","title":"Python\u00b6","text":"<p>Python is a high-level, interpreted programming language known for its simplicity, readability, and versatility. Created by Guido van Rossum and first released in 1991, Python has gained immense popularity in various domains, including web development, data science, automation, and more.</p>"},{"location":"examples/python/python/#why-python","title":"Why Python?\u00b6","text":"<p>Python has experienced a remarkable surge in popularity over the years and has become one of the most widely used programming languages across various fields.</p>"},{"location":"examples/python/python/#hello-world","title":"Hello, World!\u00b6","text":""},{"location":"examples/python/python/#comments","title":"Comments\u00b6","text":""},{"location":"examples/python/python/#variables-and-data-types","title":"Variables and Data Types\u00b6","text":""},{"location":"examples/python/python/#basic-operations","title":"Basic Operations\u00b6","text":""},{"location":"examples/python/python/#string-operations","title":"String Operations\u00b6","text":""},{"location":"examples/python/python/#conditional-statements","title":"Conditional Statements\u00b6","text":""},{"location":"examples/python/python/#lists","title":"Lists\u00b6","text":""},{"location":"examples/python/python/#creating-lists","title":"Creating Lists\u00b6","text":""},{"location":"examples/python/python/#list-functions-and-methods","title":"List Functions and Methods\u00b6","text":""},{"location":"examples/python/python/#selecting-list-elements","title":"Selecting List Elements\u00b6","text":""},{"location":"examples/python/python/#concatenating-lists","title":"Concatenating Lists\u00b6","text":""},{"location":"examples/python/python/#dictionaries","title":"Dictionaries\u00b6","text":""},{"location":"examples/python/python/#creating-dictionaries","title":"Creating Dictionaries\u00b6","text":""},{"location":"examples/python/python/#dictionary-functions-and-methods","title":"Dictionary Functions and Methods\u00b6","text":""},{"location":"examples/python/python/#loops","title":"Loops\u00b6","text":""},{"location":"examples/python/python/#functions","title":"Functions\u00b6","text":""},{"location":"examples/python/python/#built-in-functions","title":"Built-in Functions\u00b6","text":""},{"location":"examples/python/python/#importing-modules","title":"Importing Modules\u00b6","text":""},{"location":"examples/python/python/#classes-and-objects","title":"Classes and Objects\u00b6","text":""},{"location":"examples/python/python/#inputoutput-and-file-handling","title":"Input/Output and File Handling\u00b6","text":"<p>Input/Output</p> <pre># Get user input and display it\nuser_input = input(\"Enter a number: \")\nprint(\"You entered:\", user_input)\n</pre>"},{"location":"examples/scikit-learn/app/","title":"App","text":"In\u00a0[\u00a0]: Copied! <pre>import streamlit as st\nfrom pathlib import Path\nimport base64\nimport requests\n</pre> import streamlit as st from pathlib import Path import base64 import requests In\u00a0[\u00a0]: Copied! <pre># Initial page config\nst.set_page_config(\n    page_title='Scikit-Learn Cheat Sheet',\n    layout=\"wide\",\n    initial_sidebar_state=\"expanded\",\n)\n</pre> # Initial page config st.set_page_config(     page_title='Scikit-Learn Cheat Sheet',     layout=\"wide\",     initial_sidebar_state=\"expanded\", ) In\u00a0[\u00a0]: Copied! <pre>def main():\n    \"\"\"\n    Main function to set up the Streamlit app layout.\n    \"\"\"\n    cs_sidebar()\n    cs_body()\n    return None\n</pre> def main():     \"\"\"     Main function to set up the Streamlit app layout.     \"\"\"     cs_sidebar()     cs_body()     return None In\u00a0[\u00a0]: Copied! <pre># Define img_to_bytes() function\ndef img_to_bytes(img_url):\n    response = requests.get(img_url)\n    img_bytes = response.content\n    encoded = base64.b64encode(img_bytes).decode()\n    return encoded\n</pre> # Define img_to_bytes() function def img_to_bytes(img_url):     response = requests.get(img_url)     img_bytes = response.content     encoded = base64.b64encode(img_bytes).decode()     return encoded In\u00a0[\u00a0]: Copied! <pre># Define the cs_sidebar() function\ndef cs_sidebar():\n    \"\"\"\n    Populate the sidebar with various content sections related to Scikit-learn.\n    \"\"\"\n    st.sidebar.markdown(\n        '''[&lt;img src='data:image/png;base64,{}' class='img-fluid' width=95 &gt;](https://streamlit.io/)'''.format(\n            img_to_bytes(\"https://raw.githubusercontent.com/fralfaro/DS-Cheat-Sheets/main/docs/examples/scikit-learn/scikit-learn.png\")), unsafe_allow_html=True)\n\n    st.sidebar.header('Scikit-Learn Cheat Sheet')\n    st.sidebar.markdown('''\n&lt;small&gt;[Scikit-learn](https://scikit-learn.org/) is an open source Python library that\n implements a range of\nmachine learning,\n preprocessing, cross-validation and visualization\nalgorithms using a unified interface.&lt;/small&gt;\n    ''', unsafe_allow_html=True)\n\n    # Scikit-Learn installation and import\n    st.sidebar.markdown('__Install and import Scikit-Learn__')\n    st.sidebar.code('$ pip install scikit-learn')\n    st.sidebar.code('''\n# Import Scikit-Learn convention\n&gt;&gt;&gt; import sklearn\n''')\n\n    # Add the Scikit-learn example\n    st.sidebar.markdown('__Scikit-learn Example__')\n    st.sidebar.markdown(\n        '''[&lt;img src='data:image/png;base64,{}' class='img-fluid' width=450 &gt;](https://streamlit.io/)'''.format(\n            img_to_bytes(\"https://raw.githubusercontent.com/fralfaro/DS-Cheat-Sheets/main/docs/examples/scikit-learn/sk-tree.png\")), unsafe_allow_html=True)\n\n    st.sidebar.code(\"\"\"\n    from sklearn import neighbors, datasets, preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\n# Load the Iris dataset\niris = datasets.load_iris()\n\n# Split the dataset into features (X) and target (y)\nX, y = iris.data[:, :2], iris.target\n\n# Split the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=33)\n\n# Standardize the features using StandardScaler\nscaler = preprocessing.StandardScaler().fit(X_train)\nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)\n\n# Create a K-Nearest Neighbors classifier\nknn = neighbors.KNeighborsClassifier(n_neighbors=5)\n\n# Train the classifier on the training data\nknn.fit(X_train, y_train)\n\n# Predict the target values on the test data\ny_pred = knn.predict(X_test)\n\n# Calculate the accuracy of the classifier\naccuracy = accuracy_score(y_test, y_pred)\n\"\"\")\n    return None\n</pre> # Define the cs_sidebar() function def cs_sidebar():     \"\"\"     Populate the sidebar with various content sections related to Scikit-learn.     \"\"\"     st.sidebar.markdown(         '''[](https://streamlit.io/)'''.format(             img_to_bytes(\"https://raw.githubusercontent.com/fralfaro/DS-Cheat-Sheets/main/docs/examples/scikit-learn/scikit-learn.png\")), unsafe_allow_html=True)      st.sidebar.header('Scikit-Learn Cheat Sheet')     st.sidebar.markdown(''' [Scikit-learn](https://scikit-learn.org/) is an open source Python library that  implements a range of machine learning,  preprocessing, cross-validation and visualization algorithms using a unified interface.     ''', unsafe_allow_html=True)      # Scikit-Learn installation and import     st.sidebar.markdown('__Install and import Scikit-Learn__')     st.sidebar.code('$ pip install scikit-learn')     st.sidebar.code(''' # Import Scikit-Learn convention &gt;&gt;&gt; import sklearn ''')      # Add the Scikit-learn example     st.sidebar.markdown('__Scikit-learn Example__')     st.sidebar.markdown(         '''[](https://streamlit.io/)'''.format(             img_to_bytes(\"https://raw.githubusercontent.com/fralfaro/DS-Cheat-Sheets/main/docs/examples/scikit-learn/sk-tree.png\")), unsafe_allow_html=True)      st.sidebar.code(\"\"\"     from sklearn import neighbors, datasets, preprocessing from sklearn.model_selection import train_test_split from sklearn.metrics import accuracy_score  # Load the Iris dataset iris = datasets.load_iris()  # Split the dataset into features (X) and target (y) X, y = iris.data[:, :2], iris.target  # Split the dataset into training and testing sets X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=33)  # Standardize the features using StandardScaler scaler = preprocessing.StandardScaler().fit(X_train) X_train = scaler.transform(X_train) X_test = scaler.transform(X_test)  # Create a K-Nearest Neighbors classifier knn = neighbors.KNeighborsClassifier(n_neighbors=5)  # Train the classifier on the training data knn.fit(X_train, y_train)  # Predict the target values on the test data y_pred = knn.predict(X_test)  # Calculate the accuracy of the classifier accuracy = accuracy_score(y_test, y_pred) \"\"\")     return None In\u00a0[\u00a0]: Copied! <pre># Define the cs_body() function\ndef cs_body():\n    \"\"\"\n    Create content sections for the main body of the Streamlit cheat sheet with Scikit-learn examples.\n    \"\"\"\n    col1, col2, col3 = st.columns(3)  # Create columns for layout\n\n    #######################################\n    # COLUMN 1\n    #######################################\n\n    # Loading The Data\n    col1.subheader('Loading The Data')\n    col1.code('''\n    from sklearn import datasets\n\n    # Load the Iris dataset\n    iris = datasets.load_iris()\n\n    # Split the dataset into features (X) and target (y)\n    X, y = iris.data, iris.target\n\n    # Print the lengths of X and y\n    print(\"Size of X:\", X.shape) #  (150, 4)\n    print(\"Size of y:\", y.shape) #  (150, )\n        ''')\n\n    # Training And Test Data\n    col1.subheader('Training And Test Data')\n    col1.code('''\n    # Import train_test_split from sklearn\n    from sklearn.model_selection import train_test_split\n\n    # Split the data into training and test sets with test_size=0.2 (20% for test set)\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n        ''')\n\n    # Create instances of the models\n    col1.subheader('Create instances of the models')\n    col1.code('''\n        # Import necessary classes from sklearn libraries\n        from sklearn.linear_model import LogisticRegression\n        from sklearn.neighbors import KNeighborsClassifier\n        from sklearn.svm import SVC\n        from sklearn.cluster import KMeans\n        from sklearn.decomposition import PCA\n\n        # Create instances of supervised learning models\n        # Logistic Regression classifier (max_iter=1000)\n        lr = LogisticRegression(max_iter=1000)\n\n        # k-Nearest Neighbors classifier with 5 neighbors\n        knn = KNeighborsClassifier(n_neighbors=5)\n\n        # Support Vector Machine classifier\n        svc = SVC()\n\n        # Create instances of unsupervised learning models\n        # k-Means clustering with 3 clusters and 10 initialization attempts\n        k_means = KMeans(n_clusters=3, n_init=10)\n\n        # Principal Component Analysis with 2 components\n        pca = PCA(n_components=2)\n        ''')\n\n\n    # Model Fitting\n    col1.subheader('Model Fitting')\n    col1.code('''\n    # Supervised learning\n    lr.fit(X_train, y_train)\n    knn.fit(X_train, y_train)\n    svc.fit(X_train, y_train)\n\n    # Unsupervised Learning\n    k_means.fit(X_train)\n    pca.fit_transform(X_train)\n        ''')\n\n    # Prediction\n    col1.subheader('Prediction')\n    col1.code('''\n    # Supervised Estimators\n    y_pred = svc.predict(X_test) # Predict labels\n    y_pred = lr.predict(X_test) # Predict labels\n    y_pred = knn.predict_proba(X_test) # Estimate probability of a label\n\n    # Unsupervised Estimators\n    y_pred = k_means.predict(X_test) # Predict labels in clustering algos\n        ''')\n\n\n\n\n\n    #######################################\n    # COLUMN 2\n    #######################################\n\n    # Preprocessing The Data\n\n    # Standardization\n    col2.subheader('Standardization')\n    col2.code('''\n    from sklearn.preprocessing import StandardScaler\n\n    # Create an instance of the StandardScaler and fit it to training data\n    scaler = StandardScaler().fit(X_train)\n\n    # Transform the training and test data using the scaler\n    standardized_X = scaler.transform(X_train)\n    standardized_X_test = scaler.transform(X_test)\n    ''')\n\n    # Normalization\n    col2.subheader('Normalization')\n    col2.code('''\n    from sklearn.preprocessing import Normalizer\n    scaler = Normalizer().fit(X_train)\n    normalized_X = scaler.transform(X_train)\n    normalized_X_test = scaler.transform(X_test)\n    ''')\n\n    # Binarization\n    col2.subheader('Binarization')\n    col2.code('''\n    import numpy as np\n    from sklearn.preprocessing import Binarizer\n\n    # Create a sample data array\n    data = np.array([[1.5, 2.7, 0.8],\n                     [0.2, 3.9, 1.2],\n                     [4.1, 1.0, 2.5]])\n\n    # Create a Binarizer instance with a threshold of 2.0\n    binarizer = Binarizer(threshold=2.0)\n\n    # Apply binarization to the data\n    binarized_data = binarizer.transform(data)\n    ''')\n\n    # Encoding Categorical Features\n    col2.subheader('Encoding Categorical Features')\n    col2.code('''\n    from sklearn.preprocessing import LabelEncoder\n\n    # Sample data: categorical labels\n    labels = ['cat', 'dog', 'dog', 'fish', 'cat', 'dog', 'fish']\n\n    # Create a LabelEncoder instance\n    label_encoder = LabelEncoder()\n\n    # Fit and transform the labels\n    encoded_labels = label_encoder.fit_transform(labels)\n    ''')\n\n    # Imputing Missing Values\n    col2.subheader('Imputing Missing Values')\n    col2.code('''\n    import numpy as np\n    from sklearn.impute import SimpleImputer\n\n    # Sample data with missing values\n    data = np.array([[1.0, 2.0, np.nan],\n                     [4.0, np.nan, 6.0],\n                     [7.0, 8.0, 9.0]])\n\n    # Create a SimpleImputer instance with strategy='mean'\n    imputer = SimpleImputer(strategy='mean')\n\n    # Fit and transform the imputer on the data\n    imputed_data = imputer.fit_transform(data)\n    ''')\n\n    # Generating Polynomial Features\n    col2.subheader('Generating Polynomial Features')\n    col2.code('''\n    import numpy as np\n    from sklearn.preprocessing import PolynomialFeatures\n\n    # Sample data\n    data = np.array([[1, 2],\n                     [3, 4],\n                     [5, 6]])\n\n    # Create a PolynomialFeatures instance of degree 2\n    poly = PolynomialFeatures(degree=2)\n\n    # Transform the data to include polynomial features\n    poly_data = poly.fit_transform(data)\n    ''')\n\n\n\n    #######################################\n    # COLUMN 3\n    #######################################\n\n    # Comparison operations\n    # Classification Metrics\n    col3.subheader('Classification Metrics')\n    col3.code('''\n    from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\n    # Accuracy Score\n    accuracy_knn = knn.score(X_test, y_test)\n    print(\"Accuracy Score (knn):\", knn.score(X_test, y_test))\n\n    accuracy_y_pred = accuracy_score(y_test, y_pred_lr)\n    print(\"Accuracy Score (y_pred):\", accuracy_y_pred)\n\n    # Classification Report\n    classification_rep_y_pred = classification_report(y_test, y_pred_lr)\n    print(\"Classification Report (y_pred):\", classification_rep_y_pred)\n\n    classification_rep_y_pred_lr = classification_report(y_test, y_pred_lr)\n    print(\"Classification Report (y_pred_lr):\", classification_rep_y_pred_lr)\n\n    # Confusion Matrix\n    conf_matrix_y_pred_lr = confusion_matrix(y_test, y_pred_lr)\n    print(\"Confusion Matrix (y_pred_lr):\", conf_matrix_y_pred_lr)\n        ''')\n\n    # Regression Metrics\n    col3.subheader('Regression Metrics')\n    col3.code('''\n    from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n\n    # Data: True/Predicted values \n    y_true = [3, -0.5, 2]\n    y_pred = [2.8, -0.3, 1.8]\n\n    # Calculate Mean Absolute Error\n    mae = mean_absolute_error(y_true, y_pred)\n    print(\"Mean Absolute Error:\", mae)\n\n    # Calculate Mean Squared Error\n    mse = mean_squared_error(y_true, y_pred)\n    print(\"Mean Squared Error:\", mse)\n\n    # Calculate R\u00b2 Score\n    r2 = r2_score(y_true, y_pred)\n    print(\"R\u00b2 Score:\", r2)\n        ''')\n\n    # Clustering Metrics\n    col3.subheader('Clustering Metrics')\n    col3.code('''\n    from sklearn.metrics import adjusted_rand_score, homogeneity_score, v_measure_score\n\n    # Adjusted Rand Index\n    adjusted_rand_index = adjusted_rand_score(y_test, y_pred_kmeans)\n    print(\"Adjusted Rand Index:\", adjusted_rand_index)\n\n    # Homogeneity Score\n    homogeneity = homogeneity_score(y_test, y_pred_kmeans)\n    print(\"Homogeneity Score:\", homogeneity)\n\n    # V-Measure Score\n    v_measure = v_measure_score(y_test, y_pred_kmeans)\n    print(\"V-Measure Score:\", v_measure)\n        ''')\n\n    # Cross-Validation\n    col3.subheader('Cross-Validation')\n    col3.code('''\n    # Import necessary library\n    from sklearn.model_selection import cross_val_score\n\n    # Cross-validation with KNN estimator\n    knn_scores = cross_val_score(knn, X_train, y_train, cv=4)\n    print(knn_scores)\n\n    # Cross-validation with Linear Regression estimator\n    lr_scores = cross_val_score(lr, X, y, cv=2)\n    print(lr_scores)\n        ''')\n\n    # Grid Search\n    col3.subheader('Grid Search')\n    col3.code('''\n    # Import necessary library\n    from sklearn.model_selection import GridSearchCV\n\n    # Define parameter grid\n    params = {\n        'n_neighbors': np.arange(1, 3),\n        'weights': ['uniform', 'distance']\n    }\n\n    # Create GridSearchCV object\n    grid = GridSearchCV(estimator=knn, param_grid=params)\n\n    # Fit the grid to the data\n    grid.fit(X_train, y_train)\n\n    # Print the best parameters found\n    print(\"Best parameters:\", grid.best_params_)\n\n    # Print the best cross-validation score\n    print(\"Best cross-validation score:\", grid.best_score_)\n\n    # Print the accuracy on the test set using the best parameters\n    best_knn = grid.best_estimator_\n    test_accuracy = best_knn.score(X_test, y_test)\n    print(\"Test set accuracy:\", test_accuracy)\n        ''')\n\n    # Asking for Help\n    col1.subheader('Asking for Help')\n    col1.code('''\n    import sklearn.cluster\n\n    # Use the help() function to get information about the KMeans class\n    help(sklearn.cluster.KMeans)\n    ''')\n</pre> # Define the cs_body() function def cs_body():     \"\"\"     Create content sections for the main body of the Streamlit cheat sheet with Scikit-learn examples.     \"\"\"     col1, col2, col3 = st.columns(3)  # Create columns for layout      #######################################     # COLUMN 1     #######################################      # Loading The Data     col1.subheader('Loading The Data')     col1.code('''     from sklearn import datasets      # Load the Iris dataset     iris = datasets.load_iris()      # Split the dataset into features (X) and target (y)     X, y = iris.data, iris.target      # Print the lengths of X and y     print(\"Size of X:\", X.shape) #  (150, 4)     print(\"Size of y:\", y.shape) #  (150, )         ''')      # Training And Test Data     col1.subheader('Training And Test Data')     col1.code('''     # Import train_test_split from sklearn     from sklearn.model_selection import train_test_split      # Split the data into training and test sets with test_size=0.2 (20% for test set)     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)         ''')      # Create instances of the models     col1.subheader('Create instances of the models')     col1.code('''         # Import necessary classes from sklearn libraries         from sklearn.linear_model import LogisticRegression         from sklearn.neighbors import KNeighborsClassifier         from sklearn.svm import SVC         from sklearn.cluster import KMeans         from sklearn.decomposition import PCA          # Create instances of supervised learning models         # Logistic Regression classifier (max_iter=1000)         lr = LogisticRegression(max_iter=1000)          # k-Nearest Neighbors classifier with 5 neighbors         knn = KNeighborsClassifier(n_neighbors=5)          # Support Vector Machine classifier         svc = SVC()          # Create instances of unsupervised learning models         # k-Means clustering with 3 clusters and 10 initialization attempts         k_means = KMeans(n_clusters=3, n_init=10)          # Principal Component Analysis with 2 components         pca = PCA(n_components=2)         ''')       # Model Fitting     col1.subheader('Model Fitting')     col1.code('''     # Supervised learning     lr.fit(X_train, y_train)     knn.fit(X_train, y_train)     svc.fit(X_train, y_train)      # Unsupervised Learning     k_means.fit(X_train)     pca.fit_transform(X_train)         ''')      # Prediction     col1.subheader('Prediction')     col1.code('''     # Supervised Estimators     y_pred = svc.predict(X_test) # Predict labels     y_pred = lr.predict(X_test) # Predict labels     y_pred = knn.predict_proba(X_test) # Estimate probability of a label      # Unsupervised Estimators     y_pred = k_means.predict(X_test) # Predict labels in clustering algos         ''')          #######################################     # COLUMN 2     #######################################      # Preprocessing The Data      # Standardization     col2.subheader('Standardization')     col2.code('''     from sklearn.preprocessing import StandardScaler      # Create an instance of the StandardScaler and fit it to training data     scaler = StandardScaler().fit(X_train)      # Transform the training and test data using the scaler     standardized_X = scaler.transform(X_train)     standardized_X_test = scaler.transform(X_test)     ''')      # Normalization     col2.subheader('Normalization')     col2.code('''     from sklearn.preprocessing import Normalizer     scaler = Normalizer().fit(X_train)     normalized_X = scaler.transform(X_train)     normalized_X_test = scaler.transform(X_test)     ''')      # Binarization     col2.subheader('Binarization')     col2.code('''     import numpy as np     from sklearn.preprocessing import Binarizer      # Create a sample data array     data = np.array([[1.5, 2.7, 0.8],                      [0.2, 3.9, 1.2],                      [4.1, 1.0, 2.5]])      # Create a Binarizer instance with a threshold of 2.0     binarizer = Binarizer(threshold=2.0)      # Apply binarization to the data     binarized_data = binarizer.transform(data)     ''')      # Encoding Categorical Features     col2.subheader('Encoding Categorical Features')     col2.code('''     from sklearn.preprocessing import LabelEncoder      # Sample data: categorical labels     labels = ['cat', 'dog', 'dog', 'fish', 'cat', 'dog', 'fish']      # Create a LabelEncoder instance     label_encoder = LabelEncoder()      # Fit and transform the labels     encoded_labels = label_encoder.fit_transform(labels)     ''')      # Imputing Missing Values     col2.subheader('Imputing Missing Values')     col2.code('''     import numpy as np     from sklearn.impute import SimpleImputer      # Sample data with missing values     data = np.array([[1.0, 2.0, np.nan],                      [4.0, np.nan, 6.0],                      [7.0, 8.0, 9.0]])      # Create a SimpleImputer instance with strategy='mean'     imputer = SimpleImputer(strategy='mean')      # Fit and transform the imputer on the data     imputed_data = imputer.fit_transform(data)     ''')      # Generating Polynomial Features     col2.subheader('Generating Polynomial Features')     col2.code('''     import numpy as np     from sklearn.preprocessing import PolynomialFeatures      # Sample data     data = np.array([[1, 2],                      [3, 4],                      [5, 6]])      # Create a PolynomialFeatures instance of degree 2     poly = PolynomialFeatures(degree=2)      # Transform the data to include polynomial features     poly_data = poly.fit_transform(data)     ''')        #######################################     # COLUMN 3     #######################################      # Comparison operations     # Classification Metrics     col3.subheader('Classification Metrics')     col3.code('''     from sklearn.metrics import accuracy_score, classification_report, confusion_matrix      # Accuracy Score     accuracy_knn = knn.score(X_test, y_test)     print(\"Accuracy Score (knn):\", knn.score(X_test, y_test))      accuracy_y_pred = accuracy_score(y_test, y_pred_lr)     print(\"Accuracy Score (y_pred):\", accuracy_y_pred)      # Classification Report     classification_rep_y_pred = classification_report(y_test, y_pred_lr)     print(\"Classification Report (y_pred):\", classification_rep_y_pred)      classification_rep_y_pred_lr = classification_report(y_test, y_pred_lr)     print(\"Classification Report (y_pred_lr):\", classification_rep_y_pred_lr)      # Confusion Matrix     conf_matrix_y_pred_lr = confusion_matrix(y_test, y_pred_lr)     print(\"Confusion Matrix (y_pred_lr):\", conf_matrix_y_pred_lr)         ''')      # Regression Metrics     col3.subheader('Regression Metrics')     col3.code('''     from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score      # Data: True/Predicted values      y_true = [3, -0.5, 2]     y_pred = [2.8, -0.3, 1.8]      # Calculate Mean Absolute Error     mae = mean_absolute_error(y_true, y_pred)     print(\"Mean Absolute Error:\", mae)      # Calculate Mean Squared Error     mse = mean_squared_error(y_true, y_pred)     print(\"Mean Squared Error:\", mse)      # Calculate R\u00b2 Score     r2 = r2_score(y_true, y_pred)     print(\"R\u00b2 Score:\", r2)         ''')      # Clustering Metrics     col3.subheader('Clustering Metrics')     col3.code('''     from sklearn.metrics import adjusted_rand_score, homogeneity_score, v_measure_score      # Adjusted Rand Index     adjusted_rand_index = adjusted_rand_score(y_test, y_pred_kmeans)     print(\"Adjusted Rand Index:\", adjusted_rand_index)      # Homogeneity Score     homogeneity = homogeneity_score(y_test, y_pred_kmeans)     print(\"Homogeneity Score:\", homogeneity)      # V-Measure Score     v_measure = v_measure_score(y_test, y_pred_kmeans)     print(\"V-Measure Score:\", v_measure)         ''')      # Cross-Validation     col3.subheader('Cross-Validation')     col3.code('''     # Import necessary library     from sklearn.model_selection import cross_val_score      # Cross-validation with KNN estimator     knn_scores = cross_val_score(knn, X_train, y_train, cv=4)     print(knn_scores)      # Cross-validation with Linear Regression estimator     lr_scores = cross_val_score(lr, X, y, cv=2)     print(lr_scores)         ''')      # Grid Search     col3.subheader('Grid Search')     col3.code('''     # Import necessary library     from sklearn.model_selection import GridSearchCV      # Define parameter grid     params = {         'n_neighbors': np.arange(1, 3),         'weights': ['uniform', 'distance']     }      # Create GridSearchCV object     grid = GridSearchCV(estimator=knn, param_grid=params)      # Fit the grid to the data     grid.fit(X_train, y_train)      # Print the best parameters found     print(\"Best parameters:\", grid.best_params_)      # Print the best cross-validation score     print(\"Best cross-validation score:\", grid.best_score_)      # Print the accuracy on the test set using the best parameters     best_knn = grid.best_estimator_     test_accuracy = best_knn.score(X_test, y_test)     print(\"Test set accuracy:\", test_accuracy)         ''')      # Asking for Help     col1.subheader('Asking for Help')     col1.code('''     import sklearn.cluster      # Use the help() function to get information about the KMeans class     help(sklearn.cluster.KMeans)     ''') In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre># Run the main function if the script is executed directly\nif __name__ == '__main__':\n    main()\n</pre> # Run the main function if the script is executed directly if __name__ == '__main__':     main()"},{"location":"examples/scikit-learn/sklearn/","title":"Scikit-Learn","text":"In\u00a0[1]: Copied! <pre># Import Scikit-Learn convention\nimport sklearn\n</pre> # Import Scikit-Learn convention import sklearn In\u00a0[1]: Copied! <pre>from sklearn import neighbors, datasets, preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\n# Load the Iris dataset\niris = datasets.load_iris()\n\n# Split the dataset into features (X) and target (y)\nX, y = iris.data[:, :2], iris.target\n\n# Split the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=33)\n\n# Standardize the features using StandardScaler\nscaler = preprocessing.StandardScaler().fit(X_train)\nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)\n\n# Create a K-Nearest Neighbors classifier\nknn = neighbors.KNeighborsClassifier(n_neighbors=5)\n\n# Train the classifier on the training data\nknn.fit(X_train, y_train)\n\n# Predict the target values on the test data\ny_pred = knn.predict(X_test)\n\n# Calculate the accuracy of the classifier\naccuracy = accuracy_score(y_test, y_pred)\n\n# Print the accuracy\nprint(\"Accuracy:\", accuracy)\n</pre> from sklearn import neighbors, datasets, preprocessing from sklearn.model_selection import train_test_split from sklearn.metrics import accuracy_score  # Load the Iris dataset iris = datasets.load_iris()  # Split the dataset into features (X) and target (y) X, y = iris.data[:, :2], iris.target  # Split the dataset into training and testing sets X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=33)  # Standardize the features using StandardScaler scaler = preprocessing.StandardScaler().fit(X_train) X_train = scaler.transform(X_train) X_test = scaler.transform(X_test)  # Create a K-Nearest Neighbors classifier knn = neighbors.KNeighborsClassifier(n_neighbors=5)  # Train the classifier on the training data knn.fit(X_train, y_train)  # Predict the target values on the test data y_pred = knn.predict(X_test)  # Calculate the accuracy of the classifier accuracy = accuracy_score(y_test, y_pred)  # Print the accuracy print(\"Accuracy:\", accuracy) <pre>Accuracy: 0.631578947368421\n</pre> In\u00a0[2]: Copied! <pre>from sklearn import datasets\n\n# Load the Iris dataset\niris = datasets.load_iris()\n\n# Split the dataset into features (X) and target (y)\nX, y = iris.data, iris.target\n\n# Print the lengths of X and y\nprint(\"Size of X:\", X.shape) #  (150, 4)\nprint(\"Size of y:\", y.shape) #  (150, )\n</pre> from sklearn import datasets  # Load the Iris dataset iris = datasets.load_iris()  # Split the dataset into features (X) and target (y) X, y = iris.data, iris.target  # Print the lengths of X and y print(\"Size of X:\", X.shape) #  (150, 4) print(\"Size of y:\", y.shape) #  (150, ) <pre>Size of X: (150, 4)\nSize of y: (150,)\n</pre> In\u00a0[3]: Copied! <pre># Import train_test_split from sklearn\nfrom sklearn.model_selection import train_test_split\n\n# Split the data into training and test sets with test_size=0.2 (20% for test set)\nX, y = iris.data, iris.target\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n\n# Print the sizes of the arrays\nprint(\"Size of X_train:\", X_train.shape)\nprint(\"Size of X_test: \", X_test.shape)\nprint(\"Size of y_train:\", y_train.shape)\nprint(\"Size of y_test: \", y_test.shape)\n</pre> # Import train_test_split from sklearn from sklearn.model_selection import train_test_split  # Split the data into training and test sets with test_size=0.2 (20% for test set) X, y = iris.data, iris.target X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)  # Print the sizes of the arrays print(\"Size of X_train:\", X_train.shape) print(\"Size of X_test: \", X_test.shape) print(\"Size of y_train:\", y_train.shape) print(\"Size of y_test: \", y_test.shape) <pre>Size of X_train: (120, 4)\nSize of X_test:  (30, 4)\nSize of y_train: (120,)\nSize of y_test:  (30,)\n</pre> In\u00a0[4]: Copied! <pre># Import necessary classes from sklearn libraries\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\n\n# Create instances of supervised learning models\n# Logistic Regression classifier (max_iter=1000)\nlr = LogisticRegression(max_iter=1000)\n\n# k-Nearest Neighbors classifier with 5 neighbors\nknn = KNeighborsClassifier(n_neighbors=5)\n\n# Support Vector Machine classifier\nsvc = SVC()\n\n# Create instances of unsupervised learning models\n# k-Means clustering with 3 clusters and 10 initialization attempts\nk_means = KMeans(n_clusters=3, n_init=10)\n\n# Principal Component Analysis with 2 components\npca = PCA(n_components=2)\n</pre> # Import necessary classes from sklearn libraries from sklearn.linear_model import LogisticRegression from sklearn.neighbors import KNeighborsClassifier from sklearn.svm import SVC from sklearn.cluster import KMeans from sklearn.decomposition import PCA  # Create instances of supervised learning models # Logistic Regression classifier (max_iter=1000) lr = LogisticRegression(max_iter=1000)  # k-Nearest Neighbors classifier with 5 neighbors knn = KNeighborsClassifier(n_neighbors=5)  # Support Vector Machine classifier svc = SVC()  # Create instances of unsupervised learning models # k-Means clustering with 3 clusters and 10 initialization attempts k_means = KMeans(n_clusters=3, n_init=10)  # Principal Component Analysis with 2 components pca = PCA(n_components=2) In\u00a0[5]: Copied! <pre># Fit models to the data\nlr.fit(X_train, y_train)\nknn.fit(X_train, y_train)\nsvc.fit(X_train, y_train)\nk_means.fit(X_train)\npca.fit_transform(X_train)\n\n# Print the instances and models\nprint(\"lr:\", lr)\nprint(\"knn:\", knn)\nprint(\"svc:\", svc)\nprint(\"k_means:\", k_means)\nprint(\"pca:\", pca)\n</pre> # Fit models to the data lr.fit(X_train, y_train) knn.fit(X_train, y_train) svc.fit(X_train, y_train) k_means.fit(X_train) pca.fit_transform(X_train)  # Print the instances and models print(\"lr:\", lr) print(\"knn:\", knn) print(\"svc:\", svc) print(\"k_means:\", k_means) print(\"pca:\", pca) <pre>lr: LogisticRegression(max_iter=1000)\nknn: KNeighborsClassifier()\nsvc: SVC()\nk_means: KMeans(n_clusters=3, n_init=10)\npca: PCA(n_components=2)\n</pre> In\u00a0[6]: Copied! <pre># Predict using different supervised estimators\ny_pred_svc = svc.predict(X_test)\ny_pred_lr = lr.predict(X_test)\ny_pred_knn_proba = knn.predict_proba(X_test)\n\n\n# Predict labels using KMeans in clustering algorithms\ny_pred_kmeans = k_means.predict(X_test)\n\n# Print the results\nprint(\"Supervised Estimators:\")\nprint(\"SVC predictions:\", y_pred_svc)\nprint(\"Logistic Regression predictions:\", y_pred_lr)\nprint(\"KNeighborsClassifier probabilities:\\n\", y_pred_knn_proba[:5],\"\\n     ...\")\n\nprint(\"\\nUnsupervised Estimators:\")\nprint(\"KMeans predictions:\", y_pred_kmeans)\n</pre> # Predict using different supervised estimators y_pred_svc = svc.predict(X_test) y_pred_lr = lr.predict(X_test) y_pred_knn_proba = knn.predict_proba(X_test)   # Predict labels using KMeans in clustering algorithms y_pred_kmeans = k_means.predict(X_test)  # Print the results print(\"Supervised Estimators:\") print(\"SVC predictions:\", y_pred_svc) print(\"Logistic Regression predictions:\", y_pred_lr) print(\"KNeighborsClassifier probabilities:\\n\", y_pred_knn_proba[:5],\"\\n     ...\")  print(\"\\nUnsupervised Estimators:\") print(\"KMeans predictions:\", y_pred_kmeans) <pre>Supervised Estimators:\nSVC predictions: [2 1 0 2 0 2 0 1 1 1 2 1 1 1 1 0 1 1 0 0 2 1 0 0 2 0 0 1 1 0]\nLogistic Regression predictions: [2 1 0 2 0 2 0 1 1 1 2 1 1 1 1 0 1 1 0 0 2 1 0 0 2 0 0 1 1 0]\nKNeighborsClassifier probabilities:\n [[0. 0. 1.]\n [0. 1. 0.]\n [1. 0. 0.]\n [0. 0. 1.]\n [1. 0. 0.]] \n     ...\n\nUnsupervised Estimators:\nKMeans predictions: [2 2 0 1 0 1 0 2 2 2 1 2 2 2 2 0 2 2 0 0 2 2 0 0 2 0 0 2 2 0]\n</pre> In\u00a0[7]: Copied! <pre>from sklearn.preprocessing import StandardScaler\n\n# Create an instance of the StandardScaler and fit it to training data\nscaler = StandardScaler().fit(X_train)\n\n# Transform the training and test data using the scaler\nstandardized_X = scaler.transform(X_train)\nstandardized_X_test = scaler.transform(X_test)\n\n# Print the variables\nprint(\"\\nStandardized X_train:\\n\", standardized_X[:5],\"\\n     ...\")\nprint(\"\\nStandardized X_test:\\n\", standardized_X_test[:5],\"\\n     ...\")\n</pre> from sklearn.preprocessing import StandardScaler  # Create an instance of the StandardScaler and fit it to training data scaler = StandardScaler().fit(X_train)  # Transform the training and test data using the scaler standardized_X = scaler.transform(X_train) standardized_X_test = scaler.transform(X_test)  # Print the variables print(\"\\nStandardized X_train:\\n\", standardized_X[:5],\"\\n     ...\") print(\"\\nStandardized X_test:\\n\", standardized_X_test[:5],\"\\n     ...\") <pre>\nStandardized X_train:\n [[ 0.61303014  0.10850105  0.94751783  0.736072  ]\n [-0.56776627 -0.12400121  0.38491447  0.34752959]\n [-0.80392556  1.03851009 -1.30289562 -1.33615415]\n [ 0.25879121 -0.12400121  0.60995581  0.736072  ]\n [ 0.61303014 -0.58900572  1.00377816  1.25412853]] \n     ...\n\nStandardized X_test:\n [[-0.09544771 -0.58900572  0.72247648  1.5131568 ]\n [ 0.14071157 -1.98401928  0.10361279 -0.30004108]\n [-0.44968663  2.66602591 -1.35915595 -1.33615415]\n [ 1.6757469  -0.35650346  1.39760052  0.736072  ]\n [-1.04008484  0.80600783 -1.30289562 -1.33615415]] \n     ...\n</pre> In\u00a0[8]: Copied! <pre>from sklearn.preprocessing import Normalizer\nscaler = Normalizer().fit(X_train)\nnormalized_X = scaler.transform(X_train)\nnormalized_X_test = scaler.transform(X_test)\n\n# Print the variables\nprint(\"\\nNormalized X_train:\\n\", normalized_X[:5],\"\\n     ...\")\nprint(\"\\nNormalized X_test:\\n\", normalized_X_test[:5],\"\\n     ...\")\n</pre> from sklearn.preprocessing import Normalizer scaler = Normalizer().fit(X_train) normalized_X = scaler.transform(X_train) normalized_X_test = scaler.transform(X_test)  # Print the variables print(\"\\nNormalized X_train:\\n\", normalized_X[:5],\"\\n     ...\") print(\"\\nNormalized X_test:\\n\", normalized_X_test[:5],\"\\n     ...\") <pre>\nNormalized X_train:\n [[0.69804799 0.338117   0.59988499 0.196326  ]\n [0.69333409 0.38518561 0.57777841 0.1925928 ]\n [0.80641965 0.54278246 0.23262105 0.03101614]\n [0.71171214 0.35002236 0.57170319 0.21001342]\n [0.69417747 0.30370264 0.60740528 0.2386235 ]] \n     ...\n\nNormalized X_test:\n [[0.67767924 0.32715549 0.59589036 0.28041899]\n [0.78892752 0.28927343 0.52595168 0.13148792]\n [0.77867447 0.59462414 0.19820805 0.02831544]\n [0.71366557 0.28351098 0.61590317 0.17597233]\n [0.80218492 0.54548574 0.24065548 0.0320874 ]] \n     ...\n</pre> In\u00a0[9]: Copied! <pre>import numpy as np\nfrom sklearn.preprocessing import Binarizer\n\n# Create a sample data array\ndata = np.array([[1.5, 2.7, 0.8],\n                 [0.2, 3.9, 1.2],\n                 [4.1, 1.0, 2.5]])\n\n# Create a Binarizer instance with a threshold of 2.0\nbinarizer = Binarizer(threshold=2.0)\n\n# Apply binarization to the data\nbinarized_data = binarizer.transform(data)\n\nprint(\"Original data:\")\nprint(data)\nprint(\"\\nBinarized data:\")\nprint(binarized_data)\n</pre> import numpy as np from sklearn.preprocessing import Binarizer  # Create a sample data array data = np.array([[1.5, 2.7, 0.8],                  [0.2, 3.9, 1.2],                  [4.1, 1.0, 2.5]])  # Create a Binarizer instance with a threshold of 2.0 binarizer = Binarizer(threshold=2.0)  # Apply binarization to the data binarized_data = binarizer.transform(data)  print(\"Original data:\") print(data) print(\"\\nBinarized data:\") print(binarized_data) <pre>Original data:\n[[1.5 2.7 0.8]\n [0.2 3.9 1.2]\n [4.1 1.  2.5]]\n\nBinarized data:\n[[0. 1. 0.]\n [0. 1. 0.]\n [1. 0. 1.]]\n</pre> In\u00a0[10]: Copied! <pre>from sklearn.preprocessing import LabelEncoder\n\n# Sample data: categorical labels\nlabels = ['cat', 'dog', 'dog', 'fish', 'cat', 'dog', 'fish']\n\n# Create a LabelEncoder instance\nlabel_encoder = LabelEncoder()\n\n# Fit and transform the labels\nencoded_labels = label_encoder.fit_transform(labels)\n\n# Print the original labels and their encoded versions\nprint(\"Original labels:\", labels)\nprint(\"Encoded labels:\", encoded_labels)\n\n# Decode the encoded labels back to the original labels\ndecoded_labels = label_encoder.inverse_transform(encoded_labels)\nprint(\"Decoded labels:\", decoded_labels)\n</pre> from sklearn.preprocessing import LabelEncoder  # Sample data: categorical labels labels = ['cat', 'dog', 'dog', 'fish', 'cat', 'dog', 'fish']  # Create a LabelEncoder instance label_encoder = LabelEncoder()  # Fit and transform the labels encoded_labels = label_encoder.fit_transform(labels)  # Print the original labels and their encoded versions print(\"Original labels:\", labels) print(\"Encoded labels:\", encoded_labels)  # Decode the encoded labels back to the original labels decoded_labels = label_encoder.inverse_transform(encoded_labels) print(\"Decoded labels:\", decoded_labels) <pre>Original labels: ['cat', 'dog', 'dog', 'fish', 'cat', 'dog', 'fish']\nEncoded labels: [0 1 1 2 0 1 2]\nDecoded labels: ['cat' 'dog' 'dog' 'fish' 'cat' 'dog' 'fish']\n</pre> In\u00a0[11]: Copied! <pre>import numpy as np\nfrom sklearn.impute import SimpleImputer\n\n# Sample data with missing values\ndata = np.array([[1.0, 2.0, np.nan],\n                 [4.0, np.nan, 6.0],\n                 [7.0, 8.0, 9.0]])\n\n# Create a SimpleImputer instance with strategy='mean'\nimputer = SimpleImputer(strategy='mean')\n\n# Fit and transform the imputer on the data\nimputed_data = imputer.fit_transform(data)\n\nprint(\"Original data:\")\nprint(data)\nprint(\"\\nImputed data:\")\nprint(imputed_data)\n</pre> import numpy as np from sklearn.impute import SimpleImputer  # Sample data with missing values data = np.array([[1.0, 2.0, np.nan],                  [4.0, np.nan, 6.0],                  [7.0, 8.0, 9.0]])  # Create a SimpleImputer instance with strategy='mean' imputer = SimpleImputer(strategy='mean')  # Fit and transform the imputer on the data imputed_data = imputer.fit_transform(data)  print(\"Original data:\") print(data) print(\"\\nImputed data:\") print(imputed_data) <pre>Original data:\n[[ 1.  2. nan]\n [ 4. nan  6.]\n [ 7.  8.  9.]]\n\nImputed data:\n[[1.  2.  7.5]\n [4.  5.  6. ]\n [7.  8.  9. ]]\n</pre> In\u00a0[12]: Copied! <pre>import numpy as np\nfrom sklearn.preprocessing import PolynomialFeatures\n\n# Sample data\ndata = np.array([[1, 2],\n                 [3, 4],\n                 [5, 6]])\n\n# Create a PolynomialFeatures instance of degree 2\npoly = PolynomialFeatures(degree=2)\n\n# Transform the data to include polynomial features\npoly_data = poly.fit_transform(data)\n\nprint(\"Original data:\")\nprint(data)\nprint(\"\\nPolynomial features:\")\nprint(poly_data)\n</pre> import numpy as np from sklearn.preprocessing import PolynomialFeatures  # Sample data data = np.array([[1, 2],                  [3, 4],                  [5, 6]])  # Create a PolynomialFeatures instance of degree 2 poly = PolynomialFeatures(degree=2)  # Transform the data to include polynomial features poly_data = poly.fit_transform(data)  print(\"Original data:\") print(data) print(\"\\nPolynomial features:\") print(poly_data) <pre>Original data:\n[[1 2]\n [3 4]\n [5 6]]\n\nPolynomial features:\n[[ 1.  1.  2.  1.  2.  4.]\n [ 1.  3.  4.  9. 12. 16.]\n [ 1.  5.  6. 25. 30. 36.]]\n</pre> In\u00a0[13]: Copied! <pre>from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\n# Accuracy Score\naccuracy_knn = knn.score(X_test, y_test)\nprint(\"Accuracy Score (knn):\", knn.score(X_test, y_test))\n\naccuracy_y_pred = accuracy_score(y_test, y_pred_lr)\nprint(\"Accuracy Score (y_pred):\", accuracy_y_pred)\n\n# Classification Report\nclassification_rep_y_pred = classification_report(y_test, y_pred_lr)\nprint(\"Classification Report (y_pred):\\n\", classification_rep_y_pred)\n\nclassification_rep_y_pred_lr = classification_report(y_test, y_pred_lr)\nprint(\"Classification Report (y_pred_lr):\\n\", classification_rep_y_pred_lr)\n\n# Confusion Matrix\nconf_matrix_y_pred_lr = confusion_matrix(y_test, y_pred_lr)\nprint(\"Confusion Matrix (y_pred_lr):\\n\", conf_matrix_y_pred_lr)\n</pre> from sklearn.metrics import accuracy_score, classification_report, confusion_matrix  # Accuracy Score accuracy_knn = knn.score(X_test, y_test) print(\"Accuracy Score (knn):\", knn.score(X_test, y_test))  accuracy_y_pred = accuracy_score(y_test, y_pred_lr) print(\"Accuracy Score (y_pred):\", accuracy_y_pred)  # Classification Report classification_rep_y_pred = classification_report(y_test, y_pred_lr) print(\"Classification Report (y_pred):\\n\", classification_rep_y_pred)  classification_rep_y_pred_lr = classification_report(y_test, y_pred_lr) print(\"Classification Report (y_pred_lr):\\n\", classification_rep_y_pred_lr)  # Confusion Matrix conf_matrix_y_pred_lr = confusion_matrix(y_test, y_pred_lr) print(\"Confusion Matrix (y_pred_lr):\\n\", conf_matrix_y_pred_lr) <pre>Accuracy Score (knn): 0.9666666666666667\nAccuracy Score (y_pred): 1.0\nClassification Report (y_pred):\n               precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        11\n           1       1.00      1.00      1.00        13\n           2       1.00      1.00      1.00         6\n\n    accuracy                           1.00        30\n   macro avg       1.00      1.00      1.00        30\nweighted avg       1.00      1.00      1.00        30\n\nClassification Report (y_pred_lr):\n               precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        11\n           1       1.00      1.00      1.00        13\n           2       1.00      1.00      1.00         6\n\n    accuracy                           1.00        30\n   macro avg       1.00      1.00      1.00        30\nweighted avg       1.00      1.00      1.00        30\n\nConfusion Matrix (y_pred_lr):\n [[11  0  0]\n [ 0 13  0]\n [ 0  0  6]]\n</pre> In\u00a0[14]: Copied! <pre>from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n\n# True values (ground truth)\ny_true = [3, -0.5, 2]\n\n# Predicted values\ny_pred = [2.8, -0.3, 1.8]\n\n# Calculate Mean Absolute Error\nmae = mean_absolute_error(y_true, y_pred)\nprint(\"Mean Absolute Error:\", mae)\n\n# Calculate Mean Squared Error\nmse = mean_squared_error(y_true, y_pred)\nprint(\"Mean Squared Error:\", mse)\n\n# Calculate R\u00b2 Score\nr2 = r2_score(y_true, y_pred)\nprint(\"R\u00b2 Score:\", r2)\n</pre> from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score  # True values (ground truth) y_true = [3, -0.5, 2]  # Predicted values y_pred = [2.8, -0.3, 1.8]  # Calculate Mean Absolute Error mae = mean_absolute_error(y_true, y_pred) print(\"Mean Absolute Error:\", mae)  # Calculate Mean Squared Error mse = mean_squared_error(y_true, y_pred) print(\"Mean Squared Error:\", mse)  # Calculate R\u00b2 Score r2 = r2_score(y_true, y_pred) print(\"R\u00b2 Score:\", r2) <pre>Mean Absolute Error: 0.20000000000000004\nMean Squared Error: 0.040000000000000015\nR\u00b2 Score: 0.9815384615384616\n</pre> In\u00a0[15]: Copied! <pre>from sklearn.metrics import adjusted_rand_score, homogeneity_score, v_measure_score\n\n# Adjusted Rand Index\nadjusted_rand_index = adjusted_rand_score(y_test, y_pred_kmeans)\nprint(\"Adjusted Rand Index:\", adjusted_rand_index)\n\n# Homogeneity Score\nhomogeneity = homogeneity_score(y_test, y_pred_kmeans)\nprint(\"Homogeneity Score:\", homogeneity)\n\n# V-Measure Score\nv_measure = v_measure_score(y_test, y_pred_kmeans)\nprint(\"V-Measure Score:\", v_measure)\n</pre> from sklearn.metrics import adjusted_rand_score, homogeneity_score, v_measure_score  # Adjusted Rand Index adjusted_rand_index = adjusted_rand_score(y_test, y_pred_kmeans) print(\"Adjusted Rand Index:\", adjusted_rand_index)  # Homogeneity Score homogeneity = homogeneity_score(y_test, y_pred_kmeans) print(\"Homogeneity Score:\", homogeneity)  # V-Measure Score v_measure = v_measure_score(y_test, y_pred_kmeans) print(\"V-Measure Score:\", v_measure) <pre>Adjusted Rand Index: 0.7657144139494176\nHomogeneity Score: 0.7553796021571243\nV-Measure Score: 0.8005552543570766\n</pre> In\u00a0[16]: Copied! <pre># Import necessary library\nfrom sklearn.model_selection import cross_val_score\n\n# Cross-validation with KNN estimator\nknn_scores = cross_val_score(knn, X_train, y_train, cv=4)\nprint(knn_scores)\n\n# Cross-validation with Linear Regression estimator\nlr_scores = cross_val_score(lr, X, y, cv=2)\nprint(lr_scores)\n</pre> # Import necessary library from sklearn.model_selection import cross_val_score  # Cross-validation with KNN estimator knn_scores = cross_val_score(knn, X_train, y_train, cv=4) print(knn_scores)  # Cross-validation with Linear Regression estimator lr_scores = cross_val_score(lr, X, y, cv=2) print(lr_scores) <pre>[0.96666667 0.93333333 1.         0.93333333]\n[0.96 0.96]\n</pre> In\u00a0[17]: Copied! <pre># Import necessary library\nfrom sklearn.model_selection import GridSearchCV\n\n# Define parameter grid\nparams = {\n    'n_neighbors': np.arange(1, 3),\n    'weights': ['uniform', 'distance']\n}\n\n# Create GridSearchCV object\ngrid = GridSearchCV(estimator=knn, param_grid=params)\n\n# Fit the grid to the data\ngrid.fit(X_train, y_train)\n\n# Print the best parameters found\nprint(\"Best parameters:\", grid.best_params_)\n\n# Print the best cross-validation score\nprint(\"Best cross-validation score:\", grid.best_score_)\n\n# Print the accuracy on the test set using the best parameters\nbest_knn = grid.best_estimator_\ntest_accuracy = best_knn.score(X_test, y_test)\nprint(\"Test set accuracy:\", test_accuracy)\n</pre> # Import necessary library from sklearn.model_selection import GridSearchCV  # Define parameter grid params = {     'n_neighbors': np.arange(1, 3),     'weights': ['uniform', 'distance'] }  # Create GridSearchCV object grid = GridSearchCV(estimator=knn, param_grid=params)  # Fit the grid to the data grid.fit(X_train, y_train)  # Print the best parameters found print(\"Best parameters:\", grid.best_params_)  # Print the best cross-validation score print(\"Best cross-validation score:\", grid.best_score_)  # Print the accuracy on the test set using the best parameters best_knn = grid.best_estimator_ test_accuracy = best_knn.score(X_test, y_test) print(\"Test set accuracy:\", test_accuracy) <pre>Best parameters: {'n_neighbors': 1, 'weights': 'uniform'}\nBest cross-validation score: 0.9416666666666667\nTest set accuracy: 1.0\n</pre>"},{"location":"examples/scikit-learn/sklearn/#scikit-learn","title":"Scikit-Learn\u00b6","text":"<p>Scikit-learn is an open source Python library that implements a range of machine learning, preprocessing, cross-validation and visualization algorithms using a unified interface.</p>"},{"location":"examples/scikit-learn/sklearn/#install-and-import-scikit-learn","title":"Install and import Scikit-Learn\u00b6","text":"<p><code>$ pip install scikit-learn</code></p>"},{"location":"examples/scikit-learn/sklearn/#scikit-learn-example","title":"Scikit-learn Example\u00b6","text":""},{"location":"examples/scikit-learn/sklearn/#loading-the-data","title":"Loading The Data\u00b6","text":""},{"location":"examples/scikit-learn/sklearn/#training-and-test-data","title":"Training And Test Data\u00b6","text":""},{"location":"examples/scikit-learn/sklearn/#create-instances-of-the-models","title":"Create instances of the models\u00b6","text":""},{"location":"examples/scikit-learn/sklearn/#model-fitting","title":"Model Fitting\u00b6","text":""},{"location":"examples/scikit-learn/sklearn/#prediction","title":"Prediction\u00b6","text":""},{"location":"examples/scikit-learn/sklearn/#preprocessing-the-data","title":"Preprocessing The Data\u00b6","text":""},{"location":"examples/scikit-learn/sklearn/#standardization","title":"Standardization\u00b6","text":""},{"location":"examples/scikit-learn/sklearn/#normalization","title":"Normalization\u00b6","text":""},{"location":"examples/scikit-learn/sklearn/#binarization","title":"Binarization\u00b6","text":""},{"location":"examples/scikit-learn/sklearn/#encoding-categorical-features","title":"Encoding Categorical Features\u00b6","text":""},{"location":"examples/scikit-learn/sklearn/#imputing-missing-values","title":"Imputing Missing Values\u00b6","text":""},{"location":"examples/scikit-learn/sklearn/#generating-polynomial-features","title":"Generating Polynomial Features\u00b6","text":""},{"location":"examples/scikit-learn/sklearn/#classification-metrics","title":"Classification Metrics\u00b6","text":""},{"location":"examples/scikit-learn/sklearn/#regression-metrics","title":"Regression Metrics\u00b6","text":""},{"location":"examples/scikit-learn/sklearn/#clustering-metrics","title":"Clustering Metrics\u00b6","text":""},{"location":"examples/scikit-learn/sklearn/#cross-validation","title":"Cross-Validation\u00b6","text":""},{"location":"examples/scikit-learn/sklearn/#grid-search","title":"Grid Search\u00b6","text":""}]}